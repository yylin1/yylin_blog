<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Frank's Notes</title><link>https://blog.yylin.io/</link><description>Recent content on Frank's Notes</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><lastBuildDate>Sun, 31 Dec 2023 13:33:28 +0800</lastBuildDate><atom:link href="https://blog.yylin.io/index.xml" rel="self" type="application/rss+xml"/><item><title>2023 年度回顧 / 2024 年展望</title><link>https://blog.yylin.io/year/2023-retrospect-and-prospect/</link><pubDate>Sun, 31 Dec 2023 13:33:28 +0800</pubDate><guid>https://blog.yylin.io/year/2023-retrospect-and-prospect/</guid><description>&lt;p>| 本篇是個人於 2023 年的紀錄以及對於未來的展望&lt;/p>
&lt;p>2023 充滿變化和轉折的一年，在職場和生活的各個方面都嘗試了許多新事物，並積極改變以往的習慣、心態和生活方式，這些努力逐步調整過程，同時在人生的道路上慢慢找到了自己的定位，做任何事都有了明確意義。&lt;/p>
&lt;p>&lt;img src="https://blog.yylin.io/year/2023-retrospect-and-prospect/images/2023-reospect-prospect.png"
width="1620"
height="1080"
srcset="https://blog.yylin.io/year/2023-retrospect-and-prospect/images/2023-reospect-prospect_huca3b4ab34d006b28a7472e6d6d1a75cc_2652010_480x0_resize_box_3.png 480w, https://blog.yylin.io/year/2023-retrospect-and-prospect/images/2023-reospect-prospect_huca3b4ab34d006b28a7472e6d6d1a75cc_2652010_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>&lt;/p>
&lt;h2 id="工作">工作&lt;/h2>
&lt;ol>
&lt;li>內部職位調整 &lt;code>Specialist SA&lt;/code> 轉回 &lt;code>Account SA&lt;/code> ，更聚焦深入理解客戶的業務需求和面臨的挑戰，設計出切合實際的技術解決方案、規劃系統架構，以及確定實施方案的步驟和專案時程，確保成功交付客戶所需解決方案。&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>關於專案進行，我有額外進修專案管理課程，很實用就是課程內容提供 BIG TABLE 表格與真實情境演練，上完課隔日就能馬上在專案上使用，推薦大家上&lt;a class="link" href="https://shop.darencademy.com/product/view/id/1" target="_blank" rel="noopener"
>大人學 - 101專案管理一日特訓班(7PDU)｜專案管理課程&lt;/a>。&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>公司策略走向，有機會想拓展 Taiwan AI 市場與容器平台機會，再次接觸到好多之前合作過的 AI 平台公司，還有 OEM 廠商還記得我之前有合作過，就這樣再次踏上 AI 浪潮時間，慢慢將市場與需求拼圖慢慢拼湊出來。&lt;/li>
&lt;li>後疫情時代首次能出國出差的時刻，有機會參加在公司舉辦在新加坡 Singapore 的 &lt;code>Tech Exchange 2023&lt;/code>年會，真的很難得有機會和 APAC 區域的不同國家的同事交流經驗與技術，還有見沒有見過的網友同事，意外很充實的技術年會收穫，額外最驚艷應該是有機會在 GalaParty 看到印度舞蹈的魅力與群體氛圍。&lt;/li>
&lt;li>在 Intel Vision APJ 2023 活動上，有機會與首席架構師 Andreas Spanner 共同合作，特別展示 MLOps 和 RHODS 與 Intel OpenVINO Toolkit 結合應用場景，還有機會與來自不同國家的 Red Hat Global Team 同事進行深入交流，更榮幸與 Intel 的 CEO - Pat Gelsinger 合影留念，真的是我非常難得的機會。&lt;/li>
&lt;/ol>
&lt;h2 id="生活">生活&lt;/h2>
&lt;ol>
&lt;li>和夥伴約定 3 年前的滑雪計畫，終於這次疫情後出團成功，我的第一個雪季來到&lt;code>新潟-妙高高原滑雪&lt;/code>，真的很不一樣的體驗。雖然出發前有大夥去小叮噹雪場上過教練課-行前訓練，但在真正雪場需要克服的狀況很不同，最難還是上下纜車不同地形還是很有挑戰，還有遇到搭纜車時下雪時刻超美。很感謝夥伴信任，讓我用帶相機上纜車捕捉到一些難忘的雪景，更多雪景可以看我的攝影網站 &lt;a class="link" href="https://yiyanglin.tw/myoko-kogen" target="_blank" rel="noopener"
>Myoko Kogen, Niigata | 新潟 妙高高原&lt;/a>。&lt;/li>
&lt;li>自主揪山最大一團的經驗，霞可羅古道(養老步道至白石駐在所往返, 24K)，工程師遠離電腦桌前，也要親身體會才能感受山裡帶給我們的平靜，因為有更多夥伴來爬山，每一次爬山都有更多不一樣的滋味。&lt;/li>
&lt;li>參加了英文口說班跟社交班，每個禮拜都花很多時間在準備作業非常不容易，但感覺在互動對話的過程有進步一些，目標是希望之後和國外同事交流過程，可以有更多閒聊自己日常生活 Small Talk。&lt;/li>
&lt;li>把實體書慢慢轉換至 KOBO 電子書平台，&lt;code>建立閱讀習慣&lt;/code>，喜歡閱讀的開始是因為想多看書中作者是怎麼研究、思考問題，當他們面對人生相似的困境時，這個過程如何看待問題、如何解決問題來學會不同的觀點，然後把這些觀點內化成自己的思考，當生活中遇到的各種難題上，思維也會變得更開闊。(今年多補一個 #值得閱讀的書單)&lt;/li>
&lt;li>終於有機會現場聽到告五人演唱會，最初在 #街聲Streetvoice 上聽他們的 Demo 發表，從那時起，目睹告五人一步步成長，如今他們已經開始了世界巡迴，這次在巨蛋的表演讓我第一次體會到他們的魅力，舞台佈置和光線效果驚人，感謝告五人為我們的生活帶來更多美好，期待下次的相遇。&lt;/li>
&lt;li>自我盤整之外，今年也做了一部攝影 60 張照片回顧，透過鏡頭記錄自己的每一刻，希望每年都有不同的精彩。&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://lh3.googleusercontent.com/pw/ABLVV8437oxFfJxVTn0hWIP7nBHfFD5zLR4CNGvlW1OmZFRIfuJ9e6W9W7TJXdXJHcJtRrmmxJhSQJpF9KydzLF2pGDclQ5ASGrMMeyDl4QLrcOxKZ7WYFXSsMJaYTveG2Ilwi5zV5WqTh_TvzxCV3xyvjDwlA=w1620-h1080-s-no-gm?authuser=0"
loading="lazy"
>&lt;/p>
&lt;h2 id="值得閱讀的書">值得閱讀的書&lt;/h2>
&lt;p>對讀者而言，閱讀像是進入作者的生命，讓我們用很短的時間(幾個小時比起幾年)，高效率地從作者的視角中活過一次這段人生。每讀一本書，就像多活過一些作者歷練，在自己的生命旅程中添加一分色彩與理解。&lt;/p>
&lt;ol>
&lt;li>&lt;a class="link" href="https://www.kobo.com/tw/zh/ebook/ciEj3oHWiz6lqsEMxBVjQw" target="_blank" rel="noopener"
>《薩提爾的自我覺察練習》&lt;/a> - 讓我看見自己內心深層的想法看法，意識到自己在意/不在乎或重要與否的判斷拿捏，我會更「聚焦在現在與未來，詢問過去是了解行為模式、成功/失敗經驗」。&lt;/li>
&lt;li>&lt;a class="link" href="https://www.kobo.com/tw/zh/ebook/5RiVxFucFjSJtK2j553IXg" target="_blank" rel="noopener"
>《一流的人如何駕馭自我》&lt;/a> - 是一本激發我想持續向一流人學習管理熱情，引述書中有一個章節標題，我真的非常喜歡的說法：「從挖掘熱情到實踐熱情：需要的是按部就班到全力以赴」，破除自己對於熱情事情的迷失，給出實際的指引，但更多成功的關鍵還是操之在自己身上。&lt;/li>
&lt;li>&lt;a class="link" href="https://kobo.com/tw/zh/ebook/urMA32eJMTSmIJXnnLLCiw" target="_blank" rel="noopener"
>《我決定，生活只留下對的人》&lt;/a> - 會推薦這本書中有談到，人是變動的，不同階段有不同的渴望，更重要的不是對方是誰，而是你需要什麼。和我看過大人學一篇文章，很有共鳴剛好很貼近這本書主體，這篇文章是&lt;a class="link" href="https://www.darencademy.com/article/view/id/16754" target="_blank" rel="noopener"
>「人生穩當的交友策略，不外乎就是親近「螞蟻」但遠離「蚱蜢」&lt;/a>裡面談的概念很相近，「每個人的人生成就，除了跟能力和認知邊界有關，也跟「周圍都是什麼樣的人」息息相關」，實際選擇思考過後真的影響我很大。&lt;/li>
&lt;li>&lt;a class="link" href="https://www.kobo.com/tw/zh/ebook/TGUP4inhczCwag4Oq0uwsQ" target="_blank" rel="noopener"
>《大人學選擇：成熟大人的獨立思考術》&lt;/a> - 人生有很多課題需要「選擇」真的是一件很難的事，介紹很多人生、職場、人際關係等之間的各種選擇的思維方向，提到每個人若可以常把人生後續的機會最大化，有更多餘裕牌局會越來越好，也會有更多的選擇不會只有單選題，我更多體悟是，每個選擇要都是有意義的，更多的時候是要相信自己的「選擇」。&lt;/li>
&lt;li>&lt;a class="link" href="https://www.kobo.com/tw/zh/ebook/CvoePbm2wjesiaHTXe6EBg" target="_blank" rel="noopener"
>《贏在邏輯思考力：玩一場擴張邊界的遊戲》&lt;/a>- 我常常輸給自己的過去觀點和死板的印象，透過這本書知道可以更深度有邏輯，讓自己更願意試著擴張邊界，用邏輯思考他人冰山以下的部分，去理解不理解的，用更寬廣的角度去看，不一樣不是唱反調，不一樣只是不一樣，但我們要如何應對與處理人和各種情境。&lt;/li>
&lt;/ol>
&lt;h2 id="值得感謝的人">值得感謝的人&lt;/h2>
&lt;p>2023 對我來說是一個很特別的一年，花非常多時間在梳理思緒成熟的開始，去年底接受到前輩給我的一個人生思維課題：「在人生列車上，社會化過程中的轉換心態，對於下一步的選擇都會仔細評估考量，何不多想想下下一步的自己？」&lt;/p>
&lt;p>就這個議題徘徊在我腦海盤旋，讓我很想好好探索好自己對於，所謂「認知邊界」的廣度，這邊指的是我們根據過去人生經驗而對世界所描繪出的規則與界限[1]能看見多少？ 決定要好好探索，雖然這段路崎嶇需要足夠時間，但能好好想想「找到自己人生定位」[2]，我有沒有更多對於想要嘗試的下下一步和中長期對自己的想像？此時此刻回頭思考這段慢慢建構的過程，大概是這一整年最棒的事。&lt;/p>
&lt;ul>
&lt;li>[1] &lt;a class="link" href="https://www.darencademy.com/article/view/id/16525" target="_blank" rel="noopener"
>大人學 - 你的人際關係多成功，取決於認知邊界的廣度&lt;/a>&lt;/li>
&lt;li>[2] &lt;a class="link" href="https://womany.net/read/article/11211" target="_blank" rel="noopener"
>給28歲自己的一封信：找到自己的人生定位&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>年初開始做了探索，其實真的太喜歡大人學的文章與 Podcast，更深度好好聆聽多次的一堂課很推薦，&lt;a class="link" href="https://shop.darencademy.com/product/view/id/116" target="_blank" rel="noopener"
>用經營公司的思維經營你的人生&lt;/a>，這堂課幫助我釐清現況，督促自己做出合宜選擇。其中我覺得最核心的是 - 最後一堂課，談到的「增長」若自己希望將來有一天，是真的可以「優雅」地做你想做的事情，開始有了人生願景，那增長將讓你得以一路穩當的往那邊邁進，增長還能幫我們帶來另一個東西，這跟情緒穩定很有關係，那就是「餘裕」，影響我持續探索如何穩定以終為始設定好自己的目標後，建立這樣的能力。&lt;/p>
&lt;p>另外因緣際會，剛好因為&lt;a class="link" href="https://www.instagram.com/shiashia.pro/" target="_blank" rel="noopener"
>薩提爾教練-蝦蝦&lt;/a>，邀請我擔任薩提爾教練 1 對 1 的夥伴，藉這個機會認識了「薩提爾教練模式（Satir Coaching Model）」是一種結合了『教練方法』+『薩提爾冰山理論』，深具溫度和專業度的對話方式，覺察夥伴深層的自我。就想藉由這個機會想幫助自己、透過「復盤」不同的人生課題體驗過程，去探索、搞懂自己是誰、自己想要的人生劇本是什麼，及「以終為始」的終點在哪裡？ 透過我自己整年下來體驗人生的不同課題的答案，透過深度談話覺察自己的復盤過程中，更了解「自己的增長」與勾勒出更清晰明確「屬於自己此刻的答案」！ (若你想探索內心深層的想法，及心中的道路/選擇，私心推薦和蝦蝦預約：&lt;a class="link" href="https://shiashia.pro/" target="_blank" rel="noopener"
>https://shiashia.pro/&lt;/a>）&lt;/p>
&lt;p>追逐完美過程，我知道了我「在做每一件事情之前，前置作業時間很長，思考清楚為何而做並且計畫以後，就會盡全力做到自己認為的最好。」在 2024 開始的長期計劃的事情與正在「前進」的方向，都更有了意義！&lt;/p>
&lt;h2 id="2024-展望">2024 展望&lt;/h2>
&lt;ol>
&lt;li>持續加強英文能力，達到溝通及書寫上都能夠流暢的程度。&lt;/li>
&lt;li>建立晨間習慣，開始建立閱讀習慣後，發現自己能用瑣碎的時間讀書，累積下來的閱讀時間非常可觀，但是更嘗試過早上閱讀效果比任何時刻好，我希望新的一年每 1-2 週讀一本的目標。&lt;/li>
&lt;li>每日寫好筆記日誌，追蹤個人專案成長紀錄以及擴建第二大腦的累積。&lt;/li>
&lt;li>更新停擺已久的部落格，強迫自己多撰寫文章及補齊之前技術研究的心得分享。&lt;/li>
&lt;li>完成先前未完成的專業認證。&lt;/li>
&lt;li>經營攝影回顧展-2024開始籌備年，建立好策展規劃與通路 Photography Blog (&lt;a class="link" href="https://yiyanglin.tw/" target="_blank" rel="noopener"
>https://yiyanglin.tw/&lt;/a>)。&lt;/li>
&lt;li>加強時間管理跟分配，留給更多的時間做自己想做的事以及延續興趣培養。&lt;/li>
&lt;li>和夥伴製作 Podcast 關於科技人日常的節目。&lt;/li>
&lt;li>AI 大腦應用於生活，增強自己對於 Prompt Engineering 提示工程的研究與服務串接，希望我日常使用的工作流程能都透過這些工具，建立好完整的系統。&lt;/li>
&lt;/ol></description></item><item><title>2022 年度回顧 / 2023 年展望</title><link>https://blog.yylin.io/year/2022-retrospect-and-prospect/</link><pubDate>Sat, 31 Dec 2022 13:33:28 +0800</pubDate><guid>https://blog.yylin.io/year/2022-retrospect-and-prospect/</guid><description>&lt;p>2022 年有非常多的時間進行選擇與尋找定位，雖然過程很不容易，但今年還是很充實的過完這一年，很多朋友開始在年底都會有復盤自己的習慣，想過好下一年，那麼知道今年你是怎麼過的？或許對自己會有很大的幫助。本篇是個人於 2022 年的記錄以及對於未來的展望。&lt;/p>
&lt;p>&lt;img src="https://blog.yylin.io/year/2022-retrospect-and-prospect/images/01.png"
width="1080"
height="608"
srcset="https://blog.yylin.io/year/2022-retrospect-and-prospect/images/01_hu4b94eabded4d0fc2abf8a6c6d57fe797_994522_480x0_resize_box_3.png 480w, https://blog.yylin.io/year/2022-retrospect-and-prospect/images/01_hu4b94eabded4d0fc2abf8a6c6d57fe797_994522_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
>&lt;/p>
&lt;h5 id="2022-年回顧--2022-年回顧2022-年回顧">&lt;a class="link" href="#2022-%e5%b9%b4%e5%9b%9e%e9%a1%a7" title=" 2022 年回顧"
>&lt;/a>2022 年回顧&lt;/h5>
&lt;ul>
&lt;li>轉職 &lt;code>SSA(Specialist Solution Architect/領域專家解決方案架構師)&lt;/code>滿一年多了，雖然花很多時間與團隊在對於角色定位與支援上安排，主要和 SA 關注在不同的面向，更重於在解決方案中針對某一領域的問題提出相對應的系統架構。舉例來說更重於思考實際客戶系統架構需求或系統設計面，並和售後團隊有更密切接觸。&lt;/li>
&lt;li>疫情開放後，參與入職來首次公司舉辦的 &lt;code>Outing&lt;/code> 活動，讓售前/售後團隊，能有更進一步的團隊對話與技術互動。&lt;/li>
&lt;li>嘗試考 &lt;code>AWS Solution Architect Associate (SAA-C03)&lt;/code>剛好報名前題庫改版，補好多不同的題目，閱讀考古題比較沒有新的題庫，可惜最終分數差 3題只好明年再來重考(很想拿到)，年底公司指標只好直接趕緊補考 &lt;code>AWS Certified Cloud Practitioner (CLF-C01)&lt;/code>裸考意外簡單很多。&lt;/li>
&lt;li>開始維護公司 &lt;code>AAP POC&lt;/code> 專案重拾之前合作送 &lt;code>PR (Pull Request)&lt;/code>的狀態，希望能持續加更多 Demo 應用場景幫助團隊。&lt;/li>
&lt;li>成為薩提爾教練模式 Satir Coaching Model 的『夥伴』，並針對同一個議題進行 2 次對話，透過練習過程，像是跟一面鏡子進行自我對話的方法，期待後續的主題，感謝 COSCUP 認識的夥伴邀約。&lt;/li>
&lt;li>完成每季定期 3 篇 &lt;code>Blog&lt;/code> 希望能繼續保持，讓自己每個階段都有收斂與查閱資訊的地方。&lt;/li>
&lt;li>疫情開放，和夥伴快速安排出國「首爾」攝影紀實之後在補充一篇文章。&lt;/li>
&lt;li>記得 2022 年初趁著夥伴對於 &lt;code>中級山&lt;/code>、&lt;code>縱走山行&lt;/code>心情還溫熱，大夥討論來訂下 2022 年度指標清單挑戰之一「嘉明湖」，最後一起報名 &lt;code>台灣 368 商業團&lt;/code> 和夥伴們一起走過並多拿下兩座百岳，我的 ⛰5th #向陽山 3,603m, ⛰6th #三叉山 3,496m。&lt;/li>
&lt;li>挑戰成功「&lt;a class="link" href="%28https://taipeigrandtrail.travel.taipei/%29" >臺北大縱走尋寶石任務&lt;/a>」七段任務，最終和兩位夥伴一起完成所有縱走，感謝從 2021-2022 一起假日遠離都市來健行的夥伴們!&lt;/li>
&lt;li>個人興趣培養與成長，持續更精進自我攝影觀念與技巧，這次不拍山岳風景社攝影，來參加 &lt;a class="link" href="https://www.instagram.com/4samantha" target="_blank" rel="noopener"
>@4samatha&lt;/a> 舉辦的&lt;code>人像工作坊&lt;/code>和與 &lt;a class="link" href="https://www.instagram.com/jerrythepopper/" target="_blank" rel="noopener"
>@jerrythepopper&lt;/a> 兩位攝影師交流，從人像實戰體驗培養美感的方式，並記住自己要多嘗試一點減法攝影，期待明年有更多不一樣的作品。&lt;/li>
&lt;li>自我盤整之外，嘗試今年做了一部攝影 72 張照片回顧，透過鏡頭記錄自己的每一刻，感謝夥伴&lt;a class="link" href="https://www.youtube.com/channel/UCI2WLm8J8y_Upm0dVdGZFQg/videos" target="_blank" rel="noopener"
>紙片模型&lt;/a>一同協助。&lt;/li>
&lt;/ul>
&lt;h5 id="2023-年展望--2023-年展望-2023-年展望">&lt;a class="link" href="#2023-%e5%b9%b4%e5%b1%95%e6%9c%9b" title=" 2023 年展望 "
>&lt;/a>2023 年展望&lt;/h5>
&lt;ul>
&lt;li>希望英文交流能變更好，疫情趨緩會有更多跨國年會與工作上同事交流，參加團隊聚會時希望能跟他們說一些日常交流&lt;/li>
&lt;li>安排每週固定去健身房，轉換職涯後都沒繼續&lt;/li>
&lt;li>投稿&lt;strong>社群技術&lt;/strong>演講 2 場&lt;/li>
&lt;li>完成先前未完成的 Red Hat 證照&lt;/li>
&lt;li>攝影/紀實部落格能有效經營，建立好 IG 專頁，出國機會更多，需要工作流程讓照片穩定輸出&lt;/li>
&lt;/ul>
&lt;h3 id="photography--2022-recap">Photography | 2022 Recap&lt;/h3>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/di-M9AdRiwk"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;h3 id="related-posts">Related Posts&lt;/h3>
&lt;ul>
&lt;li>Photography Blog (&lt;a class="link" href="https://medium.com/yiyang-lins-life" target="_blank" rel="noopener"
>https://medium.com/yiyang-lins-life&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>透過自動化進行 TWGCB 臺灣政府組態標準合規 - 邏輯檢查</title><link>https://blog.yylin.io/ansible/twgcb/</link><pubDate>Sat, 19 Nov 2022 12:00:40 +0800</pubDate><guid>https://blog.yylin.io/ansible/twgcb/</guid><description>&lt;h2 id="-概述-">/ 概述 /&lt;/h2>
&lt;p>TWGCB 由行政院國家資通安全會報技術服務中心發佈，政府組態基準(Government Configuration Baseline，簡稱GCB)目的在於規範資通訊設備 (例如：個人電腦、伺服器主機及網通設備等) 的一致性安全設定 (例如：密碼長度、更新期限等)，以降低成為駭客入侵管道，進而引發資安事件之風險。(擷取資料: &lt;a class="link" href="https://www.nccst.nat.gov.tw/GCB" target="_blank" rel="noopener"
>行政院國家資通安全會報技術服務中心&lt;/a>)。&lt;/p>
&lt;h3 id="twgcb-發展與目的">TWGCB 發展與目的&lt;/h3>
&lt;p>政府主要目的期望藉由提供電腦作業環境一致性資安防護基準與實作指引，供政府機關及企業能透過建立安全組態，提升資安防護能力。&lt;/p>
&lt;p>本文以提供 &lt;code>TWGCB for Red Hat Enterprise Linux 8&lt;/code> 作業系統為例，GCB 主要規範機關內作業系統有一致性安全設定，以降低成為駭客入侵管道，進而引發資安事件之風險：&lt;/p>
&lt;ol>
&lt;li>發展一致性安全組態設定&lt;/li>
&lt;li>提升作業系統使用安全性&lt;/li>
&lt;/ol>
&lt;p>共計 292 項規定，分基本項目(243項)，防火牆(18項)以及SSH服務(31項)&lt;/p>
&lt;ul>
&lt;li>
&lt;p>主要參考下列二項國際知名資訊安全標準：&lt;/p>
&lt;ul>
&lt;li>CIS (Center for Internet Security) RHEL 8 Benchmark&lt;/li>
&lt;li>DISA(Defense Information Systems Agency) RHEL 8 STIG 以及 TWGCB for RHEL 5 相關內容&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://blog.yylin.io/ansible/twgcb/img/01.png"
width="961"
height="723"
srcset="https://blog.yylin.io/ansible/twgcb/img/01_hud6584220a655dc6a45384a3f1945fff9_203206_480x0_resize_box_3.png 480w, https://blog.yylin.io/ansible/twgcb/img/01_hud6584220a655dc6a45384a3f1945fff9_203206_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="132"
data-flex-basis="319px"
> &lt;img src="https://blog.yylin.io/ansible/twgcb/img/02.png"
width="963"
height="722"
srcset="https://blog.yylin.io/ansible/twgcb/img/02_hu347fcb8edb75ab1e3bc8921a22fa1bad_215596_480x0_resize_box_3.png 480w, https://blog.yylin.io/ansible/twgcb/img/02_hu347fcb8edb75ab1e3bc8921a22fa1bad_215596_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>擷取至 &lt;a class="link" href="https://download.nccst.nat.gov.tw/attachfilegcb/TWGCB-01-008_Red%20Hat%20Enterprise%20Linux%208%E6%94%BF%E5%BA%9C%E7%B5%84%E6%85%8B%E5%9F%BA%E6%BA%96%E8%AA%AA%E6%98%8E%E6%96%87%E4%BB%B6v1.0_1100924.pdf" target="_blank" rel="noopener"
>TWGCB-01-008(v1.0)-政府組態基準說明文件&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="-引入前思考-">/ 引入前思考 /&lt;/h2>
&lt;p>各企業為確保有所本能符合政府合規檢核基準，企業資安維運團隊的將要思考，如何採用規範及當前大量基礎設施，包含三大面向：&lt;/p>
&lt;ol>
&lt;li>如何定義系統組態合規標準條例(不影響企業服務)&lt;/li>
&lt;li>大範圍檢查及修正的人力成本？&lt;/li>
&lt;li>人工製作的系統組態稽核報告？&lt;/li>
&lt;/ol>
&lt;p>當前市面上有很多針對 TWGCB 的一些合規 Solution 和產品，但要符合因應企業內部不停需求及&lt;code>客製化&lt;/code>的方面相對比較困難，而企業能做什麼：&lt;/p>
&lt;ul>
&lt;li>需要找一個專家顧問團隊(如 Red Hat Consultant 團隊)，可針對企業環境與既有資安團隊定義的規範重新評估，進行訪談企業內所它需要的一個自動化對應腳本及如何引入 TWGCB 合規機制。&lt;/li>
&lt;li>列舉針對企業不同作業系統做規範定義 (e.g RHEL8)[補充]，顧問團隊在這些規則裡面去取用企業資安團隊能夠接受的相關條例。&lt;/li>
&lt;li>將這些規則列舉並透過後續自動化方式建立，達到 IT 維運團隊能夠透過一連串自動化部署及邏輯檢查，以更加速日常合規檢核及後續對應報表需求的最終目的。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>補充: 其他作業系統，若要評估資安條例及防範規範檢查，可以參考&lt;a class="link" href="https://blog.yylin.io/ansible/openscap/" target="_blank" rel="noopener"
>實現 OpenSCAP 自動化邏輯檢查&lt;/a> 文章介紹的 OpenSCAP 工具。&lt;/p>
&lt;/blockquote>
&lt;h2 id="-透過-ansible-結合-twgcb-實現系統自動化合規檢查-">/ 透過 Ansible 結合 TWGCB 實現系統「自動化」合規檢查 /&lt;/h2>
&lt;p>上述文中釐清企業狀態與需求，這邊列出當前引入 TWGCB 政府組態規範目標：&lt;/p>
&lt;ul>
&lt;li>提供一套自動檢測&lt;/li>
&lt;li>能夠定時執行&lt;/li>
&lt;li>確認合規的完整報表(各項合規細節說明)&lt;/li>
&lt;/ul>
&lt;p>在以下展示中我們透過影片方式，介紹如何透過 AAP 與 客製化 TWGCB腳本來達成自動合規「邏輯檢查」報表產出：&lt;/p>
&lt;ul>
&lt;li>AAP 自動化工具&lt;/li>
&lt;/ul>
&lt;p>Red Hat Ansible Automation(簡稱 AAP) 可以協助維運團使 IT 環境和流程的各個方面實現自動化，而 AAP 則可以與其他服務整合。自動化工具架構如下圖，我們會有一台 Ansible Controller，它是一個中控平台中心，我們管理對象包含我們企業內部 On-Premise 各環境作業系統節點。&lt;/p>
&lt;ul>
&lt;li>定義客製化腳本 | 整合 TWGCB 組態檢查&lt;/li>
&lt;/ul>
&lt;p>自動化工具需要透過腳本運行，顧問團隊透過訪談及列舉需求，開發出企業客戶所需的專業腳本，企業維運人員透過 UI 介面方便管理者後續操作及工作流程串接，運行後續提供「結果報告」，協助企業釐清當前環境依據 TWGCB Profile 是否符合對應規範及條例，讓企業有檢驗後依據，並能將此報告交由企業內部資安團隊進行後續修正依據。&lt;/p>
&lt;p>&lt;img src="https://blog.yylin.io/ansible/twgcb/img/03.png"
width="1289"
height="850"
srcset="https://blog.yylin.io/ansible/twgcb/img/03_hu9ff8c18a355c3f28cc4488abe913d01b_171120_480x0_resize_box_3.png 480w, https://blog.yylin.io/ansible/twgcb/img/03_hu9ff8c18a355c3f28cc4488abe913d01b_171120_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="151"
data-flex-basis="363px"
>&lt;/p>
&lt;h3 id="展示---產出-rhel-8-主機組態設定檢查報表">展示 - 產出 RHEL 8 主機組態設定檢查報表&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>作業目的：
自動至 RHEL8 主機進行 TWGCB 檢查項目，結果整合於 HTML 報表中呈現。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>檢查項目：
腳本以 TWGCB 說明文件項目規範， 針對主機「檢查邏輯」結果&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>首先，配置 TWGCB Check Report 於 Ansible Automation Platform 環境，一鍵點選執行就會進行節點 TWGCB 邏輯檢查&lt;/p>
&lt;p>&lt;img src="https://blog.yylin.io/ansible/twgcb/img/04.png"
width="1207"
height="643"
srcset="https://blog.yylin.io/ansible/twgcb/img/04_hu60e577c5d7bb63275dc28fd9b434cec4_149018_480x0_resize_box_3.png 480w, https://blog.yylin.io/ansible/twgcb/img/04_hu60e577c5d7bb63275dc28fd9b434cec4_149018_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="187"
data-flex-basis="450px"
>&lt;/p>
&lt;p>運行後，產出報表呈現包括：&lt;/p>
&lt;ul>
&lt;li>查詢主機狀態 / 時間 / 系統版本 資訊&lt;/li>
&lt;li>TWGCB - ID / 檢查結果&lt;/li>
&lt;li>依據組態基準項目進行 「類別」分類&lt;/li>
&lt;li>檔案行首的「+」符號 =&amp;gt; 可以確認結果狀態與資訊&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://blog.yylin.io/ansible/twgcb/img/05.png"
width="1912"
height="934"
srcset="https://blog.yylin.io/ansible/twgcb/img/05_hu92c189cefd195a4ea632bbaddf368070_452776_480x0_resize_box_3.png 480w, https://blog.yylin.io/ansible/twgcb/img/05_hu92c189cefd195a4ea632bbaddf368070_452776_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="204"
data-flex-basis="491px"
>&lt;/p>
&lt;blockquote>
&lt;p>實際展示影片 (請打開&lt;code>字幕&lt;/code>)&lt;/p>
&lt;/blockquote>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/XPlo67IBtQw"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;h3 id="補充展示---運行修復-rhel-主機設備規則並比對先前報表結果">補充展示 - 運行修復 RHEL 主機設備規則並比對先前報表結果&lt;/h3>
&lt;blockquote>
&lt;p>邏輯檢查修復部分，需要經過企業內部資安團隊與當前服務不衝突情況下評估，並藉由專業顧問團隊同時釐清需求，才會進行大量修復情境，以下展示以「網路設定」條例做修復展示。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>
&lt;p>作業目的：
自動至 RHEL8 主機進行 TWGCB 檢查，類型「網路設定」項目，結果進行修復。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>檢查項目：
針對邏輯檢測主機，結果「TIPC協定、無線網路介面」資訊，進行自動化腳本關閉修復。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>首先配置針對 &lt;code>TWGCB-01-008-0129&lt;/code> 及 &lt;code>TWGCB-01-008-0130&lt;/code> 條例撰寫對應修復 Task，並且透過 AAP 一鍵運行修復：&lt;/p>
&lt;p>&lt;img src="https://blog.yylin.io/ansible/twgcb/img/06.png"
width="1034"
height="523"
srcset="https://blog.yylin.io/ansible/twgcb/img/06_hu985a02afff0d10678c06c6f7b9955442_121485_480x0_resize_box_3.png 480w, https://blog.yylin.io/ansible/twgcb/img/06_hu985a02afff0d10678c06c6f7b9955442_121485_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="197"
data-flex-basis="474px"
>&lt;/p>
&lt;p>重新運行 &lt;code>TWGCB Check Report&lt;/code> 後比對邏輯檢查結果，發現條例內容已經做修復，並顯示 PASS 資訊：
&lt;img src="https://blog.yylin.io/ansible/twgcb/img/07.png"
width="1083"
height="515"
srcset="https://blog.yylin.io/ansible/twgcb/img/07_hufb34822caa4fbf68cba40044391a37d1_168446_480x0_resize_box_3.png 480w, https://blog.yylin.io/ansible/twgcb/img/07_hufb34822caa4fbf68cba40044391a37d1_168446_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="210"
data-flex-basis="504px"
>&lt;/p>
&lt;blockquote>
&lt;p>實際展示影片 (請打開&lt;code>字幕&lt;/code>)&lt;/p>
&lt;/blockquote>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/qTY95XwzhzQ"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;h2 id="-結論-">/ 結論 /&lt;/h2>
&lt;p>我們可以透過台灣 GCB 組態基準進行邏輯檢查，透過 Ansible 客製化 Playbook 腳本提供大量主機節點，對企業客戶來說條例檢查過程 Output log 資訊很重要，Red Hat 專業顧問團隊將企業需求的客製化報表提供客戶，有完整可視化條例資訊查看，更能幫助企業資安團隊，確認當前環境使用的套件及安裝組態做清查及彙整，並透過每次運行報告清單中變化，來查閱這些變化是不是符合流程申請，以企業客戶需求導向給一個範本出來，讓客戶有一個基本的概念與依據組態管理自動化檢驗擁有完整報告，如此將可大幅降低資安風險，即可延伸探討後續修正及相對應資安防範措施。&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://www.mss.com.tw/gcb.html" target="_blank" rel="noopener"
>https://www.mss.com.tw/gcb.html&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>透過自動化進行 TWGCB 臺灣政府組態標準合規 - 邏輯檢查</title><link>https://blog.yylin.io/ansible/twgcb/</link><pubDate>Sat, 19 Nov 2022 12:00:40 +0800</pubDate><guid>https://blog.yylin.io/ansible/twgcb/</guid><description/></item><item><title>Deep dive - OpenShift 叢集節點跨網段架構規劃</title><link>https://blog.yylin.io/openshift/security-zones/</link><pubDate>Tue, 27 Sep 2022 12:00:40 +0800</pubDate><guid>https://blog.yylin.io/openshift/security-zones/</guid><description>&lt;h2 id="概述-為什麼有這樣需求">/概述/ 為什麼有這樣需求？&lt;/h2>
&lt;p>近期剛好接觸客戶需求，希望能透過「單一叢集OpenSihft 運作於跨網段區域」上架構需求，希望有基於能限制不同角色，訪問流量進入 OpenShift 叢集只允許使用特定功能，包含以下需求：&lt;/p>
&lt;ol>
&lt;li>能限制只有叢集管理人員/開發團隊，能直接存取操作 OpenShift 叢集於內部網路中，因此叢集對應的內部服務、API、儲存等，能獲得更多更安全性。&lt;/li>
&lt;li>將提供外部應用程式/服務，隔離於對外 Security Zones 區域，並限制只允許特定的 Router 使用某些特定功能(例如：單純網站服務運行, APP 後端服務)等。&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>主要目的：希望透過 Shard Route 負責，在不同 IP 地址，讓內部和外部使用者訪問不同的 Router 以達到 DMZ 與 OCP 訪問限制，來減少成本下能更加提升叢集運作安全性。&lt;/p>
&lt;/blockquote>
&lt;p>補充 - 更多場景情境，歡迎大家可以參考 Luis Javier Arizmendi Alonso 分享針對 OpenShift 於 Security Zones 系列文章 - &lt;a class="link" href="https://itnext.io/security-zones-in-openshift-worker-nodes-part-i-introduction-4f85762962d7" target="_blank" rel="noopener"
>Security Zones in OpenShift worker nodes&lt;/a>&lt;/p>
&lt;h2 id="探討--相關架構考量">/探討/ 相關架構考量&lt;/h2>
&lt;p>先探討結論，為什麼不採用「針對 Security Zones 進行實體隔離」來達到企業內部制定相對安全標準和法規，例如直接在 DMZ 區域多部署一座 OpenShift 叢集提供對外服務(參考補充)，更直接保護叢集運行產品的應用及服務更能確保安全性，其實重點包含&lt;code>成本考量&lt;/code>還有 &lt;code>OpenShift維護成本&lt;/code>高，可能企業內部需要更多維運人員來管理不同 OpenShift 叢集上版流程、應用程式、API及相關服務配置管理等，都是總總問題。&lt;/p>
&lt;h3 id="補充---透過實體隔離方案-">/補充 - 透過&lt;code>實體隔離方案&lt;/code> /&lt;/h3>
&lt;ul>
&lt;li>有助於證明 Data Center 符合安全標準和法規&lt;/li>
&lt;li>更保護叢集 API 和 DMZ 中，不會暴露給外部 Internet&lt;/li>
&lt;li>OpenShift 維護成本高&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://blog.yylin.io/openshift/security-zones/img/01.png"
width="516"
height="593"
srcset="https://blog.yylin.io/openshift/security-zones/img/01_hud6af0256d637efc1e9fc480ef98eae1a_45911_480x0_resize_box_3.png 480w, https://blog.yylin.io/openshift/security-zones/img/01_hud6af0256d637efc1e9fc480ef98eae1a_45911_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="87"
data-flex-basis="208px"
>&lt;/p>
&lt;p>所以或許另一種選擇，透過有一個大型的 OpenShift「單一叢集跨網段架構」能使更容易維運管理及同時達到提高安全性架構，就是此次架構分享重點。&lt;/p>
&lt;blockquote>
&lt;p>這邊還是一個重點，取決於你對於當前環境規劃與架構設計需求而做選擇&lt;/p>
&lt;/blockquote>
&lt;h3 id="以下針對本文主要概述-單一叢集跨網段架構-架構圖做細部探討">以下針對本文主要概述「 &lt;code>單一叢集跨網段架構&lt;/code> 」架構圖做細部探討：&lt;/h3>
&lt;p>&lt;img src="https://blog.yylin.io/openshift/security-zones/img/02.png"
width="517"
height="496"
srcset="https://blog.yylin.io/openshift/security-zones/img/02_hub4534f67c6d5a4f6e58796ce01e74a58_78220_480x0_resize_box_3.png 480w, https://blog.yylin.io/openshift/security-zones/img/02_hub4534f67c6d5a4f6e58796ce01e74a58_78220_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="104"
data-flex-basis="250px"
>&lt;/p>
&lt;ul>
&lt;li>每座 OpenShift 叢集都應被視為僅在內部管理，而不是暴露於外部 Internet&lt;/li>
&lt;li>若劃分 Infra Nodes 創建在不同的 Zone 區域中，每個區域中提供使用者運行 Ingress 等應用及 Services 服務的 Pod&lt;/li>
&lt;li>將限制使用者無法訪問或直接使用其他叢集區域中的資源，直接保護這些節點及組件。
&lt;ul>
&lt;li>例如：Master API, Logging, Metrics, Registry 等應該運行於內部 Internet&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>針對特定 Zone 區域運行應用，如果有特定服務需求，可以使用 node-selectors 將 Pod 實體隔離到特定 Worker 節點
&lt;ul>
&lt;li>例如：上圖 Pod 跑在特定「藍色節點」上，只能單獨在藍色區域節點運行 Pod&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="單一叢集-opensihft-運作於跨網段區域">單一叢集 OpenSihft 運作於跨網段區域&lt;/h2>
&lt;p>下圖 - 為-驗證規劃 OpenShift 示意圖：&lt;/p>
&lt;p>&lt;img src="https://blog.yylin.io/openshift/security-zones/img/03.png"
width="905"
height="764"
srcset="https://blog.yylin.io/openshift/security-zones/img/03_hu4c832c4ecd980ff8588f2e4451d8a24c_86575_480x0_resize_box_3.png 480w, https://blog.yylin.io/openshift/security-zones/img/03_hu4c832c4ecd980ff8588f2e4451d8a24c_86575_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="118"
data-flex-basis="284px"
>&lt;/p>
&lt;h2 id="操作步驟">操作步驟&lt;/h2>
&lt;ol>
&lt;li>需創建對外服務的 Ingress Controller 要如何配置規範&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>Infra 節點依據網段區域定義標籤&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DNS 配置對外 External Service 使用的 WildCard&lt;/p>
&lt;/li>
&lt;li>
&lt;p>創建 Ingress Controller 指派為外部應用使用&lt;/p>
&lt;/li>
&lt;li>
&lt;p>設置 route 透過標籤指派運行於對外區域的 infra 節點&lt;/p>
&lt;p>&lt;img src="https://blog.yylin.io/openshift/security-zones/img/05.png"
width="1241"
height="576"
srcset="https://blog.yylin.io/openshift/security-zones/img/05_hu81aaa288d3453154f57d3f8367842c22_154219_480x0_resize_box_3.png 480w, https://blog.yylin.io/openshift/security-zones/img/05_hu81aaa288d3453154f57d3f8367842c22_154219_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="215"
data-flex-basis="517px"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>指定配置 Hostname 並給外部Service 解析
&lt;img src="https://blog.yylin.io/openshift/security-zones/img/06.png"
width="1115"
height="513"
srcset="https://blog.yylin.io/openshift/security-zones/img/06_hu9a0b08036f071fc3bfebf1085b32fc7b_99190_480x0_resize_box_3.png 480w, https://blog.yylin.io/openshift/security-zones/img/06_hu9a0b08036f071fc3bfebf1085b32fc7b_99190_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="217"
data-flex-basis="521px"
>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>服務與應用程式部署完成後，對外的 Router 要定義經過哪一個 Ingress 節點去提供服務&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>修改預設 Ingress Controller - default 配置不讓其他 Service 服務進入&lt;/p>
&lt;/li>
&lt;li>
&lt;p>新增對外服務的 Ingress Controller - service 如何配置&lt;/p>
&lt;p>&lt;img src="https://blog.yylin.io/openshift/security-zones/img/07.png"
width="1229"
height="508"
srcset="https://blog.yylin.io/openshift/security-zones/img/07_huebd1e6a12edf16bac67160f0ad8bb7bc_114486_480x0_resize_box_3.png 480w, https://blog.yylin.io/openshift/security-zones/img/07_huebd1e6a12edf16bac67160f0ad8bb7bc_114486_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="241"
data-flex-basis="580px"
>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="1-dns-配置對外-external-service-使用的-wildcard">1. DNS 配置對外 External Service 使用的 WildCard&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Usage&lt;/th>
&lt;th>FQDN&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Kubernetes API&lt;/td>
&lt;td>api.&amp;lt;cluster_name&amp;gt;.&amp;lt;base_domain&amp;gt;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Internal API&lt;/td>
&lt;td>api-int.&amp;lt;cluster_name&amp;gt;.&amp;lt;base_domain&amp;gt;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ingress route&lt;/td>
&lt;td>*.apps.&amp;lt;cluster_name&amp;gt;.&amp;lt;base_domain&amp;gt;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Application, External Service&lt;/td>
&lt;td>*.service.&amp;lt;cluster_name&amp;gt;.&amp;lt;base_domain&amp;gt;&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="2-將-router-固定到-infra-node">2. 將 Router 固定到 Infra Node&lt;/h3>
&lt;ul>
&lt;li>將 Infra Node 依據服務提供區 Zone 1, Zone 2，指定標籤 (範例配置, region=8, region=10)&lt;/li>
&lt;li>在 IngressController 對象的 matchLabels 中指定 Label 設置為對應 Infra Node&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc label nodes &amp;lt;INFRA_NODE&amp;gt; region=8
$ oc patch ingresscontroller/default -n openshift-ingress-operator --type=merge -p &amp;#39;{&amp;#34;spec&amp;#34;:{&amp;#34;nodePlacement&amp;#34;: {&amp;#34;nodeSelector&amp;#34;: {&amp;#34;matchLabels&amp;#34;: {&amp;#34;region&amp;#34;: &amp;#34;8&amp;#34;}}}}}&amp;#39;
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
name: default
namespace: openshift-ingress-operator
spec:
replicas: 3
nodePlacement:
nodeSelector:
matchLabels:
region: &amp;#34;8&amp;#34;
$ oc label nodes &amp;lt;INFRA_NODE&amp;gt; region=10
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>檢查節點 label 狀態&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ oc get node -A --show-labels
NAME STATUS ROLES AGE VERSION LABELS
infra-1.ocp4.lab.example.com Ready worker 60d v1.23.5+3afdacb &lt;span class="nv">region&lt;/span>&lt;span class="o">=&lt;/span>8, beta.kubernetes.io/arch&lt;span class="o">=&lt;/span>amd64,...
infra-2.ocp4.lab.example.com Ready worker 60d v1.23.5+3afdacb &lt;span class="nv">region&lt;/span>&lt;span class="o">=&lt;/span>8, beta.kubernetes.io/arch&lt;span class="o">=&lt;/span>amd64,...
infra-3.ocp4.lab.example.com Ready worker 60d v1.23.5+3afdacb &lt;span class="nv">region&lt;/span>&lt;span class="o">=&lt;/span>8, beta.kubernetes.io/arch&lt;span class="o">=&lt;/span>amd64,...
infra-4.ocp4.lab.example.com Ready worker 60d v1.23.5+3afdacb &lt;span class="nv">region&lt;/span>&lt;span class="o">=&lt;/span>10, beta.kubernetes.io/arch&lt;span class="o">=&lt;/span>amd64,...
infra-5.ocp4.lab.example.com Ready worker 60d v1.23.5+3afdacb &lt;span class="nv">region&lt;/span>&lt;span class="o">=&lt;/span>10, beta.kubernetes.io/arch&lt;span class="o">=&lt;/span>amd64,...
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="3-創建-ingress-controller-指派為外部應用使用">3. 創建 Ingress Controller 指派為外部應用使用&lt;/h3>
&lt;ul>
&lt;li>創建命名為 “Service” 的 Ingress Controller(Router) 將允許從外部訪問的應用程式或服務，引流到對應的 Ingress&lt;/li>
&lt;li>如下圖 (指定的 Label region: ‘10’ )為對外使用的網域&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ cat ingress-service.yaml
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
name: service
namespace: openshift-ingress-operator
spec:
replicas: 2
domain: service.ocp4.lab.example.com
nodePlacement:
nodeSelector:
matchLabels:
region: &amp;#39;10&amp;#39;
routeSelector:
matchExpressions:
- key: type
operator: In
values:
- service
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>這邊指定對外 External Service 使用的網域&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>設置 ingress&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc apply -f ingress-service.yaml
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="4-限制對內對外服務-ingress-controller-配置">4. 限制對內對外服務 Ingress Controller 配置&lt;/h3>
&lt;p>&lt;img src="https://blog.yylin.io/openshift/security-zones/img/04.png"
width="341"
height="459"
srcset="https://blog.yylin.io/openshift/security-zones/img/04_hu4abab21e5dcbbf8538530220842f1a4c_43342_480x0_resize_box_3.png 480w, https://blog.yylin.io/openshift/security-zones/img/04_hu4abab21e5dcbbf8538530220842f1a4c_43342_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="74"
data-flex-basis="178px"
>&lt;/p>
&lt;ul>
&lt;li>修改預設 Ingress Controller - default 配置不讓其他 Service 服務進入&lt;/li>
&lt;li>新增對外服務的 Ingress Controller - service 如何配置&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>設定 Ingress Controller - service 指定 service 服務可以進入&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc edit ingresscontroller service -n openshift-ingress-operator
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
name: service
namespace: openshift-ingress-operator
spec:
replicas: 2
domain: service.ocp4.lab.example.com
nodePlacement:
nodeSelector:
matchLabels:
region: &amp;#39;10&amp;#39;
routeSelector:
matchExpressions:
- key: type
operator: In
values:
- service
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>檢查 Ingress Controller - default 限制不讓 service 服務進入&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc edit ingresscontroller default -n openshift-ingress-operator
apiVersion: operator.openshift.io/v1
kind: IngressController
metadata:
name: service
namespace: openshift-ingress-operator
spec:
replicas: 3
domain: apps.ocp4.lab.example.com
nodePlacement:
nodeSelector:
matchLabels:
region: &amp;#34;8&amp;#34;
routeSelector:
matchExpressions:
- key: type
operator: NotIn
values:
- service
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="5-部署應用生成-route-並指定其-hostname和-label-typeservice">5. 部署應用，生成 Route 並指定其 Hostname和 Label (type=service)&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc new-project demo
$ oc new-app rails-postgresql-example
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc get pod -o wide
NAME READY STATUS RESTARTS AGE IP NODE
postgresql-1-deploy 0/1 Completed 0 2d20h 10.129.6.16 worker-3.ocp4.lab.example.com
postgresql-1-hjztg 1/1 Running 0 2d20h 10.129.4.98 worker-2.ocp4.lab.example.com
rails-postgresql-example-1-build 0/1 Completed 0 2d20h 10.129.4.97 worker-2.ocp4.lab.example.com
rails-postgresql-example-1-deploy 0/1 Completed 0 2d19h 10.129.8.9 infra-1.ocp4.lab.example.com
rails-postgresql-example-1-f8w4l 1/1 Running 0 2d19h 10.129.3.18 worker-1.ocp4.lab.example.com
rails-postgresql-example-1-hook-pre 0/1 Completed 0 2d19h 10.129.3.17 worker-1.ocp4.lab.example.com
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>在創建 route 的時候需指定 hostname，不可使用預設名稱，此部分跳過說明，可以看到如以下 route domain 為 &lt;code>.service.ocp4.lab.example.com&lt;/code> 結尾。&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc get route
NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD
rails-postgresql-example rails-postgresql-example-demo.service.ocp4.lab.example.com rails-postgresql-example &amp;lt;all&amp;gt; None
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>#指定 label 讓 rails-postgresql-example 的 route 地址與設置解析&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc label route rails-postgresql-example type=service
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="6-訪問-ap-的-route-地址確認狀態可以訪問">6. 訪問 AP 的 Route 地址，確認狀態可以訪問&lt;/h3>
&lt;ul>
&lt;li>預設應用及服務走 default 網頁會讀取不到&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc label route rails-postgresql-example type-
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.yylin.io/openshift/security-zones/img/08.png"
width="1127"
height="647"
srcset="https://blog.yylin.io/openshift/security-zones/img/08_huda9aa56bc4effed2df008c35645ed447_142356_480x0_resize_box_3.png 480w, https://blog.yylin.io/openshift/security-zones/img/08_huda9aa56bc4effed2df008c35645ed447_142356_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="174"
data-flex-basis="418px"
>&lt;/p>
&lt;ul>
&lt;li>增加外部服務對應 label (如範例 type=service)&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc label route rails-postgresql-example type=service
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.yylin.io/openshift/security-zones/img/09.png"
width="1187"
height="683"
srcset="https://blog.yylin.io/openshift/security-zones/img/09_hufbd81718645c2c061487964a68caad0a_251451_480x0_resize_box_3.png 480w, https://blog.yylin.io/openshift/security-zones/img/09_hufbd81718645c2c061487964a68caad0a_251451_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="173"
data-flex-basis="417px"
>&lt;/p>
&lt;h2 id="延伸討論">延伸討論&lt;/h2>
&lt;ul>
&lt;li>本次無討論 Application, External Service 資源放置問題&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>是否建議將屬於 DMZ 區的 Pod 放置於屬於 DMZ 上配置的 Worker Node 節點？&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>因架構規劃，需多新增一個 Ingress 對外提供服務，就有憑證管理需求&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>此部分要採用 OpenShift 本身簽署的部分還是客戶額外簽署的部分？&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>DNS 跨網段拆分問題&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>若各網段有獨立DNS服務器架構情境？&lt;/p>
&lt;/blockquote>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://rcarrata.com/openshift/ocp4_route_sharding/" target="_blank" rel="noopener"
>Deep dive of Route Sharding in OpenShift 4&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://itnext.io/security-zones-in-openshift-worker-nodes-part-i-introduction-4f85762962d7" target="_blank" rel="noopener"
>Security Zones in OpenShift worker nodes — Part I — Introduction&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://blog.csdn.net/weixin_43902588/article/details/103543191?spm=1001.2014.3001.5502" target="_blank" rel="noopener"
>OpenShift 4 - Ingress、Route與Shard&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.openshift.com/container-platform/4.11/networking/configuring_ingress_cluster_traffic/configuring-ingress-cluster-traffic-ingress-controller.html#nw-using-ingress-and-routes_configuring-ingress-cluster-traffic-ingress-controller" target="_blank" rel="noopener"
>OCP4.11 - Using Ingress Controllers and routes &lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>實現 OpenSCAP 自動化邏輯檢查</title><link>https://blog.yylin.io/ansible/openscap/</link><pubDate>Sun, 25 Sep 2022 12:00:40 +0800</pubDate><guid>https://blog.yylin.io/ansible/openscap/</guid><description>&lt;h2 id="概述">概述&lt;/h2>
&lt;p>SCAP (Security Content Automation Protocol)是一包資安標準的集合。實作 SCAP 的工具有好幾種，其中一個是 OpenSCAP 開源工具，運用 OpenSCAP 可做到全自動的檢查、script/ansible playbook的報告與修復。但「修復」這段不太可能全自動，需要人為判斷要不要修復會不會與公司定義的規則互相衝突，否則完全聽從某些嚴格的 SCAP Rules，派下去之後反而造成維運及開發團隊環境配置衝突，導致相關影響及不便性。&lt;/p>
&lt;h2 id="透過-openscap-和-satellite-實現系統合規檢查">透過 OpenSCAP 和 Satellite 實現系統合規檢查&lt;/h2>
&lt;p>在 Red Hat Satellite 中，包含可以配置 OpenSCAP 項目提供的工具用於實施安全合規性檢查。有關 OpenSCAP 的更多信息，可以參見Guide to the Secure &lt;a class="link" href="https://static.open-scap.org/ssg-guides/ssg-rhel7-guide-cui.html#!" target="_blank" rel="noopener"
>Configuration of Red Hat Enterprise Linux 7&lt;/a>
和 &lt;a class="link" href="http://static.open-scap.org/ssg-guides/ssg-rhel8-guide-cui.html#!" target="_blank" rel="noopener"
>Guide to the Secure Configuration of Red Hat Enterprise Linux 8&lt;/a>。通過 Satellite Web UI，可以在 Red Hat Satellite 管理的所有主機上進行計劃的合規性檢查和直接查看對應報告。&lt;/p>
&lt;p>Red Hat Ansible Automation(簡稱 AAP) 可以協助維運團使 IT 環境和流程的各個方面實現自動化，而 AAP 則可以與其他服務整合。在以下實驗中我們透過影片方式，介紹如何透過 AAP 與 Satellite 來達成OpenSCAP的自動合規邏輯檢查：&lt;/p>
&lt;p>執行主要步驟包含：&lt;/p>
&lt;ol>
&lt;li>在 Red Hat Satellite 中定義 OpenSCAP 檢查策略&lt;/li>
&lt;li>使用 Red Hat Ansible Automation Platform 於系統主機上大量運行 OpenSCAP 邏輯檢查掃描&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>可以參考實作詳細資訊步驟-參考： &lt;a class="link" href="https://github.com/ansible/workshops/tree/devel/exercises/ansible_smart_mgmt" target="_blank" rel="noopener"
>Automated Smart Management Workshop&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/UXs_XmyAqJE"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;h2 id="補充-openscap與資安合規生命週期">/補充/ OpenSCAP與資安合規生命週期&lt;/h2>
&lt;p>為什麼需要系統安全檢查強化工具，OpenSCAP 可以完美的參與整個資安合規的生命週期：&lt;/p>
&lt;ul>
&lt;li>評估當前系統不合規的地方&lt;/li>
&lt;li>將找到的問題，依重要性分類&lt;/li>
&lt;li>修復（需要與企業內部定義規則評估）&lt;/li>
&lt;li>產生報告&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>重覆以上輪迴直到某主機的安全強度到一可接受的程度)&lt;/p>
&lt;/blockquote>
&lt;p>更棒的是，這四階段可以通通 Ansible Automation Platform 自動化，用來解決下面的資安老問題：&lt;/p>
&lt;ul>
&lt;li>做資安檢測費時費工&lt;/li>
&lt;li>判斷問題、修復問題，容易出錯&lt;/li>
&lt;li>資安規則太多，很容易漏掉&lt;/li>
&lt;li>資安規則細節項目太多，要做好整合不容易&lt;/li>
&lt;li>人工檢測，即便做成 SOP，也不容易實踐&lt;/li>
&lt;/ul>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>OpenSCAP on Github: &lt;a class="link" href="https://github.com/OpenSCAP/openscap" target="_blank" rel="noopener"
>https://github.com/OpenSCAP/openscap&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.open-scap.org/" target="_blank" rel="noopener"
>https://www.open-scap.org/&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://aap2.demoredhat.com/exercises/ansible_smart_mgmt/" target="_blank" rel="noopener"
>https://aap2.demoredhat.com/exercises/ansible_smart_mgmt/&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://blog.51cto.com/u_15127570/2712917" target="_blank" rel="noopener"
>https://blog.51cto.com/u_15127570/2712917&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>單節點 OpenShift 部署與應用探討</title><link>https://blog.yylin.io/openshift/sno-installer/</link><pubDate>Sat, 24 Sep 2022 21:40:40 +0800</pubDate><guid>https://blog.yylin.io/openshift/sno-installer/</guid><description>&lt;p>OpenShift 4.9 開始正式推出提供單節點部署（Single Node OpenShift，SNO），以支援小型、全功能的企業級Kubernetes叢集的應用，常見客戶 POC 應用需求如資料中心伺服器資源有限情況下，單節點 OpenShift 部署型態能夠更容易處理，可協助企業擴充既有應用程式開發與部署規模，以及管理相關工作流程，更支援邊緣資料資料中心的執行需求。&lt;/p>
&lt;p>單節點部署可以使用 RHACM 或者在線的安裝引導進行安装，此篇以安裝引導進行 SNO 部署說明：&lt;/p>
&lt;h2 id="1-準備好本地的安裝環境">1. 準備好本地的安裝環境：&lt;/h2>
&lt;ul>
&lt;li>本文章使用 &lt;a class="link" href="https://access.redhat.com/zh_CN/content/4218151" target="_blank" rel="noopener"
>Red Hat Virtualization&lt;/a>虛擬化環境，部署 SNO 叢集的最低配置要求如 &lt;code>Prerequisite&lt;/code> 下表資訊&lt;/li>
&lt;li>生成 SSH 密鑰(用於SSH登陸)&lt;/li>
&lt;li>配置部署的虛擬機 IP 或使用DHCP配置叢集網路及 DNS 伺服器解析&lt;/li>
&lt;/ul>
&lt;h3 id="prerequisite">Prerequisite&lt;/h3>
&lt;p>&lt;strong>主機資源要求&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>CPU&lt;/th>
&lt;th>Memory&lt;/th>
&lt;th>Disk&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>8vCPU&lt;/td>
&lt;td>16GB&lt;/td>
&lt;td>120GB&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;blockquote>
&lt;p>Requirements for installing OpenShift on a single node - &lt;a class="link" href="https://docs.openshift.com/container-platform/4.10/installing/installing_sno/install-sno-preparing-to-install-sno.html#install-sno-requirements-for-installing-on-a-single-node_install-sno-preparing" target="_blank" rel="noopener"
>minimum resource requirements&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h3 id="dns-設定">&lt;strong>DNS 設定&lt;/strong>&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Usage&lt;/th>
&lt;th>FQDN&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Kubernetes API&lt;/td>
&lt;td>api.&amp;lt;cluster_name&amp;gt;.&amp;lt;base_domain&amp;gt;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Internal API&lt;/td>
&lt;td>api-int.&amp;lt;cluster_name&amp;gt;.&amp;lt;base_domain&amp;gt;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ingress route&lt;/td>
&lt;td>*.apps.&amp;lt;cluster_name&amp;gt;.&amp;lt;base_domain&amp;gt;&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>參考 How to try out single-node OpenShift from Red Hat 安裝指南：
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/QFf0yVAHQKc"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;/li>
&lt;/ul>
&lt;h2 id="2-登入安裝-consoleredhatcomhttpsconsoleredhatcom-創建-openshift-單節點部署">2. 登入安裝 &lt;a class="link" href="https://console.redhat.com/" target="_blank" rel="noopener"
>console.redhat.com&lt;/a>, 創建 OpenShift 單節點部署&lt;/h2>
&lt;h3 id="installation---assisted-install">Installation - Assisted Install&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>開啟 &lt;a class="link" href="https://console.redhat.com" target="_blank" rel="noopener"
>https://console.redhat.com&lt;/a>，選擇 OpenShift&lt;/strong>
&lt;img src="https://i.imgur.com/Qzz1mj4.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>點擊上方 Create Cluster&lt;/strong>
&lt;img src="https://i.imgur.com/mNKB6GQ.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>選擇 Datacenter 並點擊 Create Cluster&lt;/strong>
&lt;img src="https://i.imgur.com/tGSYnXs.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>輸入 Cluster 相關參數，勾選 Install single node OpenShift&lt;/strong>
&lt;img src="https://i.imgur.com/oPwZ5kx.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Host network 部分選擇 Static network configuration&lt;/strong>
&lt;img src="https://i.imgur.com/wV0rcAv.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>輸入相關網路參數&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>此部分範例設置為 192.168.10.0/24 網段&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://i.imgur.com/SgPDkJ5.png"
loading="lazy"
>
&lt;img src="https://i.imgur.com/X9XE6Ev.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>點選 Add host&lt;/strong>
&lt;img src="https://i.imgur.com/vhYpStz.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>選擇 Minimal image file，並輸入對應 ssh public key 內容&lt;/strong>
&lt;img src="https://i.imgur.com/zJwFOr9.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>下載 Discovery ISO&lt;/strong>
&lt;img src="https://i.imgur.com/1N1LkT7.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>啟動 VM 並掛載該 ISO，等待其自動安裝與設定，完成後應該看到 Host Inventory 顯示如下&lt;/strong>
&lt;img src="https://i.imgur.com/QngzQ70.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>針對錯誤部分進行修改，此處問題為 hostname 不能為 localhost&lt;/strong>
&lt;img src="https://i.imgur.com/vEYp79z.png"
loading="lazy"
>
&lt;img src="https://i.imgur.com/TI0hOOP.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>確認沒問題後即可進行下一步&lt;/strong>
&lt;img src="https://i.imgur.com/yzBx0w6.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>最後檢查一遍設定，確認無誤後點擊 Install cluster&lt;/strong>
&lt;img src="https://i.imgur.com/sxKA3O1.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>等待安裝完畢&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>單節點安裝時間大約 40 分鐘&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://i.imgur.com/rE8Ykdw.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;img src="https://i.imgur.com/5hl2Gqc.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>安裝完成後即可根據以下連線資訊使用 Single Node OCP&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i.imgur.com/Bvn1ERs.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>最終登入 OCP 查看狀態&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i.imgur.com/tZG1QkE.png"
loading="lazy"
>
&lt;img src="https://i.imgur.com/BidpalP.jpg"
loading="lazy"
>&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ol>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=QFf0yVAHQKc&amp;amp;ab_channel=OpenShift" target="_blank" rel="noopener"
>Demo: How to try out single-node OpenShift from Red Hat&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.openshift.com/container-platform/4.10/installing/installing_sno/install-sno-preparing-to-install-sno.html" target="_blank" rel="noopener"
>Preparing to install on a single node&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.openshift.com/container-platform/4.10/installing/installing_sno/install-sno-installing-sno.html" target="_blank" rel="noopener"
>OpenShift 4.10 - Installing OpenShift on a single node&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=PE8W8OKJoXc&amp;amp;ab_channel=OpenShift" target="_blank" rel="noopener"
>OpenShift Virtualization on a Single Node Cluster&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.redhat.com/en/blog/meet-single-node-openshift-our-smallest-openshift-footprint-edge-architectures" target="_blank" rel="noopener"
>Meet single node OpenShift: Our newest small OpenShift footprint for edge architectures&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/lees07/tech-docs/blob/master/e1-sno-by-assisted-installer.md" target="_blank" rel="noopener"
>https://github.com/lees07/tech-docs/blob/master/e1-sno-by-assisted-installer.md&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=leJa9HmvdI0&amp;amp;ab_channel=RyanNix" target="_blank" rel="noopener"
>https://www.youtube.com/watch?v=leJa9HmvdI0&amp;ab_channel=RyanNix&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>COSCUP 2022 - 那些年我們在開源社群的日子 - Cloud Native Taiwan</title><link>https://blog.yylin.io/community/coscup2022/</link><pubDate>Sun, 28 Aug 2022 03:40:40 +0800</pubDate><guid>https://blog.yylin.io/community/coscup2022/</guid><description>&lt;p>&lt;a class="link" href="https://coscup.org/2022/zh-TW/" target="_blank" rel="noopener"
>COSCUP x KCD Taiwan&lt;/a>，今年終於變回實體線下活動，能透過線下活動人與人交流到處尋覓老朋友、聊現況，真的是每年最熱鬧的一刻。&lt;/p>
&lt;h2 id="完整議程-kcd-taiwan-2022-x-coscup--kubernetes-community-days-taiwan-2022">完整議程: KCD Taiwan 2022 x COSCUP | Kubernetes Community Days Taiwan 2022&lt;/h2>
&lt;ul>
&lt;li>COSCUP 2022 Agenda: &lt;a class="link" href="https://coscup.org/2022/zh-TW/session" target="_blank" rel="noopener"
>https://coscup.org/2022/zh-TW/session&lt;/a>&lt;/li>
&lt;li>KCD Taiwan 2022 Agenda: &lt;a class="link" href="https://community.cncf.io/kcd-taiwan/" target="_blank" rel="noopener"
>https://community.cncf.io/kcd-taiwan/&lt;/a>&lt;/li>
&lt;/ul>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/8rGhfmbhZqs"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;blockquote>
&lt;p>Kubernetes Community Days (KCD) 是由雲原生計算基金會 (CNCF) 支持與認證的官方社群組織活動，此會議集結來自開源和雲原生社區的使用者及技術人員，以進行教育、協作和分享。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>本次 Kubernetes Community Days Taiwan (KCD Taiwan) 是由台灣雲原生使用者社群 (Cloud Native Taiwan User Group, CNTUG) 所主辦的在地 KCD 的社群活動。其目的是透過本土社群的力量，讓更多人參與 Kubernetes 社群互相交流和學習，並以此持續發展和維持社群。&lt;/p>
&lt;/blockquote>
&lt;p>這次我們社群 &lt;a class="link" href="https://cloudnative.tw/" target="_blank" rel="noopener"
>CNTUG&lt;/a> 申請主辦台灣地區的 &lt;a class="link" href="https://community.cncf.io/events/details/cncf-kcd-taiwan-presents-coscup-x-kcd-taiwan-2022/?fbclid=IwAR3ceTLw2_Lsd8JjbrMQkuxiBC3KQq2KhvC4qhi9MG3UhdIomaZWdrhPrKY" target="_blank" rel="noopener"
>Kubernetes Community Day&lt;/a> (KCD)，KCD 為 CNCF 官方的活動，性質跟 KubeConf 有點不太一樣，KCD 主要是藉由各地區當地的社群來推廣 Cloud Native 以及 Kubernetes 文化的一個活動，所以會由各國家地區的社群來主持這個活動，而台灣地區的就是 KCD Taiwan。&lt;/p>
&lt;p>&lt;img src="https://lh3.googleusercontent.com/pw/AL9nZEVSyhHoIPq0-FpjgSI0wYT80UMjYHX03C5x7KHvSJE17pZcv_YJgfbaLn89JCRh-pUuBUBM_JXZcZYxy_KlpJM04a3ZXMRJjWoat1h7PGXl_Wrh141Z9uDk2esnwZWvpGkZqLqqjjIjz1zewTb4Xm5S=w1620-h1080-no?authuser=1"
loading="lazy"
>&lt;/p>
&lt;p>今年 KCD Taiwan 跟 COSCUP 2022 一起合作，所以可以看到 COSCUP 2022 官網會有 COSCUP x KCD Taiwan 2022 以及吉祥物，而有一個主議程軌 (7/30 AU 視聽館)是專門給 KCD Taiwan 的，有興趣的朋友可以參考&lt;a class="link" href="https://coscup.org/2022/zh-TW/session" target="_blank" rel="noopener"
>議程表&lt;/a>。&lt;/p>
&lt;h2 id="talk---那些年我們在開源社群的日子-cloud-native-taiwantalk---那些年我們在開源社群的日子-cloud-native-taiwan">Talk - 那些年我們在開源社群的日子 Cloud Native Taiwan&lt;a class="link" href="#talk---%e9%82%a3%e4%ba%9b%e5%b9%b4%e6%88%91%e5%80%91%e5%9c%a8%e9%96%8b%e6%ba%90%e7%a4%be%e7%be%a4%e7%9a%84%e6%97%a5%e5%ad%90-cloud-native-taiwan" >&lt;/a>&lt;/h2>
&lt;iframe class="speakerdeck-iframe" frameborder="0" src="https://speakerdeck.com/player/2436fceb0ba742deadd08d357c49131d" title="那些年我們在開源社群的日子 - Cloud Native Taiwan" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true" style="border: 0px; background: padding-box padding-box rgba(0, 0, 0, 0.1); margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 560px; height: 420px;" data-ratio="1.3333333333333333">&lt;/iframe>
&lt;p>今年很榮幸跟社群夥伴 &lt;a class="link" href="https://blog.phshih.com/" target="_blank" rel="noopener"
>Po-Hsien&lt;/a> 一起投稿開源新手村，投稿題目是 &lt;strong>「那些年我們在開源社群的日子 - Cloud Native Taiwan」&lt;/strong>，主要是以社群志工角度，介紹我們對於參與開源社群的一些想法，整理一些建議給想參與社群的會眾。&lt;/p>
&lt;p>&lt;img src="https://live.staticflickr.com/65535/52303613392_fb3654134a_6k.jpg"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://live.staticflickr.com/65535/52304743814_2f87221ab8_6k.jpg"
loading="lazy"
>
(照片來源: COSCUP 2022 官方相簿)&lt;/p>
&lt;p>我們認為社群就是 一群志同道合宅宅聚集而成的團體，目的為&lt;strong>分享&lt;/strong>、&lt;strong>學習&lt;/strong>、&lt;strong>推廣&lt;/strong>、&lt;strong>交流&lt;/strong>以及&lt;strong>貢獻&lt;/strong>開源技術，有點類似學校的社團一樣，大家對於共同領域有熱情，並一起投入進去的感覺。&lt;/p>
&lt;h3 id="如何參與社群如何參與社群">如何參與社群?&lt;a class="link" href="#%e5%a6%82%e4%bd%95%e5%8f%83%e8%88%87%e7%a4%be%e7%be%a4" >&lt;/a>&lt;/h3>
&lt;p>在此 Talk 中我們整理了四個參與社群的簡單步驟:&lt;/p>
&lt;ol>
&lt;li>尋找動機&lt;/li>
&lt;li>尋找管道&lt;/li>
&lt;li>參與社群&lt;/li>
&lt;li>支持與貢獻&lt;/li>
&lt;/ol>
&lt;h3 id="尋找動機尋找動機">尋找動機&lt;a class="link" href="#%e5%b0%8b%e6%89%be%e5%8b%95%e6%a9%9f" >&lt;/a>&lt;/h3>
&lt;p>顧名思義，就是尋找你想參與社群的目的或是動機，這裡可以再細分成兩步。第一步可以先找出你有興趣的領域，例如系統、程式、硬體、資安、開源、產品或是平台都可以，也可以多個。找到有興趣的領域後，第二步就是尋找你的動機跟目的，想增進技術？想擴展人脈? 想交流或是請教技術？想要貢獻技術？還是想要增加眼界？這些都可以變成你加入社群的動機，可以統整下來，並以這些目標前進，但還是需要注意，目標已不影響他人為主！&lt;/p>
&lt;h3 id="尋找管道尋找管道">尋找管道&lt;a class="link" href="#%e5%b0%8b%e6%89%be%e7%ae%a1%e9%81%93" >&lt;/a>&lt;/h3>
&lt;p>有了動機跟目的後，可以開始尋找資源，透過各種管道找到社群的資訊，這邊推薦幾種常見的管道:&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://hackmd.io/@SITCON/floss-community-list" target="_blank" rel="noopener"
>台灣開源社群推廣目錄&lt;/a>&lt;/li>
&lt;li>社群平台 (Facebook、Twitter、Slack、Telegram 等等)&lt;/li>
&lt;li>社群官方網站&lt;/li>
&lt;li>各式研討會 (SITCON/COSCUP/HITCON/iThome…)&lt;/li>
&lt;li>親朋好友或是實驗室跟學校社團&lt;/li>
&lt;/ul>
&lt;p>可以根據關鍵字或是地區來進行搜索，目前台灣有非常多的社群，可以直接參與。在這些方法中我個人很推薦參與研討會，參與研討會可以讓你見識不同領域的新技術以及認識各式各樣的公司或是社群，是一個很好的機會與人交流以及尋找自己的方向的地方，除了可以聽聽演講以外，許多社群或是公司也會有擺攤、Workshop 活動，可以多加參與進一步暸解社群以及文化。&lt;/p>
&lt;p>如果自己想要的領域比較冷門或是還沒有相關社群時，可以考慮自己創立一個社群，也許有人覺得創立社群很困難，一開始就要多大多複雜的組織架構，但其實回歸到最原始的定義，社群只是『一群對同樣領域有熱情的人組成的團體』，所以其實是可以從小團體開始經營，例如小型讀書會、聚會或是可以從建立社群平台粉專開始，等到穩定之後，再慢慢擴大規模，例如從幾個朋友之間，變成實驗室，再變成系上或是學校，甚至還可以開始跟其他社群合作或是投稿研討會增加社群能見度，都是不錯的方式。&lt;/p>
&lt;h3 id="參與社群參與社群">參與社群&lt;a class="link" href="#%e5%8f%83%e8%88%87%e7%a4%be%e7%be%a4" >&lt;/a>&lt;/h3>
&lt;p>找到適合的社群後，就可以積極的參與各項社群活動，包括:&lt;/p>
&lt;ol>
&lt;li>社群活動 (Meetup/Conference/Workshop…)&lt;/li>
&lt;li>與其他會眾交流&lt;/li>
&lt;li>於各式活動支持社群攤位&lt;/li>
&lt;li>加入社群平台社團交流&lt;/li>
&lt;li>旁聽社群定期會議&lt;/li>
&lt;li>擔任講者分享經驗 (增加自己的能見度)&lt;/li>
&lt;/ol>
&lt;p>可以多參加不同的社群，了解不同社群文化以及經營，也可以多方學習不同種類的技術，多與人交流，也許可以獲得不錯的寶貴經驗。&lt;/p>
&lt;p>不過大多數人是比較害羞內向的，在參與社群時，可能比較難以跟其他人交流，在這裡分享一個小技巧，從請教問題開始切入。一開始可以先當聽眾就好，不用刻意要找人聊天，專心參與以及聽分享，也許某一次的分享的內容你剛好很有共鳴或是有疑問，就可以去請教講者，這就是一個很好的交流切入點，有時候在與講者討論時，其他會眾也加入一起討論，就可以趁這機會多認識人，慢慢的在交流上就會更有自信，也可以提升人脈。&lt;/p>
&lt;h3 id="擔任志工擔任志工">擔任志工&lt;a class="link" href="#%e6%93%94%e4%bb%bb%e5%bf%97%e5%b7%a5" >&lt;/a>&lt;/h3>
&lt;p>若有閒暇之餘，也可以擔任社群志工，為社群經營盡一份力，志工主要負責以下這些項目:&lt;/p>
&lt;ol>
&lt;li>協助籌辦各式活動&lt;/li>
&lt;li>協助尋找講者&lt;/li>
&lt;li>參與社群定期會議&lt;/li>
&lt;li>管理社群相關營運事務 (社團、官方網站)&lt;/li>
&lt;/ol>
&lt;p>由於經營社群會佔用到一些個人的時間，因此可以根據自身狀況盡力協助，志工之間彼此互相 Cover。&lt;/p>
&lt;h3 id="如何支持及貢獻開源技術社群如何支持及貢獻開源技術社群">如何支持及貢獻開源技術社群&lt;a class="link" href="#%e5%a6%82%e4%bd%95%e6%94%af%e6%8c%81%e5%8f%8a%e8%b2%a2%e7%8d%bb%e9%96%8b%e6%ba%90%e6%8a%80%e8%a1%93%e7%a4%be%e7%be%a4" >&lt;/a>&lt;/h3>
&lt;p>在參與社群一段時間後，可以選擇協助支持或是貢獻開源技術社群，支持有許多種形式，可以選擇最適合自己的方式:&lt;/p>
&lt;ol>
&lt;li>積極社群活動 (Meetup/Conference/Workshop…)&lt;/li>
&lt;li>使用及推廣開源技術&lt;/li>
&lt;li>貢獻專案，成為 Contributor 或是 Member&lt;/li>
&lt;li>於各式活動分享相關專案或技術經驗&lt;/li>
&lt;li>擔任志工協助經營社群&lt;/li>
&lt;li>贊助社群&lt;/li>
&lt;/ol>
&lt;h3 id="參與社群後對生活及職涯的影響參與社群後對生活及職涯的影響">參與社群後對生活及職涯的影響&lt;a class="link" href="#%e5%8f%83%e8%88%87%e7%a4%be%e7%be%a4%e5%be%8c%e5%b0%8d%e7%94%9f%e6%b4%bb%e5%8f%8a%e8%81%b7%e6%b6%af%e7%9a%84%e5%bd%b1%e9%9f%bf" >&lt;/a>&lt;/h3>
&lt;p>參與社群除了能提升專業、自信以及能見度以外，我個人認為最重要的是人脈，能認識許多志同道合的朋友以及業界的夥伴，這不管在未來職涯還是生活上都很有幫助。若是參與志工，更能學習到如何組織活動、與其他人溝通及協同作業，這些都是實用且寶貴的經歷。&lt;/p>
&lt;p>套用社群朋友的一句話 &lt;strong>社群就是一個很大的「舞台」&lt;/strong>，這個舞台提供了許多能夠讓人分享、交流以及貢獻的機會，並在這些過程中，不斷學習精進，透過社群內部的交流以及社群與社群間交流，互相學習補足各領域不足的資訊，讓整個社群圈變成一個知識共同體，讓技術不斷向邁進，這是我認為社群最棒的文化。&lt;/p>
&lt;p>&lt;img src="https://lh3.googleusercontent.com/pw/AL9nZEUbyDsuT6PLFdvGM8e2KvwyquDytQbHey4-H_zj-8ThWVSUCCA3-k8goXa02dn4hElH69X1JnUet3w1PBokvykwmiuMAVUqrPXuffImGrVSNELH4NFVxSEIa1uGz8Xc5Z8VuKWPCHyDcxyoUISDrYpx=w2292-h1528-no?authuser=1"
loading="lazy"
>&lt;/p>
&lt;h3 id="referencereference">Reference&lt;a class="link" href="#reference" >&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>&lt;a class="link" href="https://hackmd.io/@SITCON/floss-community-list" target="_blank" rel="noopener"
>開源社群推廣目錄&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://ocf.tw/p/community" target="_blank" rel="noopener"
>OCF - 社群專案&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.bnext.com.tw/article/37063/BN-2015-08-16-131320-34" target="_blank" rel="noopener"
>[王景弘] 談談COSCUP：讓整個社群圈變成一個知識共同體。&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.yourator.co/articles/215?fbclid=IwAR0ENbxcYKK689wj-AX3COHxGja9KiYgSBxqX0FLwB_jKK_JoX7fcZAjfk0" target="_blank" rel="noopener"
>用社群實踐開源精神，Denny 不平凡的技術社群人生－專訪 SITCON 共同發起人 Denny Huang&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>OpenShift 啟用 GPU Operator Dashboard</title><link>https://blog.yylin.io/openshift/gpu-utilization/</link><pubDate>Tue, 28 Jun 2022 21:40:40 +0800</pubDate><guid>https://blog.yylin.io/openshift/gpu-utilization/</guid><description>&lt;h2 id="先決條件">先決條件：&lt;/h2>
&lt;ul>
&lt;li>Bastion 安裝 Helm&lt;/li>
&lt;li>當前 OpenShift 版本為 4.10+&lt;/li>
&lt;li>Nvidia GPU Operator 已經完成安裝&lt;/li>
&lt;/ul>
&lt;h2 id="啟用-nvidia-gpu-operator-usage-資訊">啟用 NVIDIA GPU Operator Usage 資訊&lt;/h2>
&lt;ol>
&lt;li>添加 helm repo:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ helm repo add rh-ecosystem-edge https://rh-ecosystem-edge.github.io/console-plugin-nvidia-gpu
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>更新 repo:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ helm repo update
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="3">
&lt;li>安裝 &lt;code>helm chart&lt;/code> 於預設 NVIDIA GPU Operator namespace:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ helm install -n nvidia-gpu-operator console-plugin-nvidia-gpu rh-ecosystem-edge/console-plugin-nvidia-gpu
$ kubectl -n nvidia-gpu-operator get all -l app.kubernetes.io/name=console-plugin-nvidia-gpu
# 啟用 plugin 執行以下 command:
$ kubectl patch consoles.operator.openshift.io cluster --patch &amp;#39;[{&amp;#34;op&amp;#34;: &amp;#34;add&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/spec/plugins/-&amp;#34;, &amp;#34;value&amp;#34;: &amp;#34;console-plugin-nvidia-gpu&amp;#34; }]&amp;#39; --type=json
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="4">
&lt;li>查看部署的資源：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc -n nvidia-gpu-operator get all -l app.kubernetes.io/name=console-plugin-nvidia-gpu
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="5">
&lt;li>驗證 plugins 是否已指定&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc get consoles.operator.openshift.io cluster --output=jsonpath=&amp;#34;{.spec.plugins}&amp;#34;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>如果未指定，則運行以下 command 以啟用 plugin：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc patch consoles.operator.openshift.io cluster --patch &amp;#39;{ &amp;#34;spec&amp;#34;: { &amp;#34;plugins&amp;#34;: [&amp;#34;console-plugin-nvidia-gpu&amp;#34;] } }&amp;#39; --type=merge
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>如果指定，則運行以下 command 以啟用 plugin：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc patch consoles.operator.openshift.io cluster --patch &amp;#39;[{&amp;#34;op&amp;#34;: &amp;#34;add&amp;#34;, &amp;#34;path&amp;#34;: &amp;#34;/spec/plugins/-&amp;#34;, &amp;#34;value&amp;#34;: &amp;#34;console-plugin-nvidia-gpu&amp;#34; }]&amp;#39; --type=json
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在 OCP Web Console 頁面中（Home &amp;gt; Overview）就可以查閱 GPU utilization:&lt;/p>
&lt;p>&lt;img src="https://docs.nvidia.com/datacenter/cloud-native/_images/gpu_overview_dashboard1.png"
loading="lazy"
>&lt;/p>
&lt;hr>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/enable-gpu-op-dashboard.html" target="_blank" rel="noopener"
>https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/enable-gpu-op-dashboard.html&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>在 ACM 透過 OpenShift-GitOps/ArgoCD 管理應用程式</title><link>https://blog.yylin.io/openshift/argocd-and-acm/</link><pubDate>Sat, 25 Jun 2022 09:40:40 +0800</pubDate><guid>https://blog.yylin.io/openshift/argocd-and-acm/</guid><description>&lt;h2 id="概述">概述&lt;/h2>
&lt;p>從 ACM 2.5 版開始正式 GA 功能，您可以透過 ApplicationSets 來配置 ArgoCD / OpenShift-GitOps ，通過單一管理平台以可擴展的方式管理您的所有 GitOps Applications。&lt;/p>
&lt;p>ApplicationSet Controller 是一個 Kubernetes Controller，它增加對 ApplicationSet CustomResourceDefinition (CRD) 的支持。&lt;/p>
&lt;p>ApplicationSet Controller 在與 Argo CD 一起安裝時，通過添加額外的功能來支持以叢集管理員為中心的場景來補充它。&lt;/p>
&lt;p>ApplicationSet Ccontroller 提供：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>使用單個 Kubernetes 清單通過 Argo CD 從一個或多個 Git 存儲庫部署多個 Application 的能力&lt;/p>
&lt;/li>
&lt;li>
&lt;p>改進了對 &lt;a class="link" href="https://blog.maxkit.com.tw/2017/09/monorepos.html" target="_blank" rel="noopener"
>monorepos&lt;/a> 的支持：在 Argo CD 的上下文中，monorepo 是在單個 Git 存儲庫中定義的多個 Argo CD Application 資源&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>我們將介紹如何將 ACM 與 OpenShift GitOps 的 ApplicationSets 連接起來，以便在託管 Cluster 中配置和部署 OpenShift GitOps Application 和 ApplicationSet。&lt;/p>
&lt;h2 id="環境配置-先決條件">環境配置-先決條件&lt;/h2>
&lt;ul>
&lt;li>我們需要使用 Operator Hub 在 ACM Hub 那座 OpenShift Cluster 中安裝 OpenShift GitOps：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ until oc apply -k https://github.com/RedHat-EMEA-SSA-Team/ns-gitops/tree/bootstrap/bootstrap ; do sleep 2; done
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>
&lt;p>參考 &lt;a class="link" href="https://docs.openshift.com/container-platform/4.9/cicd/gitops/installing-openshift-gitops.html" target="_blank" rel="noopener"
>OpenShift GitOps 的官方文件說明&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>另一方面，我們需要配置管理不同的 Cluster (e.g. Public Cloud)。在我的例子中，我使用我環境中部署 2 座 OCP Cluster 叢集，並將在這篇文章中用於部署我的 Application。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="於-openshift-gitops--argocd-配置託管叢集">於 OpenShift GitOps / ArgoCD 配置託管叢集&lt;/h2>
&lt;p>要在 ACM 中配置和鏈接 OpenShift GitOps，我們可以將一組一個或多個託管 Cluster 註冊到 Argo CD 或 OpenShift GitOps Operator 的實例。&lt;/p>
&lt;p>註冊後，我們可以使用從 ACM Hub Application Controller 的 Application 和 ApplicationSets 將我們需要部署的應用程式部署到這些叢集。然後，我們可以設置一個連續的 GitOps 環境，以在開發、暫存和生產環境中跨叢集自動化配置 Application 的一致性。&lt;/p>
&lt;ul>
&lt;li>首先，我們需要創建 cluster sets 並將託管 clusters 添加到這些 cluster sets：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ cat acmgitops/managedclusterset.yaml
apiVersion: cluster.open-cluster-management.io/v1alpha1
kind: ManagedClusterSet
metadata:
name: all-openshift-clusters
spec: {}
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>
&lt;p>將託管叢集作為導入 Cluster 添加到 ClusterSet。您可以使用 &lt;a class="link" href="https://github.com/open-cluster-management/rhacm-docs/blob/2.4_stage/clusters/managedclustersets.adoc#creating-a-managedclustersetbinding-by-using-the-console" target="_blank" rel="noopener"
>ACM Console&lt;/a> 或 &lt;a class="link" href="https://github.com/open-cluster-management/rhacm-docs/blob/2.4_stage/clusters/managedclustersets.adoc#adding-clusters-to-a-managedclusterset-by-using-the-command-line" target="_blank" rel="noopener"
>CLI&lt;/a> 導入：&lt;/p>
&lt;/li>
&lt;li>
&lt;p>創建託管 Cluster 綁定到部署 Argo CD 或 OpenShift GitOps 的 namespace&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ cat managedclustersetbinding.yaml
apiVersion: cluster.open-cluster-management.io/v1alpha1
kind: ManagedClusterSetBinding
metadata:
name: all-openshift-clusters
namespace: openshift-gitops
spec:
clusterSet: all-openshift-clusters
$ oc apply -f managedclustersetbinding.yaml
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>在託管叢集綁定中使用的 namespace 中，創建放置自定義資源以選擇一組託管叢集以註冊到 ArgoCD 或 OpenShift GitOps Operator instance：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">apiVersion: cluster.open-cluster-management.io/v1alpha1
kind: Placement
metadata:
name: all-openshift-clusters
namespace: openshift-gitops
spec:
predicates:
- requiredClusterSelector:
labelSelector:
matchExpressions:
- key: vendor
operator: &amp;#34;In&amp;#34;
values:
- OpenShift
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>注意：只有 OpenShift 叢集註冊到 Argo CD 或 GitOps Operator instance，而不是其他 Kubernetes 叢集。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>創建一個 GitOpsCluster 自定義資源以將託管叢集從放置註冊到 Argo CD 或 OpenShift GitOps 的指定的 instance：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">apiVersion: apps.open-cluster-management.io/v1alpha1
kind: GitOpsCluster
metadata:
name: argo-acm-clusters
namespace: openshift-gitops
spec:
argoServer:
cluster: local-cluster
argoNamespace: openshift-gitops
placementRef:
kind: Placement
apiVersion: cluster.open-cluster-management.io/v1alpha1
name: all-openshift-clusters
namespace: openshift-gitops
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>這使 Argo CD instance 能夠將 Application 部署到任何 ACM Hub 託管叢集中。&lt;/p>
&lt;p>正如我們從前面的示例中看到的，placementRef.name 被定義為 &lt;code>all-openshift-clusters&lt;/code>，並被指定為安裝在 argoNamespace：openshift-gitops 中的 GitOps 實例的目標叢集。&lt;/p>
&lt;p>另一方面，argoServer.cluster 規範需要 &lt;code>local-cluster&lt;/code> 值，因為將使用部署在 OpenShift 叢集中的 OpenShift GitOps，該叢集也是安裝 ACM Hub 的位置。&lt;/p>
&lt;ul>
&lt;li>幾分鐘後，我們在 ACM Hub 中生成了 GitOps Cluster CRD，我們將能夠直接從 Application 部分的 ACM Hub 控制台定義 Application 和ApplicationSet。&lt;/li>
&lt;/ul>
&lt;h2 id="從-acm-hub-部署-argocdopenshift-gitops-applicationset">從 ACM Hub 部署 ArgoCD/OpenShift GitOps ApplicationSet&lt;/h2>
&lt;p>一旦我們通過 ACM Hub 中的 GitOps Cluster CRD 啟用了 OpenShift GitOps 和 ACM 之間的整合，我們就可以直接在 ACM Hub 中部署 ApplicationSet，在一個單一的頁面中管理所有 ArgoCD Application。&lt;/p>
&lt;p>另一方面，我們還將受益於&lt;a class="link" href="https://argocd-applicationset.readthedocs.io/en/stable/Generators/" target="_blank" rel="noopener"
>ArgoCD ApplicationSets 的不同生成器的特性&lt;/a>。&lt;/p>
&lt;p>使用這些生成方式，我們可以從不同叢集中的單個 Repository 部署多個 Application，利用 ApplicationSet 為每個託管的 Cluster 的從Repository 中的配置不同對象及要部署的 Application。&lt;/p>
&lt;p>讓我們在 ACM Hub 中生成 ApplicationSet。&lt;/p>
&lt;ul>
&lt;li>使用 UI 為Application 集生成一個 ApplicationSet 示例：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://rcarrata.com/images/acmappA.png"
loading="lazy"
>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
name: acm-appsets
namespace: openshift-gitops
spec:
generators:
- clusterDecisionResource:
configMapRef: acm-placement
labelSelector:
matchLabels:
cluster.open-cluster-management.io/placement: acm-appsets-placement
requeueAfterSeconds: 180
template:
metadata:
name: &amp;#39;acm-appsets-&amp;#39;
spec:
destination:
namespace: bgdk
server: &amp;#39;&amp;#39;
project: default
source:
path: apps/bgd/overlays/bgdk
repoURL: &amp;#39;https://github.com/yylin1/ns-apps/&amp;#39;
targetRevision: single-app
syncPolicy:
automated:
prune: true
selfHeal: true
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>注意：目標 namespace 可以是 openshift-gitops。BGDK 可能會更改，但它會以這種方式離開，因為我們需要放置一個目標 namespace，即ApplicationSet 本身不需要它（Applicatio bgdk 也不需要）&lt;/p>
&lt;ul>
&lt;li>結果是在 OpenShift GitOps 中生成但由 ACM Hub 管理的 ApplicationSet：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://rcarrata.com/images/acmappB.png"
loading="lazy"
>&lt;/p>
&lt;p>正如我們所看到的，被分配到兩個不同的 Cluster ，&lt;code>bm-germany&lt;/code> 這 &lt;code>local-cluster&lt;/code> 將是 Application 部署的地方，由 ApplicationSet 管理&lt;/p>
&lt;p>Application 在之前定義 ApplicationSet 期間為每個叢集生成了與定義為 acm-appsets-placement 的 Placement 匹配的 ApplicationSet。還可以匹配 Cluster 進行 label，而不僅僅依賴於 Placement 對象。&lt;/p>
&lt;ul>
&lt;li>在生成的 Application 中，每個Application都有自己的Application、Placement 和 Cluster，我們可以檢查：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://rcarrata.com/images/acmappC.png"
loading="lazy"
>&lt;/p>
&lt;p>因為我們可以檢查 ArgoCD Application 是否正確部署並由 BM-Germany 叢集中的 ACM AppSets 的 ApplicationSet 自動管理。此外，另一個 ArgoCD Application 將用於在與 Placement 匹配的另一個 Cluster 中部署另一個 Application 。&lt;/p>
&lt;p>&lt;img src="https://rcarrata.com/images/acmappD.png"
loading="lazy"
>&lt;/p>
&lt;p>正如我們之前所描述的，兩個 ArgoCD Application 是由與定義的 Placement 匹配的 ApplicationSet 生成的。&lt;/p>
&lt;ul>
&lt;li>在 OpenShift GitOps / ArgoCD argo-controller 實例中，ACM 生成的 ApplicationSet 也生成了兩個 Argo Application ，並且為與 Placement 匹配的 ClusterSet 中管理的每個 Cluster 生成了每個 ArgoCD Application ：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://rcarrata.com/images/acmappE.png"
loading="lazy"
>&lt;/p>
&lt;blockquote>
&lt;p>注意：檢查指向在早期步驟中定義的不同託管 Cluster 的目標。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>每個 Argo ApplicationSet 管理每個託管 Cluster 中的Application ，例如在 BM-Germany Cluster 中部署 BGDK Application 。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://rcarrata.com/images/acmappF.png"
loading="lazy"
>&lt;/p>
&lt;p>此 Application 將在託管 Cluster 中部署Application 清單，在這種情況下部署 bgdk Application 清單（路由、服務、部署等）。&lt;/p>
&lt;ul>
&lt;li>在 ArgoCD/OpenShift GitOps 的設置中，在 ACM 使用 ClusterSet 管理的這些叢集。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://rcarrata.com/images/acmappG.png"
loading="lazy"
>&lt;/p>
&lt;p>這些是由 ACM Hub 中生成的 GitOps CRD 自動生成和管理的，它與託管 Cluster 對應。&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://github.com/RedHat-EMEA-SSA-Team/ns-gitops/" target="_blank" rel="noopener"
>https://github.com/RedHat-EMEA-SSA-Team/ns-gitops/&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://rcarrata.com/openshift/argo-and-acm/" target="_blank" rel="noopener"
>https://rcarrata.com/openshift/argo-and-acm/&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>CI/CD: Tekton Pipeline 實戰</title><link>https://blog.yylin.io/openshift/pipelines/</link><pubDate>Tue, 21 Jun 2022 21:40:40 +0800</pubDate><guid>https://blog.yylin.io/openshift/pipelines/</guid><description>&lt;p>OpenShift Pipelines 是一個基於 Kubernetes 資源的雲塊的持續和持續交付（持續集成和持續交付，簡稱 CI/CD）的解決方案。它通過執行執行的細節，使用 Tekton 進行跨平台的自動部署。Tekton 引入了多種標準的自定義資源定義 (CRD)，定義可跨 Kubernetes 分佈用於 CI/CD 管道。&lt;/p>
&lt;p>&lt;img src="https://www.redhat.com/cms/managed-files/container-platforms-pipelines.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="主要特性">主要特性&lt;/h2>
&lt;ul>
&lt;li>OpenShift Pipelines 是一個無服務器的 CI/CD 系統，它在獨立的容器中運行 Pipelines，以及所有需要的依賴組件。&lt;/li>
&lt;li>OpenShift Pipelines 是為開發微服務架構的非中心化團隊設計的。&lt;/li>
&lt;li>OpenShift Pipelines 使用標準 CI（pipeline）定義，這些與現有的 Kubernetes 工具集成擴展可擴展和擴展，可讓您定義和擴展 Kubernetes。&lt;/li>
&lt;li>您可以通過 OpenShift Pipelines 使用 Kubernetes （如 Source-to-Image (S2I)、Buildah、Buildpacks 和 Kaniko）構建鏡像，這些工具可以移植到任何 Kubernetes 平台。&lt;/li>
&lt;li>您可以使用 OpenShift Container Platform 開發運行（Developer Console）來創建 Tekton 資源，查看 Pipeline 的日誌，並管理 OpenShift Container Platform 設計空間中的管道。&lt;/li>
&lt;/ul>
&lt;p>在 Tekton pipeline 中有以下幾個主要的組成要素，分別是：&lt;/p>
&lt;ul>
&lt;li>PipelineResource&lt;/li>
&lt;li>Task &amp;amp; ClusterTask&lt;/li>
&lt;li>TaskRun&lt;/li>
&lt;li>Pipeline&lt;/li>
&lt;li>PipelineRun&lt;/li>
&lt;/ul>
&lt;h2 id="pipelineresource">PipelineResource&lt;/h2>
&lt;p>PipelineResource 簡單來說可以作為 task 的 input or output，而每個 task 可以有多個 input &amp;amp; output。&lt;/p>
&lt;h2 id="syntax">Syntax&lt;/h2>
&lt;p>PipelineResource 的定義中會有以下必要資訊：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>apiVersion：目前固定是 tekton.dev/v1alpha1&lt;/p>
&lt;/li>
&lt;li>
&lt;p>kind：因為這是 CRD，所以是 PipelineResource&lt;/p>
&lt;/li>
&lt;li>
&lt;p>metadata：用來辨識此 TaskRun 用的資訊，例如 name&lt;/p>
&lt;/li>
&lt;li>
&lt;p>sepc：使用 resource 的詳細資訊(例如：路徑、位址)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>type：用來指定 resource type，目前支援 git, pullRequest, image, cluster, storage, cloudevent … 等等&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>其他選填項目：&lt;/p>
&lt;ul>
&lt;li>params：不同的 resource type 可能會有的不同額外參數資訊&lt;/li>
&lt;/ul>
&lt;h2 id="resource-type">Resource Type&lt;/h2>
&lt;p>有了以上概念後，接著要知道的是 PipelineResources 共有以下幾種類型：&lt;/p>
&lt;ul>
&lt;li>Git Resource&lt;/li>
&lt;li>Pull Request Resource&lt;/li>
&lt;li>Image Resource&lt;/li>
&lt;li>Cluster Resource&lt;/li>
&lt;li>Storage Resource&lt;/li>
&lt;li>Cloud Event Resource&lt;/li>
&lt;/ul>
&lt;p>以下就針對比較常用的 Git &amp;amp; Image resource 說明，其他的部份可以參考官網的詳細文件。&lt;/p>
&lt;h3 id="git-resource">Git Resource&lt;/h3>
&lt;p>一般的 git repository，作為 task input 時，Tekton 執行 task 前會將程式碼 clone 回來，因此這邊就必須注意 git repository 存取的權限問題，若是 private repository 就要額外提供 credential 資訊才可以正常運作&lt;/p>
&lt;p>以下是一個標準的 Git PipelineResource 的定義：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">apiVersion: tekton.dev/v1alpha1
kind: PipelineResource
metadata:
name: wizzbang-git
namespace: default
spec:
type: git
params:
- name: url
value: https://github.com/wizzbangcorp/wizzbang.git
# 可用 branch, tag, commit SHA or ref
# 沒指定就會拉 master branch
- name: revision
value: master
# value: some_awesome_feature
# value: refs/pull/52525/head
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="task--clustertask">Task &amp;amp; ClusterTask&lt;/h2>
&lt;p>&lt;code>Task&lt;/code>(&amp;amp; &lt;code>ClusterTask&lt;/code>) 中包含了一連串的 step，通常是使用者要用來執行 CI flow，而這些工作會在單一個 pod 中以多個 container 的形式逐一完成。&lt;/p>
&lt;p>Task &amp;amp; ClusterTask 兩者的不同在於 Task 是屬於 namespace level，而 ClusterTask 是屬於 cluster level&lt;/p>
&lt;p>而在 Task 的定義中，最重要的部份有以下三個項目：&lt;/p>
&lt;ul>
&lt;li>Input&lt;/li>
&lt;li>Output&lt;/li>
&lt;li>Steps&lt;/li>
&lt;/ul>
&lt;p>以下是一個 task 的標準定義內容：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">apiVersion: tekton.dev/v1alpha1
kind: Task
metadata:
name: deploy-using-kubectl
spec:
inputs:
resources:
- name: source
type: git
- name: image
type: image
params:
- name: path
type: string
description: Path to the manifest to apply
- name: yamlPathToImage
type: string
description:
The path to the image to replace in the yaml manifest (arg to yq)
steps:
# step 中可以定義多個執行工作，會依照順序執行
- name: replace-image
image: mikefarah/yq
command: [&amp;#34;yq&amp;#34;]
args:
- &amp;#34;w&amp;#34;
- &amp;#34;-i&amp;#34;
- &amp;#34;$(inputs.params.path)&amp;#34;
- &amp;#34;$(inputs.params.yamlPathToImage)&amp;#34;
- &amp;#34;$(inputs.resources.image.url)&amp;#34;
- name: run-kubectl
image: lachlanevenson/k8s-kubectl
command: [&amp;#34;kubectl&amp;#34;]
args:
- &amp;#34;apply&amp;#34;
- &amp;#34;-f&amp;#34;
- &amp;#34;$(inputs.params.path)&amp;#34;
# 此 volume 在 task 中沒有用到，只是一個範例而已
# 用以表示可以在 task 中定義 volume 並使用
volumes:
- name: example-volume
emptyDir: {}
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="taskrun">TaskRun&lt;/h2>
&lt;p>定義了 task 之後，Tekton 並不會主動執行任何 task，這時候就必須要搭配 TaskRun 才可以讓 task 真正的執行指定工作。&lt;/p>
&lt;p>以下是一個標準的 TaskRun 定義：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback"># 以下幾個(apiVersion, kind, metadata, spec)是必要資訊
apiVersion: tekton.dev/v1alpha1
kind: TaskRun
metadata:
name: build-docker-image-from-git-source-task-run
spec:
serviceAccount: robot-docker-basic
# 指定到已經預先定義好的 Task
taskRef:
name: build-docker-image-from-git-source
inputs:
resources:
- name: docker-source
# 指定到已經預先定義好的 PipelineResource
resourceRef:
name: git-tekton-test
params:
- name: pathToDockerFile
value: Dockerfile
- name: pathToContext
value: /workspace/docker-source/examples/microservices/leeroy-web
outputs:
resources:
- name: builtImage
resourceRef:
name: image-tekton-test
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="pipeline">Pipeline&lt;/h2>
&lt;p>Pipeline 其實可以把它簡單思考為前面 Task 的集合，有順序性的排列，並透過之後介紹的 PipelineRun 來運作。&lt;/p>
&lt;p>成功運行 Pipeline 結果:&lt;/p>
&lt;p>&lt;img src="https://www.redhat.com/architect/sites/default/files/styles/embed_large/public/2022-06/4-pipeline.png?itok=Eex7RxG9"
loading="lazy"
>&lt;/p>
&lt;p>失敗運行 Pipeline 結果：&lt;/p>
&lt;p>&lt;img src="https://www.redhat.com/architect/sites/default/files/styles/embed_large/public/2022-06/5-ci-dev-pipeline-failed.png?itok=dzFYWfKl"
loading="lazy"
>&lt;/p>
&lt;h2 id="結語">結語&lt;/h2>
&lt;p>以上內容(PipelineResource, Task, TaskRun, Pipeline, PipelineRun) 是 Tekton 中執行工作的必要元素，實際上執行的 CI/CD 工作都會與這幾個部份有關。&lt;/p>
&lt;p>Tekton 將所有的基本元素拆分成一個一個的 k8s CRD(Custom Resource Definition)，如果是稍微複雜一點的 CI/CD 工作，可能就會需要定義不少個 CRD 才能完成，而且在設計上相對於其他的 CI server(例如：GitLab CI, Drone CI)可能不是這麼直覺；但這樣的設計提供了以下優點：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>原生的 k8s 使用經驗，不需要額外學習其他語法&lt;/p>
&lt;/li>
&lt;li>
&lt;p>定義好的 CRD(PipelineResource, Task, Pipeline) 可以被重複利用&lt;/p>
&lt;/li>
&lt;li>
&lt;p>原生整合 k8s&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>若是未來有考慮 workload 都跑在 k8s 上的使用者，在選擇 CI/CD 的工具時或許可以將 Tekton 考慮進行。&lt;/p>
&lt;p>接著可能會面臨到的問題可能是，如果希望作到 GitOps，光是以上項目好像不夠還有相關元件支援性。&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://github.com/tektoncd/pipeline/tree/main/examples" target="_blank" rel="noopener"
>pipeline/examples&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/tektoncd/pipeline/blob/main/docs/resources.md" target="_blank" rel="noopener"
>PipelineResources&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>從零開始快速建置 - Microsoft Azure Red Hat OpenShift (ARO)</title><link>https://blog.yylin.io/openshift/aro/</link><pubDate>Sun, 13 Mar 2022 21:40:40 +0800</pubDate><guid>https://blog.yylin.io/openshift/aro/</guid><description>&lt;p>ARO4 深入探討 - Microsoft Azure Red Hat OpenShift 4&lt;/p>
&lt;p>讓我們深入挖掘！&lt;/p>
&lt;p>Microsoft Azure Red Hat OpenShift 服務支持部署完全託管的 OpenShift 集群。&lt;/p>
&lt;p>Azure Red Hat OpenShift 由 Red Hat 和 Microsoft 聯合設計、運營和支持，以提供集成的支持體驗。沒有虛擬機可以運行，也不需要打補丁。主節點、基礎架構和應用程序節點由 Red Hat 和 Microsoft 代表您進行修補、更新和監控。您的 Azure Red Hat OpenShift 集群已部署到您的 Azure 訂閱中，並包含在您的 Azure 賬單中。&lt;/p>
&lt;p>在 OpenShift 4 上部署 Azure Red Hat 時，整個集群都包含在一個虛擬網絡中。在這個虛擬網絡中，您的主節點和工作節點都位於各自的子網中。每個子網都使用一個內部負載均衡器和一個公共負載均衡器。&lt;/p>
&lt;p>這是有關 Azure Red Hat OpenShift 4 的官方圖表（可在 ARO4 Microsoft 頁面中找到）：&lt;/p>
&lt;p>&lt;img src="https://rcarrata.com/images/aro4-networking-diagram.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>關於 ARO4 部署和管理的網絡和資源的更多詳細信息，請查看&lt;a class="link" href="https://docs.microsoft.com/en-us/azure/openshift/concepts-networking#networking-components" target="_blank" rel="noopener"
>ARO 圖詳細信息 - 官方文檔&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>讓我們安裝我們的第一個 ARO4 集群！&lt;/p>
&lt;h2 id="azure-帳戶先決條件">Azure 帳戶先決條件&lt;/h2>
&lt;p>首先，我們需要在 Azure 帳戶中設置幾項內容，例如生成 ServicePrincipals、增加限制以及定義要使用的區域。&lt;/p>
&lt;ul>
&lt;li>按照&lt;a class="link" href="https://docs.openshift.com/container-platform/latest/installing/installing_azure/installing-azure-account.html" target="_blank" rel="noopener"
>配置 Azure 帳戶先決條件&lt;/a>來定義和分配適當的 RBAC 權限並增加對 Azure 帳戶的限制。&lt;/li>
&lt;/ul>
&lt;h2 id="為-aro-安裝配置-azure-基礎結構先決條件">為 ARO 安裝配置 Azure 基礎結構先決條件&lt;/h2>
&lt;p>當我們準備好上一步後，就可以在 Azure 中為我們的 ARO4 集群生成基礎資源先決條件了：&lt;/p>
&lt;ul>
&lt;li>定義 ARO4 安裝的基本參數：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">export LOCATION=eastus
export RESOURCEGROUP=aro-rg
export CLUSTER=rcarrata
export VNET_CIDR=&amp;#34;10.0.0.0/22&amp;#34;
export MASTER_SUBNET_CIDR=&amp;#34;10.0.0.0/23&amp;#34;
export WORKER_SUBNET_CIDR=&amp;#34;10.0.2.0/23&amp;#34;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>使用 az cli 登錄到 Azure：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">az login
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>注意：當登錄彈出時，您需要在 Azure Dashboard 中使用您的憑據進行身份驗證。&lt;/p>
&lt;ul>
&lt;li>註冊資源提供者：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">az provider register -n Microsoft.RedHatOpenShift --wait
az provider register -n Microsoft.Compute --wait
az provider register -n Microsoft.Storage --wait
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h1 id="建立-azure-red-hat-openshift-4-叢集">建立 Azure Red Hat OpenShift 4 叢集&lt;/h1>
&lt;h2 id="開始之前">開始之前&lt;/h2>
&lt;p>Azure Red Hat OpenShift 至少需要 40 個核心，才能建立和執行 OpenShift 叢集。 新 Azure 訂用帳戶的預設 Azure 資源配額不符合這項需求。 若要要求增加資源限制，請參閱標準配額：&lt;a class="link" href="https://docs.microsoft.com/zh-tw/azure/azure-portal/supportability/per-vm-quota-requests" target="_blank" rel="noopener"
>VM 系列的增加限制&lt;/a>。&lt;/p>
&lt;ul>
&lt;li>例如，若要檢查最小支援的虛擬機器系列 SKU 「標準 DSv3」的目前訂用帳戶配額：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">LOCATION=eastus
az vm list-usage -l $LOCATION \
--query &amp;#34;[?contains(name.value, &amp;#39;standardDSv3Family&amp;#39;)]&amp;#34; \
-o table
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">CurrentValue Limit LocalName
-------------- ------- --------------------------
40 1000 Standard DSv3 Family vCPUs
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="驗證權限">驗證權限&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">Azure CLI quickstart:
export GUID=hzdnk
export CLIENT_ID=bdf5480a-c661-451f-a2ce-81e448ce0ba8
export PASSWORD=Zz842xzC.7GWZS_xVZ3oQvg1~7PtoIcKVA
export TENANT=1ce7852f-dcf3-42bc-afe6-3bf81ab984fb
export SUBSCRIPTION=ede7f891-835c-4128-af5b-0e53848e54e7
export RESOURCEGROUP=openenv-hzdnk
curl -L https://aka.ms/InstallAzureCli | bash
az login --service-principal -u $CLIENT_ID -p $PASSWORD --tenant $TENANT
[
{
&amp;#34;cloudName&amp;#34;: &amp;#34;AzureCloud&amp;#34;,
&amp;#34;homeTenantId&amp;#34;: &amp;#34;1ce7852f-dcf3-42bc-afe6-3bf81ab984fb&amp;#34;,
&amp;#34;id&amp;#34;: &amp;#34;ede7f891-835c-4128-af5b-0e53848e54e7&amp;#34;,
&amp;#34;isDefault&amp;#34;: true,
&amp;#34;managedByTenants&amp;#34;: [
{
&amp;#34;tenantId&amp;#34;: &amp;#34;b5ce0030-ec42-4a62-bc94-3025993e790c&amp;#34;
}
],
&amp;#34;name&amp;#34;: &amp;#34;RHPDS Subscription - OpenTLC Tenant&amp;#34;,
&amp;#34;state&amp;#34;: &amp;#34;Enabled&amp;#34;,
&amp;#34;tenantId&amp;#34;: &amp;#34;1ce7852f-dcf3-42bc-afe6-3bf81ab984fb&amp;#34;,
&amp;#34;user&amp;#34;: {
&amp;#34;name&amp;#34;: &amp;#34;bdf5480a-c661-451f-a2ce-81e448ce0ba8&amp;#34;,
&amp;#34;type&amp;#34;: &amp;#34;servicePrincipal&amp;#34;
}
}
]
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>創建資源組為 ARO4 對象（如 vnet 和子網，以及自己的 ARO4 對象）分配資源：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">az group create --name $RESOURCEGROUP --location $LOCATION
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>創建虛擬網絡：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">az network vnet create --resource-group $RESOURCEGROUP \
--name aro-vnet --address-prefixes $VNET_CIDR
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>為主節點添加一個空子網：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">az network vnet subnet create \
--resource-group $RESOURCEGROUP \
--vnet-name aro-vnet \
--name master-subnet \
--address-prefixes $MASTER_SUBNET_CIDR \
--service-endpoints Microsoft.ContainerRegistry
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>為工作節點添加一個空子網：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">az network vnet subnet create \
--resource-group $RESOURCEGROUP \
--vnet-name aro-vnet \
--name worker-subnet \
--address-prefixes $WORKER_SUBNET_CIDR \
--service-endpoints Microsoft.ContainerRegistry
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>在主子網上禁用子網專用終結點策略：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">az network vnet subnet update \
--name master-subnet \
--resource-group $RESOURCEGROUP \
--vnet-name aro-vnet \
--disable-private-link-service-network-policies true
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="安裝-aro4">安裝 ARO4&lt;/h2>
&lt;ul>
&lt;li>使用 azure cli 創建 ARO 集群：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">echo &amp;#34;Creating ARO Cluster... Please wait 40mins&amp;#34;
az aro create --resource-group $RESOURCEGROUP \
--name $CLUSTER --vnet aro-vnet \
--master-subnet master-subnet \
--worker-subnet worker-subnet \
--pull-secret @pull-secret.txt
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>注意：安裝需要一個有效的 pull-secret。請訪問您的&lt;a class="link" href="https://rcarrata.com/openshift/aro4/cloud.redhat.com/openshift/" target="_blank" rel="noopener"
>Cloud OpenShift Doshboard&lt;/a>並獲取您的 pull-secret 令牌。&lt;/p>
&lt;ul>
&lt;li>然後 az aro cli 將在 Azure Dashboard 中預配一個 ARO 對象：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i.imgur.com/I1PyWMK.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>自動地，它使用用於安裝的 Azure 對象創建了一個額外的 Azure 資源組，由 RH 和 MSFT 的 ARO SRE 管理：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i.imgur.com/wjJ4OUi.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>在此資源組中，我們生成了提供和配置 ARO4 集群所需的資源：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://rcarrata.com/images/aro4_3.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="訪問-api-和控制台">訪問 API 和控制台&lt;/h2>
&lt;ul>
&lt;li>大約 40 分鐘後。我們將使用控制台和 API 準備好 ARO4 集群：&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://rcarrata.com/images/aro4_4.png" target="_blank" rel="noopener"
>&lt;/a>&lt;/p>
&lt;ul>
&lt;li>要訪問集群，請列出集群的憑據：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">echo &amp;#34;List credentials for ARO Cluster&amp;#34;
az aro list-credentials \
--name $CLUSTER \
--resource-group $RESOURCEGROUP
echo &amp;#34;&amp;#34;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>要顯示 ARO4 控制台：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">echo &amp;#34;List console for ARO cluster&amp;#34;
az aro show \
--name $CLUSTER \
--resource-group $RESOURCEGROUP \
--query &amp;#34;consoleProfile.url&amp;#34; -o tsv
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>檢查 ARO4 API：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">apiServer=$(az aro show -g $RESOURCEGROUP -n $CLUSTER --query apiserverProfile.url -o tsv)
echo &amp;#34;This is the API for your cluster: $apiServer&amp;#34;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>查詢 ARO Cluster 狀態&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">[root@bastion ~]# az aro list -o table
Name ResourceGroup Location ProvisioningState WorkerCount URL
--------- --------------- ---------- ------------------- ------------- -----------------------------------------------------------------
aro-demo openenv-hdpnp eastus Succeeded 3 https://console-openshift-console.apps.yylin.io/
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>About</title><link>https://blog.yylin.io/about/</link><pubDate>Sun, 13 Mar 2022 17:19:42 +0800</pubDate><guid>https://blog.yylin.io/about/</guid><description>&lt;h2 id="profile">Profile&lt;/h2>
&lt;h2 id="specialist-solutions-architect-at-red-hat">Specialist Solutions Architect at Red Hat&lt;/h2>
&lt;p>Hello, 我是 YI-YANG (Frank) Lin&lt;/p>
&lt;p>此 Blog 主要是用來「拆解」一些工作上接觸到或是開源專案，遇到技術疑問「復盤」思維脈絡。&lt;/p>
&lt;p>並透過學習過程「筆記」文章，歡迎大家一起交流討論！&lt;/p>
&lt;h2 id="contact">Contact&lt;/h2>
&lt;ul>
&lt;li>GitHub: &lt;a class="link" href="https://github.com/yylin1" target="_blank" rel="noopener"
>https://github.com/yylin1&lt;/a>&lt;/li>
&lt;li>Speaker Deck: &lt;a class="link" href="https://speakerdeck.com/yylin1" target="_blank" rel="noopener"
>https://speakerdeck.com/yylin1&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Disconnected Environment - Introducing Mirror Registry for Red Hat OpenShift</title><link>https://blog.yylin.io/openshift/mirror-registry-for-ocp4-install/</link><pubDate>Mon, 07 Mar 2022 00:53:25 +0800</pubDate><guid>https://blog.yylin.io/openshift/mirror-registry-for-ocp4-install/</guid><description>&lt;p>本文件如何安裝 OpenShift 4.8 版本至虛擬機器上，這邊將以 RHEL 環境來進行測試。&lt;/p>
&lt;ul>
&lt;li>RHEL 8 or Fedora machine with podman v3.3 installed&lt;/li>
&lt;li>Fully qualified domain name for the Quay service (must resolve via DNS, or at least /etc/hosts)&lt;/li>
&lt;li>Passwordless sudo access on the target host (rootless install tbd)&lt;/li>
&lt;li>Key-based SSH connectivity on the target host (will be set up automatically for local installs, in case of remote hosts see here)&lt;/li>
&lt;li>make (only if compiling your own installer)&lt;/li>
&lt;/ul>
&lt;p>當我們的基礎設施處於離線環境時，需要創建容器鏡像倉庫(Registry)來託管安裝 OpenShift Container Platform 所需的相關鏡像檔，來正常部署 OpenShift 叢集。&lt;/p>
&lt;p>這是有關 mirror registry for Red Hat OpenShift OpenShift 4 的官方流程圖（可在 Red Hat Blog 頁面中找到）：&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/49Qc3LU.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="情境與使用目標">情境與使用目標&lt;/h2>
&lt;p>OpenShift 通常是在受控制離線網路的情況下運行 Production Cluster。而客戶要使用 Red Hat Quay 在 OpenShift 上運行優勢包含，有更多擴充性與部署元件配置整合性。要在離線環境安裝 OpenShift 前提條件，需要一個存放的安裝所需的相關鏡像的鏡像倉庫 (e.g., Quay, Harbor, Docker registry)，這邊就會有雞生蛋蛋生雞問題。&lt;/p>
&lt;p>解決方案/目標：&lt;/p>
&lt;p>Red Hat 提供一個 “mirror registry”工具，只針對 OpenShift 部署的引導(Bootstrap)鏡像倉庫，透過自動化腳本安裝程序，提供在 RHEL 8 (or Fedora) 的系統環境，快速部署一個精簡版的 Quay ，提供保存下載特定版本 OpenShift、OpenShiftHub 鏡像檔。mirror registry 提供針對離線環境或只是單純 PoC OpenShift 情境使用的 Registry，可以透過自動化腳本，快速部署設置安裝單節點(all-in-one)的 Quay ，所需要的相關手動繁瑣設定，例如：完整網域名稱 FQDN、使用者自定義 SSL/TLS 憑證、訪問權權限 SSH key 及運行的環境選擇。&lt;/p>
&lt;p>情境: 離線環境，安裝 OpenShift 運行流程:&lt;/p>
&lt;ol>
&lt;li>在可連線外部網路環境中，透過 mirror registry 部署第一座容器鏡像倉庫(Online Mirror) 進行 OpenShift、OpenShiftHub 必要鏡像檔存放。&lt;/li>
&lt;li>同樣在離線環境中，透過 mirror registry 部署第二座容器鏡像倉庫(Air-gapped Mirror)，從 Online Mirror 拷貝並要的映像檔存放於 Air-gapped Mirror&lt;/li>
&lt;li>透過 Air-gapped Mirror 部署 OpenShift Production/Infra Cluster&lt;/li>
&lt;li>OpenShift 安裝 Quay Operator 提供內部服務及應用所需的鏡像存放&lt;/li>
&lt;/ol>
&lt;h2 id="事前準備">事前準備&lt;/h2>
&lt;ul>
&lt;li>從 &lt;a class="link" href="https://console.redhat.com/openshift/downloads#tool-mirror-registry" target="_blank" rel="noopener"
>OpenShift console Downloads&lt;/a> 下載最新版本的 &lt;code>mirror-registry.tar.gz&lt;/code>&lt;/li>
&lt;li>準備 pull-secret.json 檔案&lt;/li>
&lt;/ul>
&lt;h2 id="安裝">安裝&lt;/h2>
&lt;ul>
&lt;li>在當前環境安裝 mirror registry&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ vim /etc/hosts
127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4
::1 localhost localhost.localdomain localhost6 localhost6.localdomain6
127.0.0.1 registry.yylin.demolab
$ export HOSTNAME=&amp;#34;registry.yylin.demolab&amp;#34;
$ ./mirror-registry install --quayHostname ${HOSTNAME} --ssh-key &amp;lt;~/.ssh/my_id_rsa&amp;gt;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>最後輸出顯示 registry host 與登入資訊&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">INFO[2022-03-01 00:52:38] Quay installed successfully, permanent data are stored in /etc/quay-install
INFO[2022-03-01 00:52:38] Quay is available at https://registry.yylin.demolab:8443 with credentials (init, xxxxxxxxxxxxxxxxxxxxxx)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>產生 Registry Basic Auth 之認證資訊&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback"># (init, xxxxxxxxxxxxxxxxxxxxxx)
echo -n &amp;#39;&amp;lt;username&amp;gt;:&amp;lt;password&amp;gt;&amp;#39; | base64 -w0
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>在 pull-secret 加入本地 Registry 認證資訊&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback"> &amp;#34;registry.yylin.demolab:8443&amp;#34;: {
&amp;#34;auth&amp;#34;: &amp;#34;aW5pdDo3TzlNV1hBMDhQcTJKZGh0M0M2elZJNU5EMWlsYkJ3NA==&amp;#34;
}
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>驗證登入registry&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ podman login -u init --authfile pull-secret.json registry.yylin.demolab:8443
Error: authenticating creds for &amp;#34;registry.yylin.demolab:8443&amp;#34;: pinging container registry registry.yylin.demolab:8443: Get &amp;#34;https://registry.yylin.demolab:8443/v2/&amp;#34;: x509: certificate signed by unknown authority (possibly because of &amp;#34;crypto/rsa: verification error&amp;#34; while trying to verify candidate authority certificate &amp;#34;bastion.redhat.kubedev.org&amp;#34;)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>安裝更新 quay 憑證&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>mirror registry 預設會配置好 CA 憑證，請將 PEM 文件格式添加憑證到系統中信任的 CA 列表中，這邊複製到 /usr/share/pki/ca-trust-source/anchors/ 目錄中&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ cp /etc/quay-install/quay-rootCA/rootCA.pem /usr/share/pki/ca-trust-source/anchors/rootCA.cert
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>更新系統範圍的信任儲存配置，請使用 update-ca-trust 命令：&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ update-ca-trust
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>再次登入mirror registry - Quay 確認憑證狀態是不是已經更新&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ podman login -u init --authfile pull-secret.json bastion.redhat.kubedev.org:8443
Password:
Login Succeeded!
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="開始備份-openshift-images">開始備份 OpenShift images&lt;/h2>
&lt;ol>
&lt;li>建立備份路徑&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ mkdir -p $HOME/openshift4/registry/images
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>匯入環境變數&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback"># vim upgrade-env
export OCP_RELEASE=$(oc version -o json --client | jq -r &amp;#39;.releaseClientVersion&amp;#39;)
export LOCAL_REGISTRY=&amp;#34;registry.yylin.demolab:8443&amp;#34;
export LOCAL_REPOSITORY=&amp;#34;ocp4/openshift4&amp;#34;
export PRODUCT_REPO=&amp;#34;openshift-release-dev&amp;#34;
# /註記/ 請確認 pull-secret.json 裡面有包含 mirror rigistry 資訊
export LOCAL_SECRET_JSON=$HOME/mirror-registry/pull-secret.json
export RELEASE_NAME=&amp;#34;ocp-release&amp;#34;
export ARCHITECTURE=x86_64
# 指定 images 存放路徑
export REMOVABLE_MEDIA_PATH=&amp;#34;$HOME/openshift4/registry/images&amp;#34;
# 匯入環境變數
source upgrade-env
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="3">
&lt;li>備份 Image&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>/#1/ Review the images and configuration manifests to mirror:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc adm release mirror -a ${LOCAL_SECRET_JSON} --from=quay.io/${PRODUCT_REPO}/${RELEASE_NAME}:${OCP_RELEASE}-${ARCHITECTURE} --to=${LOCAL_REGISTRY}/${LOCAL_REPOSITORY} --to-release-image=${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}:${OCP_RELEASE}-${ARCHITECTURE} --dry-run
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">imageContentSources:
- mirrors:
- registry.yylin.demolab:8443/ocp4/openshift4
source: quay.io/openshift-release-dev/ocp-release
- mirrors:
- registry.yylin.demolab:8443/ocp4/openshift4
source: quay.io/openshift-release-dev/ocp-v4.0-art-dev
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>/#2/ Mirror the images to a directory on the removable media:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc adm release mirror -a ${LOCAL_SECRET_JSON} --to-dir=${REMOVABLE_MEDIA_PATH}/mirror quay.io/${PRODUCT_REPO}/${RELEASE_NAME}:${OCP_RELEASE}-${ARCHITECTURE}
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">info: Mirroring completed in 3m6.3s (66.22MB/s)
Success
Update image: openshift/release:4.10.0-rc.3-x86_64
To upload local images to a registry, run:
oc image mirror --from-dir=/root/openshift4/registry/images/mirror &amp;#39;file://openshift/release:4.10.0-rc.3-x86_64*&amp;#39; REGISTRY/REPOSITORY
Configmap signature file /root/openshift4/registry/images/mirror/config/signature-sha256-3d4ada825f4aa4d2.yaml created
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>/#3/ Take the media to the restricted network environment and upload the images to the local container registry:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc image mirror -a ${LOCAL_SECRET_JSON} --from-dir=${REMOVABLE_MEDIA_PATH}/mirror &amp;#34;file://openshift/release:${OCP_RELEASE}*&amp;#34; ${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">phase 0:
registry.redhat.demolab:8443 ocp4/openshift4 blobs=334 mounts=0 manifests=163 shared=0
info: Planning completed in 2.12s
uploading: registry.redhat.demolab:8443/ocp4/openshift4 sha256:7253c5d7bf339222334565e0ec7ac88dd017dc9b9ec01654d26e8dda07408548 81.38MiB
uploading: registry.redhat.demolab:8443/ocp4/openshift4 sha256:8e549eaeb17902a2a516d03776112ad7a9bfd10cd2d1c298fe31b1c15d3b4166 154.4MiB
uploading: registry.redhat.demolab:8443/ocp4/openshift4 sha256:11456a2e94a652afe44f2645d83a051160119fd953b2459167cc88232adbf9ed 31.45MiB
uploading: registry.redhat.demolab:8443/ocp4/openshift4 sha256:4ceffbad995c4d6e76142c6b46e7f2e06fcd2ddb6eb2c3624cc0244ae018356f 106.9MiB
...
...
sha256:2d80cc5beffc10607a53eb6c013e87d03e267cdf0b8fc678b40acf5432957714 registry.redhat.demolab:8443/ocp4/openshift4:4.10.0-rc.3-x86_64-multus-networkpolicy
sha256:df3b0ec40395ea460fbf2728ca7adff79dbaebddcffce003e88b3fb9cb2c9759 registry.redhat.demolab:8443/ocp4/openshift4:4.10.0-rc.3-x86_64-must-gather
sha256:a340ea3d86560de8cf9ee2c1afe42ad24e5eefc9903a0073abe9dc54815bf710 registry.redhat.demolab:8443/ocp4/openshift4:4.10.0-rc.3-x86_64-console-operator
sha256:f532e7f50cadfc757a6d277ab5476a31a4f24aac0afc615da6ff9f7ce5e2b538 registry.redhat.demolab:8443/ocp4/openshift4:4.10.0-rc.3-x86_64-cluster-image-registry-operator
info: Mirroring completed in 1m17.77s (5.572MB/s)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>/#4/ Directly push the release images to the local registry by using following command:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc adm release mirror -a ${LOCAL_SECRET_JSON} --from=quay.io/${PRODUCT_REPO}/${RELEASE_NAME}:${OCP_RELEASE}-${ARCHITECTURE} --to=${LOCAL_REGISTRY}/${LOCAL_REPOSITORY} --apply-release-image-signature
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>&lt;a class="link" href="https://docs.openshift.com/container-platform/4.10/openshift_images/samples-operator-alt-registry.html" target="_blank" rel="noopener"
>更多配置請參考 Mirroring the OpenShift Container Platform image repository&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="mirror-後結果">mirror 後結果&lt;/h2>
&lt;p>&lt;img src="https://i.imgur.com/APzRuyc.png"
loading="lazy"
>&lt;/p>
&lt;hr>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://docs.openshift.com/container-platform/4.10/installing/disconnected_install/installing-mirroring-creating-registry.html#mirror-registry-localhost_installing-mirroring-creating-registry" target="_blank" rel="noopener"
>Mirroring on a local host with mirror registry for Red Hat OpenShift&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://cloud.redhat.com/blog/introducing-mirror-registry-for-red-hat-openshift" target="_blank" rel="noopener"
>https://cloud.redhat.com/blog/introducing-mirror-registry-for-red-hat-openshift&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://access.redhat.com/support/policy/updates/openshift#omr" target="_blank" rel="noopener"
>https://access.redhat.com/support/policy/updates/openshift#omr&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=j5e4OT71N0A" target="_blank" rel="noopener"
>https://www.youtube.com/watch?v=j5e4OT71N0A&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>NVIDIA GPU Operator on OpenShift4</title><link>https://blog.yylin.io/openshift/gpu-operator/</link><pubDate>Mon, 28 Feb 2022 21:40:40 +0800</pubDate><guid>https://blog.yylin.io/openshift/gpu-operator/</guid><description>&lt;p>Nvidia GPU Operator v1.9 on OpenShift 4.9.9 包含以上版本，安裝不用再進行額外權限配置]&lt;/p>
&lt;h2 id="openshift-499-或更高的版本-1">OpenShift 4.9.9 或更高的版本 [1]&lt;/h2>
&lt;p>針對 driver toolkit 取消必要安裝要求:&lt;/p>
&lt;ul>
&lt;li>Set up an entitlement&lt;/li>
&lt;li>Mirror the RPM packages in a disconnected environment&lt;/li>
&lt;li>Configure a proxy to access the package repository&lt;/li>
&lt;/ul>
&lt;p>[1] &lt;a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/steps-overview.html#entitlement-free-supported-versions" target="_blank" rel="noopener"
>https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/steps-overview.html#entitlement-free-supported-versions&lt;/a>&lt;/p>
&lt;h2 id="openshift-498-與以下版本-2">OpenShift 4.9.8 與以下版本 [2]&lt;/h2>
&lt;p>需手動操作獲取 OCP 憑證，創建 MachineConfig 來認證 OCP 叢集，擴大授權 Images 使用權限範圍，來安裝 Nvidia Operator :&lt;/p>
&lt;ol>
&lt;li>從 Red Hat Customer Portal 下載 Red Hat OpenShift Container Platform 訂閱憑證 (啟用權限需要登入 OCP 憑證）。&lt;/li>
&lt;li>創建一個 MachineConfig 啟用訂閱管理平台並提供有效訂閱憑證。等待 MachineConfigOperator 重啟節點並完成 MachineConfig。&lt;/li>
&lt;li>驗證叢集所有節點更新權限是否正常。&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>補充 - NVIDIA GPU Operator 安裝會部署幾個 Pod 服務，用於管理和啟用 GPU 在 OpenShift 中運作。其中一些 Pod 需要 OpenShift 使用一些非 Universal Base Image (UBI) 默認授權的 Images。必須在 OpenShift Cluster 中啟用信任的授權 Images，來啟動 NVIDIA GPU 驅動程式的容器運行。&lt;/p>
&lt;/blockquote>
&lt;p>[1] &lt;a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/steps-overview.html#entitlement-free-supported-versions" target="_blank" rel="noopener"
>https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/steps-overview.html#entitlement-free-supported-versions&lt;/a>
[2] &lt;a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/cluster-entitlement.html#enabling-a-cluster-wide-entitlemenent" target="_blank" rel="noopener"
>https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/cluster-entitlement.html#enabling-a-cluster-wide-entitlemenent&lt;/a>&lt;/p>
&lt;h2 id="install-operator---node-feature-discovery">Install Operator - Node Feature Discovery&lt;/h2>
&lt;p>&lt;img src="https://i.imgur.com/3J8zoZU.png"
loading="lazy"
>
&lt;img src="https://i.imgur.com/NDepxYJ.png"
loading="lazy"
>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">[lab-user@bastion ~]$ oc get no
NAME STATUS ROLES AGE VERSION
ip-10-0-135-51.us-east-2.compute.internal Ready worker 3h5m v1.22.3+e790d7f
ip-10-0-142-219.us-east-2.compute.internal Ready master 3h14m v1.22.3+e790d7f
ip-10-0-167-35.us-east-2.compute.internal Ready worker 3h5m v1.22.3+e790d7f
ip-10-0-186-251.us-east-2.compute.internal Ready master 3h14m v1.22.3+e790d7f
ip-10-0-213-103.us-east-2.compute.internal Ready master 3h14m v1.22.3+e790d7f
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://i.imgur.com/456JizI.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>要驗證實例是否已創建，請運行：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">[lab-user@bastion ~]$ oc get pods -n openshift-nfd
NAME READY STATUS RESTARTS AGE
nfd-controller-manager-6f65f47cf6-tg6gj 2/2 Running 0 24m
nfd-master-d7cqw 1/1 Running 0 35s
nfd-master-j42m9 1/1 Running 0 35s
nfd-master-r64nv 1/1 Running 0 35s
nfd-worker-24tzn 1/1 Running 0 35s
nfd-worker-5rsg2 1/1 Running 0 35s
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>成功的部署會顯示一個Running狀態。&lt;/li>
&lt;/ul>
&lt;h2 id="installing-the-nvidia-gpu-operator">Installing the NVIDIA GPU Operator&lt;/h2>
&lt;p>With the Node Feature Discovery Operator installed you can continue with the final step and install the NVIDIA GPU Operator.&lt;/p>
&lt;p>As a cluster administrator, you can install the NVIDIA GPU Operator using the OpenShift Container Platform CLI or the web console.&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/zSZnOQc.png"
loading="lazy"
>
&lt;img src="https://i.imgur.com/H5mLoWH.png"
loading="lazy"
>
&lt;img src="https://i.imgur.com/gV3G6kq.png"
loading="lazy"
>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">kind: ClusterPolicy
apiVersion: nvidia.com/v1
metadata:
name: gpu-cluster-policy
spec:
dcgmExporter:
config:
name: &amp;#39;&amp;#39;
dcgm:
enabled: true
daemonsets: {}
devicePlugin: {}
driver:
enabled: true
use_ocp_driver_toolkit: true
repoConfig:
configMapName: &amp;#39;&amp;#39;
certConfig:
name: &amp;#39;&amp;#39;
licensingConfig:
nlsEnabled: false
configMapName: &amp;#39;&amp;#39;
virtualTopology:
config: &amp;#39;&amp;#39;
gfd: {}
migManager:
enabled: true
nodeStatusExporter:
enabled: true
operator:
defaultRuntime: crio
deployGFD: true
initContainer: {}
mig:
strategy: single
toolkit:
enabled: true
validator:
plugin:
env:
- name: WITH_WORKLOAD
value: &amp;#39;true&amp;#39;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Create the ClusterPolicy custom resource. This CRD will create several OCP resources. It will evaluate all the labels for the each node in the cluster and look for this:&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/k4xdsx8.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/45ygkxL.png"
loading="lazy"
>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc project nvidia-gpu-operator
$ oc get pod -o wide
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="validating-the-gpu-availability">Validating the GPU availability&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">[lab-user@bastion ~]$ oc get pod | grep nvidia-device-plugin-daemonset
nvidia-device-plugin-daemonset-bspfh 1/1 Running 0 21m
nvidia-device-plugin-daemonset-n62dm 1/1 Running 0 21m
[lab-user@bastion ~]$ oc exec -ti nvidia-device-plugin-daemonset-bspfh -- nvidia-smi
Defaulted container &amp;#34;nvidia-device-plugin-ctr&amp;#34; out of: nvidia-device-plugin-ctr, toolkit-validation (init)
Fri Jan 28 06:47:21 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.82.01 Driver Version: 470.82.01 CUDA Version: 11.4 |
|-------------------------------+----------------------+----------------------+
| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |
| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |
| | | MIG M. |
|===============================+======================+======================|
| 0 Tesla V100-SXM2... On | 00000000:00:1E.0 Off | 0 |
| N/A 32C P0 23W / 300W | 0MiB / 16160MiB | 0% Default |
| | | N/A |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes: |
| GPU GI CI PID Type Process name GPU Memory |
| ID ID Usage |
|=============================================================================|
| No running processes found |
+-----------------------------------------------------------------------------+
...
...
$ oc exec -ti nvidia-device-plugin-daemonset-n62dm -- nvidia-smi
Defaulted container &amp;#34;nvidia-device-plugin-ctr&amp;#34; out of: nvidia-device-plugin-ctr, toolkit-validation (init)
Fri Jan 28 06:47:44 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.82.01 Driver Version: 470.82.01 CUDA Version: 11.4 |
|-------------------------------+----------------------+----------------------+
| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |
| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |
| | | MIG M. |
|===============================+======================+======================|
| 0 Tesla V100-SXM2... On | 00000000:00:1E.0 Off | 0 |
| N/A 26C P0 24W / 300W | 0MiB / 16160MiB | 0% Default |
| | | N/A |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes: |
| GPU GI CI PID Type Process name GPU Memory |
| ID ID Usage |
|=============================================================================|
| No running processes found |
+-----------------------------------------------------------------------------+
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="running-a-sample-gpu-application">Running a sample GPU Application&lt;/h2>
&lt;p>Run a simple CUDA VectorAdd sample, which adds two vectors together to ensure the GPUs have bootstrapped correctly.&lt;/p>
&lt;ol>
&lt;li>Run the following:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">cat &amp;lt;&amp;lt; EOF | oc create -f -
apiVersion: v1
kind: Pod
metadata:
name: cuda-vectoradd
spec:
restartPolicy: OnFailure
containers:
- name: cuda-vectoradd
image: &amp;#34;nvidia/samples:vectoradd-cuda11.2.1&amp;#34;
resources:
limits:
nvidia.com/gpu: 1
EOF
pod/cuda-vectoradd created
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>Check the logs of the container:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">[lab-user@bastion ~]$ oc logs cuda-vectoradd
[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="getting-information-about-the-gpu">Getting information about the GPU¶&lt;/h2>
&lt;p>The nvidia-smi shows memory usage, GPU utilization and the temperature of the GPU. Test the GPU access by running the popular nvidia-smi command within the pod.&lt;/p>
&lt;p>To view GPU utilization, run nvidia-smi from a pod in the GPU Operator daemonset.&lt;/p>
&lt;ol>
&lt;li>Change to the nvidia-gpu-operator project:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc project nvidia-gpu-operator
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>Run the following command to view these new pods:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc get pod -owide -lopenshift.driver-toolkit=true
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
nvidia-driver-daemonset-49.84.202201102104-0-gl557 2/2 Running 0 26m 10.131.0.106 ip-10-0-167-35.us-east-2.compute.internal &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
nvidia-driver-daemonset-49.84.202201102104-0-k9sg5 2/2 Running 0 26m 10.128.2.17 ip-10-0-135-51.us-east-2.compute.internal &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="3">
&lt;li>Run the nvidia-smi command within the pod:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ oc exec -it nvidia-driver-daemonset-48.84.202110270303-0-9df9j -- nvidia-smi
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>2021 年度回顧</title><link>https://blog.yylin.io/year/2021-retrospect-and-prospect/</link><pubDate>Fri, 31 Dec 2021 13:33:28 +0800</pubDate><guid>https://blog.yylin.io/year/2021-retrospect-and-prospect/</guid><description>&lt;p>2021 年有非常多的轉變與抉擇，是讓自己很深刻的一年，雖然年初有一些個人因素，影響後續許多計畫與安排，但之後從個人職涯選擇以及決定，為自己嘗試更多各種不同的挑戰，雖然過程很不容易，但能能充實的過完這一年。&lt;/p>
&lt;h2 id="2021-回顧">2021 回顧&lt;/h2>
&lt;ul>
&lt;li>協助前公司部分產品 Containerized 建置與Kuberentes - IT 初期工作流程基礎規劃，學習很多寶貴的維運經驗。&lt;/li>
&lt;li>下半年決定為自己職涯嘗試新的挑戰，轉換職務，雖然過程花很多時間為認知與技能做轉換，過程參與事件活動非常多，但忙得有意義，非常充實。&lt;/li>
&lt;li>在 &lt;a class="link" href="https://coscup.org/2021/zh-TW/session/9X7UAG" target="_blank" rel="noopener"
>COSCUP 2021&lt;/a> 協助 CNTUG 社群議程軌-開源運河上的雲原生號擔任主持人：首次 COSCUP 線上虛擬舉行，體會主持人如何引導議程進行時，與講者會眾互動 Q&amp;amp;A ，並完成整個整個議程軌活動，難得且充實的年會體驗。&lt;/li>
&lt;li>擔任 &lt;a class="link" href="https://www.garaotus.com/HPC2021/vod/" target="_blank" rel="noopener"
>HPC Summit 2021&lt;/a> 講者：有機會分享抽空研究DeepOps 的專案，如何對於 AI/ML Infra 建置的部署工具與企業場景實際應用分析(&lt;a class="link" href="https://speakerdeck.com/yylin1/deepops-an-efficient-way-to-deploy-gpu-cluster-for-computing" target="_blank" rel="noopener"
>簡報連結&lt;/a>)。&lt;/li>
&lt;li>擔任 &lt;a class="link" href="https://k8s.ithome.com.tw/lab-page/553" target="_blank" rel="noopener"
>Kuberentes Summit 2021 - WorkShop&lt;/a> 講者: 學習如何用會眾角度規劃整個工作坊設計。&lt;/li>
&lt;li>回歸山岳攝影-登山健行: 持續撰寫&lt;a class="link" href="https://medium.com/yiyang-lins-life" target="_blank" rel="noopener"
>登山系列文章&lt;/a>，跟一群好友組了登山興趣小組，開始嘗試(台灣中級山系列、台北大縱走路線完成4/7段[持續進行中])，脫離城市的大自然體驗。&lt;/li>
&lt;li>自己動手做一顆手工肥皂，感謝 &lt;a class="link" href="https://www.instagram.com/suvida_tw/" target="_blank" rel="noopener"
>SU VIDA x 私 生活&lt;/a> 開設的工作坊&lt;/li>
&lt;li>攀岩(抱石) 維持 LV2 等級都順利完攀，持續往下一級前進。&lt;/li>
&lt;li>終於換了新一台相機 Sony A7 IV&lt;/li>
&lt;/ul>
&lt;h2 id="2022-展望">2022 展望&lt;/h2>
&lt;ul>
&lt;li>增強專業能力部分，提升各方面不足點&lt;/li>
&lt;li>花更多時間在技術文章撰寫&lt;/li>
&lt;li>完成先前未完成的證照&lt;/li>
&lt;li>回歸開源專案貢獻，積極參與 Conference / Meetup 分享&lt;/li>
&lt;li>持續健身運動維持飲食控制，為百岳做後續準備&lt;/li>
&lt;/ul>
&lt;h3 id="related-posts">Related Posts&lt;/h3>
&lt;ul>
&lt;li>&lt;a class="link" href="https://www.yylin.io/2020/12/31/2020-retrospect-prospect/" target="_blank" rel="noopener"
>2020-年度回顧 (舊 Blog 搬家中)&lt;/a>&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>2022 繼續爬山
&lt;img src="https://blog.yylin.io/year/2021-retrospect-and-prospect/01.jpg"
width="1620"
height="1080"
srcset="https://blog.yylin.io/year/2021-retrospect-and-prospect/01_hucbf4df3e07792eaecaff75330300fcc5_1642419_480x0_resize_q75_box.jpg 480w, https://blog.yylin.io/year/2021-retrospect-and-prospect/01_hucbf4df3e07792eaecaff75330300fcc5_1642419_1024x0_resize_q75_box.jpg 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="150"
data-flex-basis="360px"
>&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>Photography Blog (&lt;a class="link" href="https://medium.com/yiyang-lins-life" target="_blank" rel="noopener"
>https://medium.com/yiyang-lins-life&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Red Hat OpenShift Platform on AWS (ROSA) 快速部署上手</title><link>https://blog.yylin.io/openshift/rosa/</link><pubDate>Thu, 30 Sep 2021 14:54:40 +0800</pubDate><guid>https://blog.yylin.io/openshift/rosa/</guid><description>&lt;h2 id="事前準備">事前準備：&lt;/h2>
&lt;p>開始前，需要先準備以下資訊與要求。&lt;/p>
&lt;h3 id="啟用-rosa">啟用 ROSA&lt;/h3>
&lt;blockquote>
&lt;p>開始配置 AWS 服務前，使用者必須以 &lt;a class="link" href="https://docs.openshift.com/rosa/rosa_getting_started/rosa-aws-prereqs.html#rosa-policy-iam_prerequisites" target="_blank" rel="noopener"
>IAM&lt;/a> 身份(參考文件: &lt;a class="link" href="https://docs.openshift.com/rosa/rosa_getting_started/rosa-aws-prereqs.html#rosa-customer-requirements_prerequisites" target="_blank" rel="noopener"
>Customer Requirements&lt;/a>)&lt;/p>
&lt;/blockquote>
&lt;p>登入 AWS 管理控制台，確認當前使用者&lt;code>已啟用 Red Hat OpenShift&lt;/code>服務
&lt;img src="https://i.imgur.com/lbpYgG6.png"
loading="lazy"
>&lt;/p>
&lt;h3 id="下載-aws-cli-與-openshift-cli-工具">下載 AWS CLI 與 OpenShift CLI 工具:&lt;/h3>
&lt;p>&lt;strong>URL Dowload&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>選擇當前環境下載對應&lt;code>CLI&lt;/code> ( &lt;a class="link" href="https://console.redhat.com/openshift/downloads" target="_blank" rel="noopener"
>Command-line interface (CLI) tools&lt;/a>)&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/c64k4mB.png"
loading="lazy"
>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>or&lt;/p>
&lt;p>&lt;strong>Command Dowload&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>下載 &lt;code>AWS/OpenShift CLI&lt;/code> 工具，並解壓縮檔案到 /usr/local/bin/ 底下:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="c1"># CLI&lt;/span>
$ wget -c https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/rosa/latest/rosa-linux.tar.gz -O - &lt;span class="p">|&lt;/span> tar -xz
$ mv rosa /usr/local/bin/
$ rosa version
1.1.1
$ wget -c https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest-4.8/openshift-client-linux.tar.gz -O - &lt;span class="p">|&lt;/span> tar -xz
$ mv &lt;span class="o">{&lt;/span>oc,kubectl&lt;span class="o">}&lt;/span> /usr/local/bin/
$ oc version
Client Version: 4.8.2
$ oc version
Client Version: 4.8.10
Server Version: 4.8.12
Kubernetes Version: v1.21.1+d8043e1
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>創建 Red Hat 帳號
OpenShift 由 Red Hat SaaS 提供，因此您需要創建一個 Red Hat 帳戶。
&lt;a class="link" href="https://cloud.redhat.com/" target="_blank" rel="noopener"
>https://cloud.redhat.com/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;h2 id="透過-rosa-指令檢查憑證與資源配置">透過 ROSA 指令檢查憑證與資源配置&lt;/h2>
&lt;p>這邊以 Red Hat 部署 ROSA 文件部署為主 (&lt;a class="link" href="https://docs.openshift.com/rosa/rosa_getting_started/rosa-creating-cluster.html" target="_blank" rel="noopener"
>Red Hat OpenShift Service on AWS - Creating a ROSA cluster&lt;/a>)&lt;/p>
&lt;p>首先，使用 &lt;code>ROSA CLI&lt;/code> 檢查 AWS 憑證&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ rosa verify permissions
I: Validating SCP policies...
I: AWS SCP policies ok
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>第一次登錄時，你會需要一個 Token 來登入你的 Red Hat 帳號&lt;/p>
&lt;blockquote>
&lt;p>需要創建一組 Red Hat 帳號&lt;/p>
&lt;/blockquote>
&lt;p>確認登入訊息：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ rosa login
I: Logged in as &lt;span class="s1">&amp;#39;xxxx@mail.com&amp;#39;&lt;/span> on &lt;span class="s1">&amp;#39;https://api.openshift.com&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>配置完成後可以透過 &lt;code>rosa whoami&lt;/code> 來檢查你目前所有登錄憑證與狀態&lt;/p>
&lt;blockquote>
&lt;p>Red Hat 帳號會附帶 OpenShift Cluster Manager (OCM) 資訊與你的 AWS 帳戶顯示。&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ rosa whoami
AWS Account ID: xxxxxxxxxxxx
AWS Default Region: us-west-2
AWS ARN: arn:aws:iam::xxxxxxxxxxxx:user/user
OCM API: https://api.openshift.com
OCM Account ID: xxxxxxxxxxxxxxxxxxxxxx
OCM Account Name: xxxxxx
OCM Account Username: xxxxx@xxxxx.com
OCM Account Email: xxxxx@xxxxx.com
OCM Organization ID: xxxxxxxxxxxxxxxxxxxxxx
OCM Organization Name: Red Hat
OCM Organization External ID: xxxxxxxx
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>以上檢查沒問題後，接下運行 &lt;code>rosa init&lt;/code> 運行指令來確保 ROSA 配置與相關資源狀態沒問題&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ rosa init
I: Logged in as &amp;#39;xxxxxx@mail.com&amp;#39; on &amp;#39;https://api.openshift.com&amp;#39;
I: Validating AWS credentials...
I: AWS credentials are valid!
I: Validating SCP policies...
I: AWS SCP policies ok
I: Validating AWS quota...
I: AWS quota ok. If cluster installation fails, validate actual AWS resource usage against https://docs.openshift.com/rosa/rosa_getting_started/rosa-required-aws-service-quotas.html
I: Ensuring cluster administrator user &amp;#39;osdCcsAdmin&amp;#39;...
I: Admin user &amp;#39;osdCcsAdmin&amp;#39; already exists!
I: Validating SCP policies for &amp;#39;osdCcsAdmin&amp;#39;...
I: AWS SCP policies ok
I: Validating cluster creation...
I: Cluster creation valid
I: Verifying whether OpenShift command-line tool is available...
I: Current OpenShift Client Version: 4.8.10
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>需要驗證當前環境，是否已經登入 AWS並確認透過&lt;code>rosa init&lt;/code> 來確認 AWS 資源與配置是否能足夠創建 OpenShift&lt;/p>
&lt;/blockquote>
&lt;h3 id="申請-aws-帳戶配額">申請 AWS 帳戶配額&lt;/h3>
&lt;p>在配置 ROSA 時作為預先檢查 &lt;code>$ rosa verify quota --region=${cluster}&lt;/code> 叢集名稱。如果您在剛剛部署但未執行任何操作的帳戶上運行它，您將收到錯誤訊息 EC2 &lt;code>quota 配置不足&lt;/code>。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ rosa verify quota --region&lt;span class="o">=&lt;/span>us-west-2
I: Validating AWS quota...
E: Insufficient AWS quotas
E: Service quota is insufficient &lt;span class="k">for&lt;/span> the following service quota codes:
- Service ec2 quota code L-1216C47A Running On-Demand Standard &lt;span class="o">(&lt;/span>A, C, D, H, I, M, R, T, Z&lt;span class="o">)&lt;/span> instances not valid, expected quota of at least 100, but got &lt;span class="m">5&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>這邊需要額外申請 AWS EC2 限制增加配額
&lt;img src="https://i.imgur.com/X2PtefK.png"
loading="lazy"
>&lt;/p>
&lt;p>需要提供申請需求與相關資訊，才能申請限制配額成功&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/fMprN3I.png"
loading="lazy"
>&lt;/p>
&lt;p>相關配額資訊參考&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html" target="_blank" rel="noopener"
>AWS service quotas&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.openshift.com/rosa/rosa_getting_started/rosa-required-aws-service-quotas.html" target="_blank" rel="noopener"
>Required AWS service quotas&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i.imgur.com/4K3BWLp.png"
loading="lazy"
>&lt;/p>
&lt;p>以上完成申請後，再次驗證&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ rosa verify quota --region&lt;span class="o">=&lt;/span>us-west-2
I: Validating AWS quota...
I: AWS quota ok. If cluster installation fails, validate actual AWS resource usage against https://docs.openshift.com/rosa/rosa_getting_started/rosa-required-aws-service-quotas.htm
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;hr>
&lt;h2 id="透過-rosa-指令快速創建-red-hat-openshift">透過 ROSA 指令快速創建 Red Hat OpenShift&lt;/h2>
&lt;ul>
&lt;li>透過 &lt;code>rosa create cluster&lt;/code> 開始部署 OpenShift Cluster (部署Cluster 大約需要30-40分鐘)&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ rosa create cluster --cluster-name&lt;span class="o">=&lt;/span>rosacluster
I: Creating cluster &lt;span class="s1">&amp;#39;rosacluster&amp;#39;&lt;/span>
I: To view a list of clusters and their status, run &lt;span class="s1">&amp;#39;rosa list clusters&amp;#39;&lt;/span>
I: Cluster &lt;span class="s1">&amp;#39;rosacluster&amp;#39;&lt;/span> has been created.
I: Once the cluster is installed you will need to add an Identity Provider before you can login into the cluster. See &lt;span class="s1">&amp;#39;rosa create idp --help&amp;#39;&lt;/span> &lt;span class="k">for&lt;/span> more information.
I: To determine when your cluster is Ready, run &lt;span class="s1">&amp;#39;rosa describe cluster -c newsblogcluster&amp;#39;&lt;/span>.
I: To watch your cluster installation logs, run &lt;span class="s1">&amp;#39;rosa logs install -c newsblogcluster --watch&amp;#39;&lt;/span>.
Name: newsblogcluster
ID: XXXXXXXXXXXXXXXXXXXX
External ID:
OpenShift Version:
Channel Group: stable
DNS: newsblogcluster.phnh.p1.openshiftapps.com
AWS Account: &lt;span class="m">123456789012&lt;/span>
API URL:
Console URL:
Region: xxxxxxxxxxx
Multi-AZ: &lt;span class="nb">false&lt;/span>
Nodes:
- Master: &lt;span class="m">3&lt;/span>
- Infra: &lt;span class="m">2&lt;/span>
- Compute: &lt;span class="m">2&lt;/span> &lt;span class="o">(&lt;/span>m5.xlarge&lt;span class="o">)&lt;/span>
Network:
- Service CIDR: 172.30.0.0/16
- Machine CIDR: 10.0.0.0/16
- Pod CIDR: 10.128.0.0/14
- Host Prefix: /23
State: pending &lt;span class="o">(&lt;/span>Preparing account&lt;span class="o">)&lt;/span>
Private: No
Created: xxxxxxxxxxxxxxxx
Details Page: https://cloud.redhat.com/openshift/details/XXXXXXXXXXXXXXXXXXXX
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>執行命令後，您可以透過 &lt;code>rosa describe cluster&lt;/code> 或 &lt;code>rosa logs install&lt;/code> 指令檢查 OpenShift Cluster 狀態。您還可以從 URL 訪問 OpenShift Console 進行確認。&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/DvBaXFH.png"
loading="lazy"
>
&lt;img src="https://i.imgur.com/KkZJ3zn.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/LUfY9n9.png"
loading="lazy"
>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ rosa create admin -c rosacluster
W: It is recommended to add an identity provider to login to this cluster. See &amp;#39;rosa create idp --help&amp;#39; for more information.
I: Admin account has been added to cluster &amp;#39;rosacluster&amp;#39;.
I: Please securely store this generated password. If you lose this password you can delete and recreate the cluster admin user.
I: To login, run the following command:
oc login https://api.rosacluster.hffh.p1.openshiftapps.com:6443 --username cluster-admin --password fTwWy-rYJJU-wUua7-W3G6Z
I: It may take up to a minute for the account to become active.
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ oc login https://api.rosacluster.hffh.p1.openshiftapps.com:6443 --username cluster-admin --password fTwWy-rYJJU-wUua7-W3G6Z
Login successful.
You have access to &lt;span class="m">87&lt;/span> projects, the list has been suppressed. You can list all projects with &lt;span class="s1">&amp;#39;oc projects&amp;#39;&lt;/span>
Using project &lt;span class="s2">&amp;#34;default&amp;#34;&lt;/span>.
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ oc get no
NAME STATUS ROLES AGE VERSION
ip-10-0-153-95.us-west-2.compute.internal Ready worker 42m v1.21.1+d8043e1
ip-10-0-171-119.us-west-2.compute.internal Ready infra,worker 17m v1.21.1+d8043e1
ip-10-0-175-165.us-west-2.compute.internal Ready infra,worker 18m v1.21.1+d8043e1
ip-10-0-202-234.us-west-2.compute.internal Ready master 49m v1.21.1+d8043e1
ip-10-0-239-231.us-west-2.compute.internal Ready master 49m v1.21.1+d8043e1
ip-10-0-242-134.us-west-2.compute.internal Ready master 49m v1.21.1+d8043e1
ip-10-0-252-208.us-west-2.compute.internal Ready worker 42m v1.21.1+d8043e1
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="刪除-cluster">刪除 Cluster&lt;/h2>
&lt;p>&lt;code>rosa delete cluster&lt;/code> 可以使用指令刪除使用 ROSA 創建的cluster。順便說一下，集群的刪除在大約 10 分鐘內完成。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ rosa delete cluster --cluster&lt;span class="o">=&lt;/span>rosacluster
? Are you sure you want to delete cluster rosacluster? Yes
I: Cluster &lt;span class="s1">&amp;#39;rosacluster&amp;#39;&lt;/span> will start uninstalling now
I: To watch your cluster uninstallation logs, run &lt;span class="err">&amp;#39;&lt;/span>rosa logs uninstall -c rosacluster --watch
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>rosaworkshop.io&lt;/li>
&lt;/ul></description></item><item><title>OpenShift Intsall Troubleshooting Notes</title><link>https://blog.yylin.io/openshift/install-troubleshooting/</link><pubDate>Wed, 29 Sep 2021 00:53:25 +0800</pubDate><guid>https://blog.yylin.io/openshift/install-troubleshooting/</guid><description>&lt;p>延伸上一篇 OCP UPI 部署(&lt;a class="link" href="https://blog.yylin.io/p/openshift-4.8.x-upi-install-on-bare-metal" target="_blank" rel="noopener"
>OpenShift 4.8.x UPI install on Bare metal&lt;/a>)過程遇到問題彙整。&lt;/p>
&lt;blockquote>
&lt;p>備註: 由於資源有限情況下，透過單一伺服器(主機)透過 VM 模擬實際節點硬體資源環境，這邊主要透過檢測與除錯，來確保 OpenShift 部署成功。&lt;/p>
&lt;/blockquote>
&lt;h2 id="部署常見問題整理-持續更新">部署常見問題整理 (持續更新)&lt;/h2>
&lt;h3 id="超時等待-bootstrap-節點啟動">超時等待 &lt;code>bootstrap&lt;/code> 節點啟動&lt;/h3>
&lt;ul>
&lt;li>發現特定 Pod 持續&lt;code>RunningNotReady&lt;/code> 狀態&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">W0830 11:16:37.087497 35214 reflector.go:436] k8s.io/client-go/tools/watch/informerwatcher.go:146: watch of *v1.ConfigMap ended with: very short watch: k8s.io/client-go/tools/watch/informerwatcher.go:146: Unexpected watch close - watch lasted less than a second and no items received
apiserver - &amp;gt; RunningNotReady
Aug 30 03:42:37 bootstrap.lab.yiylin.internal bootkube.sh[644199]: Pod Status:openshift-kube-apiserver/kube-apiserver RunningNotReady
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>此情境請透過收集&lt;code>bootstrap&lt;/code> 節點日誌，來確認環境問題&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ ./openshift-install gather bootstrap --dir&lt;span class="o">=&lt;/span>&amp;lt;installation_directory&amp;gt;
...
INFO Pulling debug logs from the bootstrap machine
INFO Bootstrap gather logs captured here &lt;span class="s2">&amp;#34;&amp;lt;installation_directory&amp;gt;/log-bundle-&amp;lt;timestamp&amp;gt;.tar.gz&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>蒐集包含 bootstrap process / bootstrap 上所有 Pod/Container 的 log&lt;/li>
&lt;li>下載完後解壓縮 &lt;code>.tar.gz&lt;/code> 檔案，針對可能部署或未啟動的&lt;code>Pod&lt;/code>檢查log錯誤狀態，來找到對應的錯誤資訊&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>補充說明 bootstrap 主要分成兩個動作&lt;/p>
&lt;ol>
&lt;li>安裝自己跟建立自己的 cluster(Pod)&lt;/li>
&lt;li>引導安裝 master x 3&lt;/li>
&lt;li>master bootstrap 全部安裝完，然後下 wait for complete 確認最終才可移除 bootstrap node&lt;/li>
&lt;/ol>
&lt;/blockquote>
&lt;h4 id="reference">Reference:&lt;/h4>
&lt;ul>
&lt;li>&lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/installing/installing-troubleshooting.html#installation-bootstrap-gather_installing-troubleshooting" target="_blank" rel="noopener"
>Gathering logs from a failed installation&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/installing/installing_bare_metal/installing-bare-metal.html#installation-installing-bare-metal_installing-bare-metal" target="_blank" rel="noopener"
>Waiting for the bootstrap process to complete&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="master-node-部署不起來檢查並驗證-etcd-運行之硬碟是否正常運作-">Master Node 部署不起來，檢查並驗證 etcd 運行之硬碟是否正常運作 ?&lt;/h3>
&lt;ul>
&lt;li>大部分 master 無法建置情境，通常可能會有原因是硬碟速度問題(硬碟壞軌)&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>造成叢集有時候部署成功有時候會失敗的情況&lt;/p>
&lt;/blockquote>
&lt;p>透過簡單運行 &lt;code>fio&lt;/code> 來測試 etcd benchamrk performance 檢測&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">$ oc debug node/&amp;lt;master_node&amp;gt;
&lt;span class="o">[&lt;/span>...&lt;span class="o">]&lt;/span>
sh-4.4# chroot /host bash
&lt;span class="o">[&lt;/span>root@&amp;lt;master_node&amp;gt; /&lt;span class="o">]&lt;/span>&lt;span class="c1"># podman run --volume /var/lib/etcd:/var/lib/etcd:Z quay.io/openshift-scale/etcd-perf&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="reference-1">Reference:&lt;/h4>
&lt;ul>
&lt;li>&lt;a class="link" href="https://access.redhat.com/solutions/4885641" target="_blank" rel="noopener"
>How to Use &amp;lsquo;fio&amp;rsquo; to Check Etcd Disk Performance in OCP
&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=6qjsh9J3ndM&amp;amp;ab_channel=PingChunHuang" target="_blank" rel="noopener"
>[參考影片說明] OpenShift 4 如何使用 fio 驗證 etcd 運行之硬碟是否可以正常運作 / Use &amp;lsquo;fio&amp;rsquo; to Check Etcd Disk Performance&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.ibm.com/docs/en/cloud-private/3.2.x?topic=requirements-hardware-recommendations" target="_blank" rel="noopener"
>Hardware requirements and recommendations&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="補充檢查---除錯流程">補充|檢查 - 除錯流程&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>部署過程都透過 bootkube 確認部署狀態資訊，log 會不斷顯示錯誤然後 loop 確認環節，嘗試能不能從他錯誤訊息找出規則(也就是他跳錯誤的地方，通常是在 log restart之前)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>嘗試 SSH 到 Master Node，透過 &lt;code>netstat -plnt&lt;/code> 檢查三個服務，這三個通常只要好，這台 Master 就沒問題 (6443| 22623|2379|2380)，分別是 OpenShift API/Kubernetes API/ETCD/Machine Config Operator&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果以上幾個 Pod 有問題，透過 &lt;code>crictl ps&lt;/code> 跟 &lt;code>crictl log&lt;/code> 去查看 Container Log，問題有可能是連續的錯誤，所以可能是 API 有問題，可能是 Controller/Scheduler 引起，細節需要透過上面提到方式，下載節點所有 Log 日誌來比對檢查，找到正確的錯誤資訊來排除錯誤&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="reference-2">Reference:&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://connect.redhat.com/en/blog/openshift-troubleshooting-resources" target="_blank" rel="noopener"
>OpenShift Troubleshooting Resources&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>OpenShift 4.8.x UPI install on Bare metal</title><link>https://blog.yylin.io/openshift/ocp4-install/</link><pubDate>Sun, 26 Sep 2021 14:54:40 +0800</pubDate><guid>https://blog.yylin.io/openshift/ocp4-install/</guid><description>&lt;blockquote>
&lt;p>[註記] 由於硬體環境資源有限，本實驗是透過 &lt;a class="link" href="https://pve.proxmox.com/wiki/Main_Page" target="_blank" rel="noopener"
>&lt;code>Proxmox Environment&lt;/code>&lt;/a> 單一伺服器節點來模擬部署 &lt;code>OpenShift&lt;/code> 叢集，並依據官網配置建議硬體需求(Server sizing)資源。
[共同撰寫編輯]: &lt;a class="link" href="https://k2r2bai.com/" target="_blank" rel="noopener"
>Kyle Bai&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="部署版本說明">部署版本說明：&lt;/h2>
&lt;ul>
&lt;li>Proxmox Environment v6.1-7
&lt;ul>
&lt;li>CPU: 8-Core, 16-Thread Unlocked / Memory: 128 GB&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>OpenShift v4.8.x.&lt;/li>
&lt;/ul>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;ul>
&lt;li>參考官網文件 - &lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/installing/installing_bare_metal/installing-bare-metal.html" target="_blank" rel="noopener"
>Installing a user-provisioned cluster on bare metal&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="事前準備">事前準備&lt;/h2>
&lt;p>開始前，需要先準備以下資訊與要求。&lt;/p>
&lt;h3 id="download-urls">Download URLs&lt;/h3>
&lt;ul>
&lt;li>&lt;a class="link" href="https://console.redhat.com/openshift/install/metal/user-provisioned" target="_blank" rel="noopener"
>User-provisioned infrastructure&lt;/a>: 可下載 OpenShift Installer、CLI 與 Pull secrets(需要登入 Red Hat 註冊帳號權限)&lt;/li>
&lt;li>&lt;a class="link" href="https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest-4.8/" target="_blank" rel="noopener"
>Public OpenShift 4.8 Mirror&lt;/a>: 可下載 OpenShift Installer、CLI 與 OPM。
&lt;ul>
&lt;li>&lt;strong>openshift-client-linux.tar.gz&lt;/strong>: 包含 oc 與 kubectl CLI 工具。&lt;/li>
&lt;li>&lt;strong>openshift-install-linux.tar.gz&lt;/strong>: 包含 openshift-install 工具。用於建立 OpenShift auth、igntion 等設定檔案。&lt;/li>
&lt;li>&lt;strong>opm-linux.tar.gz&lt;/strong>: 用於管理 Operator Hub 與 mirror 相關 images。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a class="link" href="https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos/4.8/latest/" target="_blank" rel="noopener"
>Public RHCOS 4.8 Mirror&lt;/a>: 可下載 RHCOS 4.8 相關 VM images。
&lt;ul>
&lt;li>若手動安裝以下載 &lt;code>rhcos-live.x86_64.iso&lt;/code> 為主。若想要控管使用版本，請選擇有標示版本的 live iso。
&lt;ul>
&lt;li>FET vSphere 安裝請以這方式進行。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>若以 PXE 方式安裝，則下載以下映像檔:
&lt;ul>
&lt;li>rhcos-live-initramfs.x86_64.img&lt;/li>
&lt;li>rhcos-live-kernel-x86_64&lt;/li>
&lt;li>rhcos-live-rootfs.x86_64.img&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>過程中會透過 &lt;code>wget&lt;/code> 下載，因此在有網路狀況下，不需要預先下載。&lt;/p>
&lt;/blockquote>
&lt;hr>
&lt;h3 id="network-and-hosts-info">Network and Hosts Info&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>OpenShift subnet CIDR&lt;/strong>: 192.168.101.0/24&lt;/li>
&lt;li>&lt;strong>OpenShift Pod Network(CNI)&lt;/strong>: 10.128.0.0/14&lt;/li>
&lt;li>&lt;strong>OpenShift Service Network&lt;/strong>: 172.3.0.0/16&lt;/li>
&lt;li>&lt;strong>Domain&lt;/strong>: lab.yiylin.internal&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Hosts&lt;/th>
&lt;th>IP&lt;/th>
&lt;th>CPU&lt;/th>
&lt;th>RAM&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>bashtion&lt;/td>
&lt;td>192.168.101.9&lt;/td>
&lt;td>2 vCore&lt;/td>
&lt;td>4G&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>bootstrap&lt;/td>
&lt;td>192.168.101.10&lt;/td>
&lt;td>4 vCore&lt;/td>
&lt;td>8G&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>master-1&lt;/td>
&lt;td>192.168.101.21&lt;/td>
&lt;td>4 vCore&lt;/td>
&lt;td>8G&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>master-2&lt;/td>
&lt;td>192.168.191.22&lt;/td>
&lt;td>4 vCore&lt;/td>
&lt;td>8G&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>master-3&lt;/td>
&lt;td>192.168.191.23&lt;/td>
&lt;td>4 vCore&lt;/td>
&lt;td>8G&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>worker-1&lt;/td>
&lt;td>192.168.191.31&lt;/td>
&lt;td>4 vCore&lt;/td>
&lt;td>8G&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>worker-2&lt;/td>
&lt;td>192.168.191.32&lt;/td>
&lt;td>4 vCore&lt;/td>
&lt;td>8G&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>infra-1&lt;/td>
&lt;td>192.168.191.41&lt;/td>
&lt;td>4 vCore&lt;/td>
&lt;td>8G&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>infra-2&lt;/td>
&lt;td>192.168.191.42&lt;/td>
&lt;td>4 vCore&lt;/td>
&lt;td>8G&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>infra-3&lt;/td>
&lt;td>192.168.191.43&lt;/td>
&lt;td>4 vCore&lt;/td>
&lt;td>8G&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;blockquote>
&lt;p>這裡為了方便測試，將 PXE / HAProxy / DNS Server 等都放在 bastion上。
[額外參考資訊]各元件節點最小資源可參考 &lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/installing/installing_platform_agnostic/installing-platform-agnostic.html#minimum-resource-requirements_installing-platform-agnostic" target="_blank" rel="noopener"
>Minimum resource requirements&lt;/a>。
請先透過 &lt;code>Proxmox Environment&lt;/code> 開啟對應 &lt;code>hardware&lt;/code> VM。&lt;/p>
&lt;/blockquote>
&lt;h4 id="補充-network-說明">補充 Network 說明&lt;/h4>
&lt;blockquote>
&lt;p>其中 &lt;code>OpenShift subnet CIDR&lt;/code> 請修改為自己當前 Proxmox Environment 網路配置)
&lt;img src="https://i.imgur.com/8UnOcXL.jpg"
loading="lazy"
>&lt;/p>
&lt;/blockquote>
&lt;h2 id="bastion">Bastion&lt;/h2>
&lt;p>透過 Live CD 安裝 RHEL 8 版本(或使用 CentOS 8)，並確保網路設定正確。&lt;/p>
&lt;blockquote>
&lt;p>RHEL 需要確認 &lt;code>subscription&lt;/code> 驗證，確保 repo 源可正常取得&lt;/p>
&lt;/blockquote>
&lt;h3 id="事前準備-1">事前準備&lt;/h3>
&lt;p>進入 &lt;code>bastion&lt;/code> 機器，安裝 jq 與 wget 工具等:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ sudo su -
$ yum install -y wget jq vim
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>關閉 bastion 防火牆:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ systemctl stop firewalld
$ systemctl disable firewalld
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&amp;gt; 這邊方便測試，所以直接關閉 :D。&lt;/p>
&lt;p>設定與關閉 SELinux:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ vim /etc/selinux/config
&lt;span class="nv">SELINUX&lt;/span>&lt;span class="o">=&lt;/span>disabled
$ setenforce &lt;span class="m">0&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>這邊方便測試實驗，所以直接關閉。&lt;/p>
&lt;/blockquote>
&lt;p>建立 SSH Keys:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ ssh-keygen -t rsa
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>這邊方便測試，以 root 來建立。&lt;/p>
&lt;/blockquote>
&lt;p>導入以下環境變數:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="nb">export&lt;/span> &lt;span class="nv">DOMAIN&lt;/span>&lt;span class="o">=&lt;/span>lab.yiylin.internal
&lt;span class="nb">export&lt;/span> &lt;span class="nv">OCP_NETWORK_CIDR&lt;/span>&lt;span class="o">=&lt;/span>192.168.101.0/24
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>下載 OpenShift Installer 與 CLI 工具，並解壓縮檔案到 &lt;code>/usr/local/bin/&lt;/code> 底下:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="c1"># CLI&lt;/span>
$ wget -c https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest-4.8/openshift-client-linux.tar.gz -O - &lt;span class="p">|&lt;/span> tar -xz
$ mv &lt;span class="o">{&lt;/span>oc,kubectl&lt;span class="o">}&lt;/span> /usr/local/bin/
$ oc version
Client Version: 4.8.2
&lt;span class="c1"># Installer&lt;/span>
$ wget -c https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest-4.8/openshift-install-linux.tar.gz -O - &lt;span class="p">|&lt;/span> tar -xz
$ mv openshift-install /usr/local/bin/
$ openshift-install version
openshift-install 4.8.2
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="安裝與設定-dns-server">安裝與設定 DNS Server&lt;/h3>
&lt;p>安裝 DNS server 套件，這邊使用 &lt;code>dnsmasq&lt;/code> 來提供服務:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ yum -y install dnsmasq bind-utils
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>這部分也可參考 OCP 官網安裝 &lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/installing/installing_bare_metal/installing-bare-metal.html#installation-dns-user-infra-example_installing-bare-metal" target="_blank" rel="noopener"
>BIND&lt;/a>，關於不同 &lt;code>DNS Server&lt;/code> 相關配置方法，會額外補充於後續文章介紹。&lt;/p>
&lt;/blockquote>
&lt;p>編輯 &lt;code>/etc/dnsmasq.d/openshift.conf&lt;/code> 設定檔，以設定 A Record 與 PTR:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ cat &amp;lt;&amp;lt; &lt;span class="s2">&amp;#34;EOF&amp;#34;&lt;/span> &amp;gt; /etc/dnsmasq.d/openshift.conf
&lt;span class="nv">server&lt;/span>&lt;span class="o">=&lt;/span>8.8.8.8
&lt;span class="nv">domain&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,&lt;span class="si">${&lt;/span>&lt;span class="nv">OCP_NETWORK_CIDR&lt;/span>&lt;span class="si">}&lt;/span>,local
&lt;span class="c1"># A Records(api)&lt;/span>
host-record&lt;span class="o">=&lt;/span>api.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>, 192.168.101.9
host-record&lt;span class="o">=&lt;/span>api-int.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,
host-record&lt;span class="o">=&lt;/span>api-int.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.9
&lt;span class="c1"># A Records(hosts)&lt;/span>
host-record&lt;span class="o">=&lt;/span>bastion.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.9
host-record&lt;span class="o">=&lt;/span>bootstrap.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.10
host-record&lt;span class="o">=&lt;/span>master-1.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.21
host-record&lt;span class="o">=&lt;/span>master-2.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.22
host-record&lt;span class="o">=&lt;/span>master-3.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.23
host-record&lt;span class="o">=&lt;/span>worker-1.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.31
host-record&lt;span class="o">=&lt;/span>worker-2.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.32
host-record&lt;span class="o">=&lt;/span>infra-1.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.41
host-record&lt;span class="o">=&lt;/span>infra-2.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.42
host-record&lt;span class="o">=&lt;/span>infra-3.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.43
&lt;span class="c1"># A Records(etcd)&lt;/span>
host-record&lt;span class="o">=&lt;/span>etcd-0.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.21
host-record&lt;span class="o">=&lt;/span>etcd-1.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.22
host-record&lt;span class="o">=&lt;/span>etcd-2.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,192.168.101.23
srv-host&lt;span class="o">=&lt;/span>_etcd-server-ssl._tcp.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,etcd-0.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,2380,0,10
srv-host&lt;span class="o">=&lt;/span>_etcd-server-ssl._tcp.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,etcd-1.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,2380,0,10
srv-host&lt;span class="o">=&lt;/span>_etcd-server-ssl._tcp.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,etcd-2.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>,2380,0,10
&lt;span class="c1"># PTRs&lt;/span>
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/apps.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.9
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/.apps.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.9
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/api.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.9
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/api-int.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.9
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/bastion.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.9
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/bootstrap.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.10
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/master-1.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.21
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/master-2.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.22
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/master-3.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.23
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/etcd-0.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.21
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/etcd-1.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.22
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/etcd-2.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.23
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/worker-1.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.31
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/worker-2.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.32
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/infra-1.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.41
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/infra-2.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.42
&lt;span class="nv">address&lt;/span>&lt;span class="o">=&lt;/span>/infra-3.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>/192.168.101.43
EOF
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>啟動 dnsmasq 服務，並檢測 dnsmasq 設定是否正確:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ systemctl &lt;span class="nb">enable&lt;/span> dnsmasq&lt;span class="p">;&lt;/span> systemctl start dnsmasq
$ dnsmasq --test
dnsmasq: syntax check OK.
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>編輯 &lt;code>/etc/resolv.conf&lt;/code> 檔案，修改 nameserver:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ cat &amp;lt;&amp;lt; &lt;span class="s2">&amp;#34;EOF&amp;#34;&lt;/span> &amp;gt; /etc/resolv.conf
nameserver 127.0.0.1
EOF
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>驗證 DNS server 正反解:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="c1"># dig domain @dns_server&lt;/span>
$ dig bastion.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span> @192.168.101.9
&lt;span class="c1"># dig -x ip @dns_server&lt;/span>
$ dig -x 192.168.101.9 @192.168.101.9
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>請驗證填寫自己對應的 &lt;code>ip address&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;h3 id="安裝與設定-http-server">安裝與設定 HTTP Server&lt;/h3>
&lt;p>安裝與設定 httpd 套件:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ yum -y install httpd
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>編輯 &lt;code>/etc/httpd/conf/httpd.conf&lt;/code> 設定檔:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="c1">#Listen 12.34.56.78:80&lt;/span>
Listen 8080
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>因為 80 是 Ingress-http 使用，除非將 HAProxy 拆成不同節點或用 External LB。&lt;/p>
&lt;/blockquote>
&lt;p>啟動 httpd 服務:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ systemctl &lt;span class="nb">enable&lt;/span> httpd&lt;span class="p">;&lt;/span> systemctl start httpd
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="產生-openshift-ignition-fils">產生 OpenShift Ignition fils&lt;/h3>
&lt;p>建立放置 OpenShift Config 檔案的目錄:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ &lt;span class="nb">cd&lt;/span> &lt;span class="nv">$HOME&lt;/span> &lt;span class="p">;&lt;/span> mkdir &lt;span class="nv">$HOME&lt;/span>/ocp4/ignition&lt;span class="p">;&lt;/span>&lt;span class="nb">cd&lt;/span> &lt;span class="nv">$HOME&lt;/span>/ocp4/ignition
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>建立與編輯 &lt;code>install-config.yaml&lt;/code> 檔案:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">v1&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">baseDomain&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">yiylin.internal&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">compute&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>- &lt;span class="nt">hyperthreading&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Enabled&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">worker&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">replicas&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">0&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">controlPlane&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">hyperthreading&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Enabled&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">master&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">replicas&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">3&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">lab&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">networking&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">clusterNetworks&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">cidr&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">10.128.0.0&lt;/span>&lt;span class="l">/14&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">hostPrefix&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">24&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">networkType&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">OpenShiftSDN&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">serviceNetwork&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="m">172.3.0.0&lt;/span>&lt;span class="l">/16&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">platform&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">none&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>{}&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">pullSecret&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;{&amp;#34;auths&amp;#34;:{ YOUR_PULL_SECRETE }}&amp;#39;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">sshKey&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s2">&amp;#34;SSH_PUB_KEY&amp;#34;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;ul>
&lt;li>Pull secret 可在 &lt;a class="link" href="https://cloud.redhat.com/openshift/install/metal/user-provisioned" target="_blank" rel="noopener"
>Create Cluster by user provisioned&lt;/a> 取得。&lt;/li>
&lt;li>Proxy 設定，參考 &lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/installing/installing_bare_metal/installing-restricted-networks-bare-metal.html#installation-configure-proxy_installing-restricted-networks-bare-metal" target="_blank" rel="noopener"
>Configuring the cluster-wide proxy during installation&lt;/a>。&lt;/li>
&lt;li>SSH Key 請自行於 &lt;code>bastion&lt;/code> 創建填寫，這裡不多做說明&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>產生 manifests 相關檔案:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ cp install-config.yaml install-config.yaml.bak
$ openshift-install create manifests --dir&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/ocp4/ignition
$ ls &lt;span class="nv">$HOME&lt;/span>/ocp4/ignition
manifests openshift
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>編輯 &lt;code>manifests/cluster-scheduler-02-config.yml&lt;/code> 檔案，設定 &lt;code>mastersSchedulable&lt;/code> 值，以確保 master 不作為工作負載節點:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="nn">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">mastersSchedulable&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nn">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>產生 OCP 使用的 Ignition files:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ openshift-install create ignition-configs --dir&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/ocp4/ignition
$ ls &lt;span class="nv">$HOME&lt;/span>/ocp4/ignition
auth bootstrap.ign master.ign metadata.json worker.ign
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>撰寫方面安裝 RHCOS 的腳本 &lt;code>$HOME/ocp4/ignition/coreos-install.sh&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="cp">#!/bin/bash
&lt;/span>&lt;span class="cp">&lt;/span>
&lt;span class="nb">set&lt;/span> -eu
&lt;span class="nb">export&lt;/span> &lt;span class="nv">DEVICE_NAME&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">DEVICE_NAME&lt;/span>&lt;span class="k">:-&lt;/span>&lt;span class="p">/dev/sda&lt;/span>&lt;span class="si">}&lt;/span>
&lt;span class="nb">export&lt;/span> &lt;span class="nv">IGNITION_FILE&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">IGNITION_FILE&lt;/span>&lt;span class="k">:-&lt;/span>&lt;span class="nv">bootstrap&lt;/span>&lt;span class="p">.ign&lt;/span>&lt;span class="si">}&lt;/span> &lt;span class="c1"># bootstrap.ign master.ign worker.ign &lt;/span>
&lt;span class="nb">export&lt;/span> &lt;span class="nv">IGNITION_URL&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">IGNITION_URL&lt;/span>&lt;span class="k">:-&lt;/span>&lt;span class="nv">http&lt;/span>&lt;span class="p">://192.168.101.9:&lt;/span>&lt;span class="nv">8080&lt;/span>&lt;span class="p">/ignition/&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">IGNITION_FILE&lt;/span>&lt;span class="si">}}&lt;/span>
sudo coreos-installer install &lt;span class="si">${&lt;/span>&lt;span class="nv">DEVICE_NAME&lt;/span>&lt;span class="si">}&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --insecure-ignition &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --ignition-url&lt;span class="o">=&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">IGNITION_URL&lt;/span>&lt;span class="si">}&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --firstboot-args rd.neednet&lt;span class="o">=&lt;/span>&lt;span class="m">1&lt;/span> &lt;span class="se">\
&lt;/span>&lt;span class="se">&lt;/span> --copy-network
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>複製 &lt;code>*.ign&lt;/code> 與腳本 到 &lt;code>/var/www/html/ignition&lt;/code> 目錄:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ mkdir /var/www/html/ignition
$ cp -rp &lt;span class="nv">$HOME&lt;/span>/ocp4/ignition/&lt;span class="o">{&lt;/span>*.ign,coreos-install.sh&lt;span class="o">}&lt;/span> /var/www/html/ignition
$ ls /var/www/html/ignition
bootstrap.ign master.ign worker.ign coreos-install.sh
$ chmod &lt;span class="m">664&lt;/span> -R /var/www/html/ignition/*
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="bootstrap">Bootstrap&lt;/h2>
&lt;p>透過 PVE 建立 Bootstrap 節點，並掛載 RHCOS Live ISO，並進入 Console 執行以下操作。&lt;/p>
&lt;p>首先進入系統後，先設定 Network 資訊:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ sudo nmtui
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>設定網卡資訊:&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/tJFSkiO.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/vAEtA2f.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/qINQqLa.png"
loading="lazy"
>&lt;/p>
&lt;blockquote>
&lt;p>確保網卡 IP address 設定為 &lt;code>xx.xx.xx.xx/24&lt;/code>，若沒有設定 Network mask 的話，就會用預設 &lt;code>xx.xx.xx.xx/8&lt;/code>。&lt;/p>
&lt;/blockquote>
&lt;p>重新啟動網卡設定:&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/KMvs0UZ.png"
loading="lazy"
>&lt;/p>
&lt;p>透過以下指令檢查設定結果:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ ip -4 a
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>確認網路與 DNS 都能夠被解析到。&lt;/p>
&lt;/blockquote>
&lt;p>確認沒問題後，執行以下指令來安裝 RHCOS，並設定為 Bootstrap 節點:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ curl http://192.168.101.9:8080/ignition/coreos-install.sh --output coreos-install.sh
$ chmod u+x coreos-install.sh
$ ./coreos-install.sh
&lt;span class="c1"># 安裝完成後&lt;/span>
$ lsblk -f
$ reboot
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>安裝沒問題後，重新啟動機器，並將 CD-ROM 移除。&lt;/p>
&lt;/blockquote>
&lt;p>Bootstrap 開啟完成後，回到 &lt;code>bastion&lt;/code> 節點執行以下指令來檢查部署狀況:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ openshift-install wait-for bootstrap-complete --dir&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/ocp4/ignition --log-level debug
DEBUG OpenShift Installer 4.8.2
DEBUG Built from commit a5ddd2dd6c72d8a5ea0a5f17acd8b964b6a3d1be
INFO Waiting up to 20m0s &lt;span class="k">for&lt;/span> the Kubernetes API at https://api.lab.yiylin.internal:6443...
INFO API v1.21.1+051ac4f up
INFO Waiting up to 30m0s &lt;span class="k">for&lt;/span> bootstrapping to complete...
&lt;span class="c1"># 確認 openshift-api-server 以及 machine-config-server LB 可以通&lt;/span>
$ curl -k https://api-int.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>:6443
$ curl -k https://api-int.&lt;span class="si">${&lt;/span>&lt;span class="nv">DOMAIN&lt;/span>&lt;span class="si">}&lt;/span>:22623/config/master &lt;span class="p">|&lt;/span> jq .
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>當看到此訊息時，就能並往下進行安裝 Masters。若等待過久，可以透過 bastion 進入 bootstrap 節點查看狀況:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ ssh core@bootstrap.lab.yiylin.internal
core $ sudo crictl pods
core $ sudo crictl ps -a
core $ sudo journalctl -b -f -u bootkube.service
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>正常情況 Pods 要如以下:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">POD ID CREATED STATE NAME NAMESPACE ATTEMPT RUNTIME
8101e41b16f9e 52 seconds ago Ready bootstrap-kube-scheduler-localhost kube-system 0 (default)
907d0a933771a 52 seconds ago Ready bootstrap-kube-controller-manager-localhost kube-system 0 (default)
a8b709f7caeaa 52 seconds ago Ready bootstrap-kube-apiserver-localhost kube-system 0 (default)
4eb793b3d1844 52 seconds ago Ready cloud-credential-operator-localhost openshift-cloud-credential-operator 0 (default)
49a1cdb2b25f9 52 seconds ago Ready bootstrap-cluster-version-operator-localhost openshift-cluster-version 0 (default)
c5098e42b5aa5 About a minute ago Ready bootstrap-machine-config-operator-localhost default 0 (default)
e7a3dbc6e0bc0 About a minute ago Ready etcd-bootstrap-member-localhost openshift-etcd 0 (default)
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="maters">Maters&lt;/h2>
&lt;p>透過 vCenter 建立 Master 節點，並掛載 RHCOS Live ISO，並進入 Console 執行以下操作。&lt;/p>
&lt;p>首先進入系統後，先設定 Network 資訊:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ sudo nmtui
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&amp;gt; 網路參考 Bootstrap 設定流程。&lt;/p>
&lt;p>確認沒問題後，執行以下指令來安裝 RHCOS，並設定為 Masters 節點:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ curl http://192.168.101.9:8080/ignition/coreos-install.sh --output coreos-install.sh
$ chmod u+x coreos-install.sh
$ &lt;span class="nb">export&lt;/span> &lt;span class="nv">IGNITION_FILE&lt;/span>&lt;span class="o">=&lt;/span>master.ign
$ ./coreos-install.sh
&lt;span class="c1"># 安裝完後&lt;/span>
$ reboot
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>安裝沒問題後，重新啟動機器，並將 CD-ROM 移除。&lt;/p>
&lt;/blockquote>
&lt;p>Masters 都開啟完成後，回到 &lt;code>bastion&lt;/code> 節點執行以下指令來檢查部署狀況:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ openshift-install wait-for bootstrap-complete --dir&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/ocp4/ignition --log-level debug
...
INFO Waiting up to 30m0s &lt;span class="k">for&lt;/span> bootstrapping to complete...
DEBUG Bootstrap status: &lt;span class="nb">complete&lt;/span>
INFO It is now safe to remove the bootstrap resources
INFO Time elapsed: 0s
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在 &lt;code>bastion&lt;/code> 執行以下指令來查看叢集狀況:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ cp &lt;span class="nv">$HOME&lt;/span>/ocp4/ignition/auth/kubeconfig &lt;span class="nv">$HOME&lt;/span>/ocp4/kubeconfig
$ &lt;span class="nb">export&lt;/span> &lt;span class="nv">KUBECONFIG&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/ocp4/kubeconfig
$ oc get csr
NAME AGE SIGNERNAME REQUESTOR CONDITION
csr-9xqqd 25m kubernetes.io/kubelet-serving system:node:etcd-1 Approved,Issued
csr-gzvwr 27m kubernetes.io/kubelet-serving system:node:etcd-0 Approved,Issued
csr-j6npt 25m kubernetes.io/kubelet-serving system:node:etcd-2 Approved,Issued
csr-mxqkf 25m kubernetes.io/kube-apiserver-client-kubelet system:serviceaccount:openshift-machine-config-operator:node-bootstrapper Approved,Issued
csr-tth9f 28m kubernetes.io/kube-apiserver-client-kubelet system:serviceaccount:openshift-machine-config-operator:node-bootstrapper Approved,Issued
csr-zx9q8 25m kubernetes.io/kube-apiserver-client-kubelet system:serviceaccount:openshift-machine-config-operator:node-bootstrapper Approved,Issued
system:openshift:openshift-authenticator 25m kubernetes.io/kube-apiserver-client system:serviceaccount:openshift-authentication-operator:authentication-operator Approved,Issued
$ oc get no
NAME STATUS ROLES AGE VERSION
master-1.lab.yiylin.internal Ready master 31m v1.21.1+051ac4f
master-2.lab.yiylin.internal Ready master 15m v1.21.1+051ac4f
master-3.lab.yiylin.internal Ready master 10m v1.21.1+051ac4f
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>完成後，即可進行 Workers 與 Infras 部署，並移除 Bootstrap。若等待過久，可以透過 bastion 進入 masters 節點查看狀況:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">$ ssh core@maste-1.lab.yiylin.internal
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="workers-amp-infras">Workers &amp;amp; Infras&lt;/h2>
&lt;p>透過 vCenter 建立 Workers &amp;amp; Infras 節點，並掛載 RHCOS Live ISO，並進入 Console 執行以下操作。&lt;/p>
&lt;p>首先進入系統後，先設定 Network 資訊:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ sudo nmtui
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>網路參考 Bootstrap 設定流程。&lt;/p>
&lt;/blockquote>
&lt;p>確認沒問題後，執行以下指令來安裝 RHCOS，並設定為 Workers &amp;amp; Infras 節點:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ curl http://192.168.101.9:8080/ignition/coreos-install.sh --output coreos-install.sh
$ chmod u+x coreos-install.sh
$ &lt;span class="nb">export&lt;/span> &lt;span class="nv">IGNITION_FILE&lt;/span>&lt;span class="o">=&lt;/span>worker.ign
$ ./coreos-install.sh
&lt;span class="c1"># 安裝完成後&lt;/span>
$ lsblk -f
$ reboot
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>安裝沒問題後，重新啟動機器，並將 CD-ROM 移除。&lt;/p>
&lt;/blockquote>
&lt;p>Workers &amp;amp; Infras 都開啟完成後，就可以回到 &lt;code>bastion&lt;/code> 節點執行以下指令來檢查部署狀況:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ openshift-install wait-for install-complete --dir&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/ocp4/ignition --log-level debug
DEBUG OpenShift Installer 4.8.2
DEBUG Built from commit a5ddd2dd6c72d8a5ea0a5f17acd8b964b6a3d1be
DEBUG Loading Install Config...
DEBUG Loading SSH Key...
DEBUG Loading Base Domain...
DEBUG Loading Platform...
DEBUG Loading Cluster Name...
DEBUG Loading Base Domain...
DEBUG Loading Platform...
DEBUG Loading Networking...
DEBUG Loading Platform...
DEBUG Loading Pull Secret...
DEBUG Loading Platform...
DEBUG Using Install Config loaded from state file
INFO Waiting up to 40m0s &lt;span class="k">for&lt;/span> the cluster at https://api.lab.yiylin.internal:6443 to initialize...
DEBUG Still waiting &lt;span class="k">for&lt;/span> the cluster to initialize: Some cluster operators are still updating: authentication, console, ingress, monitoring
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>出現 &lt;code>DEBUG&lt;/code> 即可往下操作，因為這部分會需要下載 Images 會比較久&lt;/p>
&lt;/blockquote>
&lt;p>開啟一個新的 Terminal，在 &lt;code>bastion&lt;/code> 節點 Approve workers CSR:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ &lt;span class="nb">export&lt;/span> &lt;span class="nv">KUBECONFIG&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/ocp4/kubeconfig
$ oc get csr -ojson &lt;span class="p">|&lt;/span> jq -r .items&lt;span class="o">[]&lt;/span> &lt;span class="p">|&lt;/span> &lt;span class="k">select&lt;/span>&lt;span class="o">(&lt;/span>.status &lt;span class="o">==&lt;/span> &lt;span class="o">{}&lt;/span> &lt;span class="o">)&lt;/span> &lt;span class="p">|&lt;/span> .metadata.name &lt;span class="p">|&lt;/span> xargs oc adm certificate approve
&lt;span class="c1"># 確認機器都起來&lt;/span>
$ oc get no
NAME STATUS ROLES AGE VERSION
infra0 Ready worker 12m v1.21.1+051ac4f
infra1 Ready worker 12m v1.21.1+051ac4f
infra2 Ready worker 12m v1.21.1+051ac4f
master0 Ready master 11h v1.21.1+051ac4f
master1 Ready master 11h v1.21.1+051ac4f
master2 Ready master 11h v1.21.1+051ac4f
worker0 Ready worker 12m v1.21.1+051ac4f
worker1 Ready worker 12m v1.21.1+051ac4f
worker2 Ready worker 12m v1.21.1+051ac4f
worker3 Ready worker 12m v1.21.1+051ac4f
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="搬移資源至-infra-nodes">搬移資源至 Infra nodes&lt;/h3>
&lt;p>接著要將 Worker 與 Infra 角色做拆分，確保系統與 Operator 服務不影響業務服務的負載，參考 &lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/machine_management/creating-infrastructure-machinesets.html#infrastructure-components_creating-infrastructure-machinesets" target="_blank" rel="noopener"
>Creating infrastructure machine sets&lt;/a>&lt;/p>
&lt;p>設定 infra nodes 的 labels:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ &lt;span class="k">for&lt;/span> i in &lt;span class="o">{&lt;/span>1..2&lt;span class="o">}&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="k">do&lt;/span>
oc label node worker-&lt;span class="si">${&lt;/span>&lt;span class="nv">i&lt;/span>&lt;span class="si">}&lt;/span> node-role.kubernetes.io/app&lt;span class="o">=&lt;/span> --overwrite
&lt;span class="k">done&lt;/span>
$ &lt;span class="k">for&lt;/span> i in &lt;span class="o">{&lt;/span>1..3&lt;span class="o">}&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="k">do&lt;/span>
oc label node infra-&lt;span class="si">${&lt;/span>&lt;span class="nv">i&lt;/span>&lt;span class="si">}&lt;/span> node-role.kubernetes.io/infra&lt;span class="o">=&lt;/span> --overwrite
oc label node infra-&lt;span class="si">${&lt;/span>&lt;span class="nv">i&lt;/span>&lt;span class="si">}&lt;/span> node-role.kubernetes.io/worker-
&lt;span class="k">done&lt;/span>
$ oc get no
NAME STATUS ROLES AGE VERSION
infra-1.lab.yiylin.internal Ready infra 31m v1.21.1+051ac4f
infra-2.lab.yiylin.internal Ready infra 31m v1.21.1+051ac4f
infra-3.lab.yiylin.internal Ready infra 31m v1.21.1+051ac4f
master-1.lab.yiylin.internal Ready master 156m v1.21.1+051ac4f
master-2.lab.yiylin.internal Ready master 140m v1.21.1+051ac4f
master-3.lab.yiylin.internal Ready master 135m v1.21.1+051ac4f
worker-1.lab.yiylin.internal Ready app,worker 31m v1.21.1+051ac4f
worker-2.lab.yiylin.internal Ready app,worker 31m v1.21.1+051ac4f
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>編輯 &lt;code>Scheduler&lt;/code> 物件，並調整預設 &lt;code>NodeSelector&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ oc edit scheduler cluster
...
spec:
defaultNodeSelector: node-role.kubernetes.io/app&lt;span class="o">=&lt;/span>
...
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>建立 Infra 機器的 Machine Config Pool 檔案:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ cat &lt;span class="p">&amp;amp;&lt;/span>lt&lt;span class="p">;&amp;amp;&lt;/span>lt&lt;span class="p">;&lt;/span>EOF &lt;span class="p">|&lt;/span> oc apply -f -
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfigPool
metadata:
name: infra
spec:
machineConfigSelector:
matchExpressions:
- key: machineconfiguration.openshift.io/role
operator: In
values:
- worker
- infra
nodeSelector:
matchLabels:
node-role.kubernetes.io/infra:
EOF
$ oc get mcp
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>這時 Infra 節點會重新啟動。&lt;/p>
&lt;/blockquote>
&lt;p>搬移 Router 元件至 Infra 節點上:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ oc edit IngressController default -n openshift-ingress-operator
...
spec:
nodePlacement:
nodeSelector:
matchLabels:
node-role.kubernetes.io/infra:
replicas: &lt;span class="m">2&lt;/span>
$ oc -n openshift-ingress get pod -o wide
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>搬移 Image Registry 元件至 Infra 節點上:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ oc edit configs.imageregistry.operator.openshift.io/cluster
...
spec:
nodeSelector:
node-role.kubernetes.io/infra:
...
$ oc -n openshift-image-registry get pods -o wide
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>搬移 Monitoring 元件至 Infra 節點上:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ cat &amp;lt;&amp;lt; &lt;span class="s2">&amp;#34;EOF&amp;#34;&lt;/span> &amp;gt; oc apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
name: cluster-monitoring-config
namespace: openshift-monitoring
data:
config.yaml: &lt;span class="p">|&lt;/span>+
alertmanagerMain:
nodeSelector:
node-role.kubernetes.io/infra:
prometheusK8s:
nodeSelector:
node-role.kubernetes.io/infra:
prometheusOperator:
nodeSelector:
node-role.kubernetes.io/infra:
grafana:
nodeSelector:
node-role.kubernetes.io/infra:
k8sPrometheusAdapter:
nodeSelector:
node-role.kubernetes.io/infra:
kubeStateMetrics:
nodeSelector:
node-role.kubernetes.io/infra:
telemeterClient:
nodeSelector:
node-role.kubernetes.io/infra:
openshiftStateMetrics:
nodeSelector:
node-role.kubernetes.io/infra:
thanosQuerier:
nodeSelector:
node-role.kubernetes.io/infra:
EOF
$ watch -n 0.1 oc -n openshift-monitoring get pod -o wide
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&amp;gt; 其他資源請參考 &lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/machine_management/creating-infrastructure-machinesets.html#infrastructure-moving-logging_creating-infrastructure-machinesets" target="_blank" rel="noopener"
>Moving OpenShift Logging resources&lt;/a> 搬移。&lt;/p>
&lt;p>叢集初始化會需要一點時間，完成後就可以透過 Console 查看整體狀況。&lt;/p>
&lt;h2 id="web-console">Web Console&lt;/h2>
&lt;p>透過 oc 取得 Web console 的 route URL:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ oc -n openshift-console get route console -o&lt;span class="o">=&lt;/span>&lt;span class="nv">jsonpath&lt;/span>&lt;span class="o">={&lt;/span>.spec.host&lt;span class="o">}{&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="o">}&lt;/span>
console-openshift-console.apps.lab.yiylin.internal
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>取得 OpenShift 的 &lt;code>kubeadmin&lt;/code> 密碼:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">$ cat &lt;span class="nv">$HOME&lt;/span>/ocp4/ignition/auth/kubeadmin-password
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://i.imgur.com/7ykeVUc.png"
loading="lazy"
>&lt;/p>
&lt;hr>
&lt;h2 id="terminal-login">Terminal Login&lt;/h2>
&lt;p>開啟一個新的 Terminal，在 bastion 節點配置 &lt;code>KUBECONFIG&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">$ &lt;span class="nb">export&lt;/span> &lt;span class="nv">KUBECONFIG&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/ocp4/kubeconfig
$ oc get no
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://github.com/openshift/machine-config-operator/blob/master/docs/custom-pools.md" target="_blank" rel="noopener"
>https://github.com/openshift/machine-config-operator/blob/master/docs/custom-pools.md&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://gist.github.com/kairen/894348c6281f33a981b528e69c3d06bf" target="_blank" rel="noopener"
>https://gist.github.com/kairen/894348c6281f33a981b528e69c3d06bf&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/installing/installing_vsphere/installing-restricted-networks-vsphere.html" target="_blank" rel="noopener"
>https://docs.openshift.com/container-platform/4.8/installing/installing_vsphere/installing-restricted-networks-vsphere.html&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-bind" target="_blank" rel="noopener"
>Networking Guide - BIND (Berkeley Internet Name Domain)&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.openshift.com/container-platform/4.8/installing/installing_bare_metal_ipi/ipi-install-prerequisites.html" target="_blank" rel="noopener"
>參考 IPI Prerequisites&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title/><link>https://blog.yylin.io/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.yylin.io/</guid><description/></item><item><title>Archives</title><link>https://blog.yylin.io/archives/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.yylin.io/archives/</guid><description/></item><item><title>Links</title><link>https://blog.yylin.io/links/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.yylin.io/links/</guid><description/></item><item><title>Search</title><link>https://blog.yylin.io/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.yylin.io/search/</guid><description/></item></channel></rss>